@inproceedings{
   title = {Proceedings of the 2001 IEEE International Conference on Control Applications (CCA'01) (Cat. No.01CH37204)},
   booktitle = {Proceedings of the 2001 IEEE International Conference on Control Applications (CCA'01) (Cat. No.01CH37204)},
   pages = {0_1},
   abstract = {Presents the front cover of the proceedings record.},
   keywords = {control engineering
control theory
adaptive control
electromechanical systems
fault detection and isolation
control education
neural networks
backstepping methods
mechanical systems
identification
modeling
power systems
fuzzy control
sliding mode
robotic control
optimal control
hybrid systems
genetic algorithms
fault diagnosis
nonlinear control
predictive control
sensors
observers
computer automated multi paradigm modeling
stability
vehicle systems
numerical studies
inverted pendulum
biochemical process
intelligent control
robust control
nonholonomic systems
noise/vibration suppression
PID controllers
PI controllers},
   DOI = {10.1109/CCA.2001.973311},
   year = {2001},
   type = {Conference Proceedings}
}

@inproceedings{
   title = {2004 IEEE International Symposium on Computer Aided Control Systems Design (IEEE Cat. No.04TH8770)},
   booktitle = {2004 IEEE International Conference on Robotics and Automation (IEEE Cat. No.04CH37508)},
   pages = {0_1},
   abstract = {The following topics are dealt with: optimal hybrid control for switched affine systems; multi-paradigm modeling for hybrid dynamic systems; polynomial methods for design of adaptive decentralized control; design and implementation of Scilab fuzzy logic toolbox; robust controller design using interval Diophantine equation; real-time interactive Simulink-based telelab; project-oriented approach to teaching control engineering; LMIs for constrained polynomial interpolation; robust H<sub>2</sub> control of norm-bounded uncertain continuous-time systems; MATLAB software package for semidefinite-quadratic-linear programming; minimax control design for nonlinear systems based on genetic programming; feedback control of networked systems},
   keywords = {adaptive control
continuous time systems
control system CAD
decentralised control
genetic algorithms
H<sup>infin</sup> control
interpolation
linear matrix inequalities
mathematical programming
nonlinear control systems
optimal control
polynomials
real-time systems
robust control
software packages
time-varying systems
uncertain systems
computer aided control system design
optimal hybrid control
switched affine systems
multiparadigm modeling
hybrid dynamic systems
adaptive decentralized control design
Scilab fuzzy logic toolbox
robust controller design
Diophantine equation
real time systems
Simulink based telelab
project oriented method
control engineering teaching
LMI method
constrained polynomial interpolation
robust H<sub>2</sub> control
uncertain continuous time systems
MATLAB software package
semidefinite quadratic programming
linear programming
minimax control design
nonlinear systems
genetic programming
feedback control
networked systems},
   DOI = {10.1109/CACSD.2004.1393830},
   year = {2004},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Á, Hegedüs and Á, Horváth and Ráth, I. and Branco, M. C. and Varró, D.},
   title = {Quick fix generation for DSMLs},
   booktitle = {2011 IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC)},
   pages = {17-24},
   abstract = {Domain-specific modeling languages (DSML) proved to be an important asset in creating powerful design tools for domain experts. Although these tools are capable of preserving the syntax-correctness of models even during free-hand editing, they often lack the ability of maintaining model consistency for complex language-specific constraints. Hence, there is a need for a tool-level automatism to assist DSML users in resolving consistency violation problems. In this paper, we describe an approach for the automatic generation of quick fixes for DSMLs, taking a set of domain-specific constraints and model manipulation policies as input. The computation relies on statespace exploration techniques to find sequences of operations that decrease the number of inconsistencies. Our approach is illustrated using a BPMN case study, and it is evaluated by several experiments to show its feasibility and performance.},
   keywords = {simulation languages
software engineering
domain-specific modeling languages
free-hand editing
language-specific constraint
tool-level automatism
DSML quick fix generation
model manipulation policy
statespace exploration technique
BPMN case study
business process management
model-driven software engineering
Context modeling
Logic gates
Generators
Computational modeling
Context
Labeling
Space exploration},
   ISBN = {1943-6106},
   DOI = {10.1109/VLHCC.2011.6070373},
   year = {2011},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Abdulrab, H. and Babkin, E. and Satunin, S.},
   title = {A hybrid multi-layered approach to demand responsive transport systems modeling},
   booktitle = {2010 5th International Conference on System of Systems Engineering},
   pages = {1-6},
   abstract = {The paper discusses a system of systems multi-paradigm approach to the modeling of Demand Responsive Transport systems. It contains a brief overview of issues which appear during modeling of such systems, considers various multi-agent architectures and describes some algorithms which can be used for modeling. Also the paper provides some details about previous investigations on this topic, in particular: a centralized model based on combinatorial auctions and a multi-agent based multilayer distributed hybrid model. The aim of the paper is working out a sound solution based on a combination of these two approaches which would utilize a system of systems approach where layered architecture would help to deal with real-time issues and increase system's reliability and combinatorial auctions would help with global search of the optimal solution. Such combination improves the efficiency and reliability of the system.},
   keywords = {combinatorial mathematics
multi-agent systems
optimisation
real-time systems
transportation
hybrid multilayered approach
demand responsive transport systems modeling
multi-agent architectures
combinatorial auctions
multilayer distributed hybrid model
real-time issues
optimal solution
Modeling
Conferences
IEEE catalog
Permission
Advertising
Demand Responsive Transport
System of Systems Engineering},
   DOI = {10.1109/SYSOSE.2010.5543956},
   year = {2010},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Adeli, H.},
   title = {Inventing the future of neurology: Integrated wavelet-chaos-neural network models for knowledge discovery and automated EEG-based diagnosis of neurological disorders},
   booktitle = {2008 IEEE International Conference on Information Reuse and Integration},
   pages = {x-xi},
   abstract = {The author has been advancing a multi-paradigm integrated approach for solution of complicated and intractable dynamic pattern recognition problems. The focus of this keynote lecture is data mining and knowledge discovery from time-series signals obtained from complex phenomena. Novel wavelet-chaos-neural network models are presented for signal processing of brain waves as recorded by electroencephalographs (EEGs) for automated EEG-based diagnosis of neurological disorders such as epilepsy and the Alzheimer’s disease (AD). Through extensive parametric studies and information reuse and integration certain combinations of parameters from the EEG sub-bands were discovered to be effective markers for seizure detection and epilepsy diagnosis. The model can distinguish among healthy, interictal, and ictal EEGs with a high accuracy of more than 96% substantially better than practicing neurologists and epileptologists. The extension the methodology for early onset diagnosis of the AD will be delineated.},
   DOI = {10.1109/IRI.2008.4582990},
   year = {2008},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Adeli, H. and Lichtenstein, A. G.},
   title = {Automated EEG-based diagnosis of the neurological and psychiatric disorders},
   booktitle = {2011 18th International Conference on Systems, Signals and Image Processing},
   pages = {1-4},
   abstract = {In this keynote lecture the author presents a research ideology, a novel multi-paradigm methodology, and advanced computational models for automated electroencephalogram (EEG)-based diagnosis of neurological and psychiatric disorders. The methodology is based on integration of three different computing technologies and problem solving paradigms: neural networks, wavelets, and the chaos theory. Examples of the research performed by the authors and his associates for automated diagnosis of epilepsy, the Alzheimer's Disease, Attention Deficit Hyperactivity Disorder (ADHD), and Autism Spectrum Disorder (ASD) are discussed.},
   keywords = {chaos
electroencephalography
medical signal processing
neural nets
neurophysiology
psychology
wavelet transforms
automated EEG based diagnosis
neurological disorders
psychiatric disorders
multiparadigm methodology
advanced computational models
electroencephalogram
problem solving paradigms
neural networks
chaos theory
epilepsy
Alzheimer disease
attention deficit hyperactivity disorder
ADHD
autism spectrum disorder
ASD
Brain models
Alzheimer's disease
Computational modeling
Synchronization},
   ISBN = {2157-8702},    year = {2011},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Ahmed, Z. and Zeeshan, S. and Liang, B. T.},
   title = {PAS-SNP: iOS App with GWAS SNP-Disease Database for Personalized Genomics Research: PAS-SNP for GWAS SNP-Disease},
   booktitle = {2019 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)},
   pages = {1962-1969},
   abstract = {To efficiently fathom the wealth of genomics and clinical data, there is a crucial need to generate appropriate gene-disease annotation repositories accessed through modern resources. Our focus was to create a comprehensive database with mobile access to authentic Single Nucleotide Polymorphisms (SNPs) and classified diseases worldwide, considered as the foundation for clinical and genomics research, epidemiology and precision medicine. In this manuscript, we present non-profit, academic and publicly available iOS application, PAS-SNP, which invites global users to freely download it on iPhone & iPad devices, effortlessly adopt it's easy to use interface and search for SNPs, genes and related diseases. PAS-SNP is developed with Swift multi-paradigm programming language, XCODE integrated development environment for MacOS, and PHP scripting that uses a MySQL server database, which includes over 67,000 SNPs reported for over 19,000 genes, from patients located in over 1000 regions, published in over 3000 articles in over 415 journals available at the PubMed, and over 100,000 classified SNP-disease combinations. It includes SNPs released and organized by the Genome-wide Association Study (GWAS). PAS-SNP is founded on the clinical and scientific premise to support and promote healthcare and genomics data sharing with technological advancements.},
   keywords = {data mining
diseases
genetics
genomics
iOS (operating system)
medical computing
medical information systems
mobile computing
molecular biophysics
PAS-SNP
GWAS SNP-disease database
personalized genomics research
gene-disease annotation repositories
epidemiology
precision medicine
related diseases
SNP-disease combinations
iOS application
Swift multiparadigm programming language
XCODE integrated development environment
MacOS
PHP scripting
MySQL server database
Genome-wide Association Study
GWAS
Disease
Germline
SNP
iOS-App},
   DOI = {10.1109/BIBM47256.2019.8983389},
   year = {2019},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Alagao, S. P. L. and Alolino, J. Y. and Ybañez, M. K. R. and Rubio, E. M. D. and Caya, M. V. C.},
   title = {Wireless Electric Consumption Acquisition Using Image Processing},
   booktitle = {2018 IEEE 10th International Conference on Humanoid, Nanotechnology, Information Technology,Communication and Control, Environment and Management (HNICEM)},
   pages = {1-6},
   abstract = {In this study, the goal is to conduct and develop a system that will transmit electric consumption reading using wireless technology and analyzing the data with the use of image processing. The researcher created a wireless transmission of data acquisition using Raspberry Pi which aimed to make the meter reading more convenient and faster. The process starts by capturing the image of the electric meter using Raspberry Pi cam. The software use is python a powerful multi-paradigm computer programming language, optimized for programmer productivity, code readability and software quality [1]. The picture will be saved in a local folder and then using image processing it will analyze the picture. After analyzing, the result will be sent to the database. The database used in the system is SQL (Structured Query Language the standard programming language to create, update, and retrieve information that is stored in the database [2]. The information stored in the database are the following, data of electric consumption, the time retrieved and account number of the consumer. For the GUI design of the software visual basic studio is use. Programming using this language has also been made easier by using visual tools provided by Visual Studio [3]. Based on the result of the data gathered the study was found out to be effective regarding reading the electric consumption since it produces a rating of above 90% accuracy during functionality test.},
   keywords = {data acquisition
data analysis
graphical user interfaces
image capture
image processing
power consumption
power system measurement
Python
software quality
SQL
Visual BASIC
wireless electric consumption acquisition
wireless transmission
Raspberry Pi cam
multiparadigm computer programming language
code readability
picture analysis
electric meter image capture
electric consumption reading
programmer productivity
structured query language
database
software visual basic studio GUI design
visual tools
Meters
Cameras
Databases
Image edge detection
Hardware
Wireless
Raspberry Pi
GUI},
   DOI = {10.1109/HNICEM.2018.8666324},
   year = {2018},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Albert, E. and Puebla, G. and Hermenegildo, M.},
   title = {Experiments in abstract interpretation-based code certification for pervasive systems},
   booktitle = {2004 IEEE International Conference on Systems, Man and Cybernetics (IEEE Cat. No.04CH37583)},
   volume = {2},
   pages = {1125-1130 vol.2},
   abstract = {Proof-carrying code (PCC) is a general methodology for certifying that the execution of a untrusted mobile code is safe. The basic idea is that the code supplier attaches a certificate to the mobile code which the consumer checks in order to ensure that the code is indeed safe. The potential benefit is that the consumer's task is reduced from the level of proving to the level of checking. Recently, the abstract interpretation techniques developed in logic programming have been proposed as a basis for PCC. This extended abstract reports on experiments which illustrate several issues involved in abstract interpretation-based certification. First, we describe the implementation of our system in the context of CiaoPP: the preprocessor of the Ciao multi-paradigm programming system. Then, by means of some experiments, we show how code certification is aided in the implementation of the framework. Finally, we discuss the application of our method within the area of pervasive systems.},
   keywords = {certification
ubiquitous computing
distributed programming
logic programming
abstract interpretation-based code certification
pervasive systems
proof-carrying code
untrusted mobile code
CiaoPP
Ciao multi-paradigm programming system
Safety
Packaging
Inspection
Automation
Power generation
Algorithm design and analysis
Costs},
   ISBN = {1062-922X},
   DOI = {10.1109/ICSMC.2004.1399773},
   year = {2004},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Alloush, I. and Aoun, C. G. and Kermarrec, Y. and Rouvrais, S.},
   title = {A Domain-Specific Framework for Creating Early Trusted Underwater Systems Relying on Enterprise Architecture},
   booktitle = {2014 IEEE 22nd International Symposium on Modelling, Analysis & Simulation of Computer and Telecommunication Systems},
   pages = {120-125},
   abstract = {Service Creation Environments facilitate the creation of complex services and play a major role in the software industry. In this context, we aim at developing a domain-specific framework (networking domain) that uses a chain of existing "off-the-shelf" tools that are integrated together from the design phase to the verification activities. In this paper, we propose a new meta-model that extends ArchiMate to provide a domain-specific modeling language concerning the Deep Sea Observatories (DSO). We instantiate, as a case study, DSO model with identification and localization functions from this language, and apply it to our framework that relies on an IMS platform to evaluate the service model. These functions can be orchestrated with other services (e.g. military or civil reaction) or interconnected with other SO Systems. On the one hand, this illustrates our approach in relying on Enterprise Architecture (EA) framework that respects: multiple-views, perspectives of stakeholders, and domain specificities. On the other hand, it shows the reusability of our framework by changing applications from different domains: Video Conference as a Telecom Service, and Localizations for DSO.},
   keywords = {DP industry
marine engineering
service-oriented architecture
software houses
early trusted underwater systems
enterprise architecture
service creation environments
complex services
software industry
off-the-shelf tools
ArchiMate
domain-specific modeling language
deep sea observatories
DSO
identification and localization functions
video conference
telecom service
Business
Sensors
Analytical models
Context
Computer architecture
Syntactics
Data models
Model Driven Engineering
Network Simulation
Distributed Systems
MeDON
Data Fusion
Object Localization},
   ISBN = {2375-0227},
   DOI = {10.1109/MASCOTS.2014.23},
   year = {2014},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Ambika, P. and Samath, J. A.},
   title = {Visual query exploration process and generation of voluminous Image database for CBIR Systems},
   booktitle = {2012 Third International Conference on Computing, Communication and Networking Technologies (ICCCNT'12)},
   pages = {1-7},
   abstract = {Content Based Image Retrieval is an approach for retrieving semantically-relevant images from an image database based on automatically-derived image features. Image retrieval is the process of browsing, searching and retrieving images from a large database of digital images. The collection of images in the web are growing larger and becoming more diverse. Retrieving images from such large collections and constructing an image database for CBIR systems are challenging problem. In this paper we have addressed a functional way to construct database for CBIR systems using multi-paradigm functional programming language. Schematic Representation of the database structure for the Content-Based Image Retrieval (CBIR) system can also be discussed. Visual exploration system enables users to search, browse and explore multimedia databases in an interactive and playful manner. We propose a query evaluation scheme to reduce the total number of similarity computations.},
   keywords = {content-based retrieval
image retrieval
interactive systems
multimedia databases
visual databases
visual query exploration process
voluminous image database
CBIR system
content based image retrieval
semantically-relevant image retrieval
automatically-derived image feature
image browsing
image searching
digital image
image collection
multiparadigm functional programming language
schematic representation
database structure
visual exploration system
multimedia database
interactive system
query evaluation
similarity computation
Databases
Image color analysis
Solid modeling
Visualization
CBIR - Content Based Image Retrieval
similarity visualization
visual exploration
DB description
F#},
   DOI = {10.1109/ICCCNT.2012.6395917},
   year = {2012},
   type = {Conference Proceedings}
}

@article{
   author = {Amelunxen, C. and Schurr, A.},
   title = {Formalising model transformation rules for UML/MOF 2},
   journal = {IET Software},
   journalAlt = {IET Software},
   volume = {2},
   number = {3},
   pages = {204-222},
   abstract = {Model-driven software development, today's state-of-the-art approach to the design of software, can be applied in various domains and thus demands a variety of domain-specific modelling languages. The specification of a domain-specific modelling language's syntax and semantics can in turn be specified based on models, which represent the approach of metamodelling as a special form of language engineering. The latest version of the unified modelling language 2 (UML 2) and its subset the meta object facility 2 (MOF 2) provide sufficient support for metamodelling, a modelling language's abstract syntax. Furthermore, based on the description of the abstract syntax, a language's static semantics can simply be specified by the object constraint language (OCL) as UML/MOF's natural constraint language, whereas the description of an MOF compliant language's dynamic semantics is still not covered. The authors try to close this gap by integrating MOF/OCL with graph transformations for the specification of dynamic aspects of modelling languages and tools. The formalisation of such an integration is non-trivial because of the fact that UML/MOF 2 offer a rather unusual and sophisticated association concept (graph model). Although there are many approaches, which formalise graph transformations in general and first approaches that offer a precise specification of the semantics of the association concepts of UML/MOF 2, there is still a lack in bringing both together. Here, the authors close this gap by formalising graph transformations that work on a UML/MOF 2 compatible graph model.},
   keywords = {computational linguistics
formal specification
graph theory
Unified Modeling Language
model-driven software development
UML
domain-specific modelling language syntax
domain-specific modelling language semantics
Unified Modelling Language
object constraint language
graph transformation
meta object facility 2},
   ISSN = {1751-8814},
   DOI = {10.1049/iet-sen:20070076},
   year = {2008},
   type = {Journal Article}
}

@inproceedings{
   author = {Amor, M. and Garcia, A. and Fuentes, L.},
   title = {AGOL: An Aspect-Oriented Domain-Specific Language for MAS},
   booktitle = {Early Aspects at ICSE: Workshops in Aspect-Oriented Requirements Engineering and Architecture Design (EARLYASPECTS'07)},
   pages = {4-4},
   abstract = {Specific features of multi-agent systems (MAS), such as autonomy, learning, mobility, coordination, are driving development concerns, which make evident the need for new design abstractions. Up to now, agent-oriented modeling languages have delivered basic MAS design abstractions - such as goals and actions - that explicitly tackle some of these concerns. However, the modularization of a plethora of fundamental MAS features has been hindered throughout the software lifecycle. This paper presents a methodological framework to address enhanced modularity and traceability of such crosscutting concerns in MAS development. Our design framework is mainly rooted at the proposition of a new domain-specific language, called AGOL. In addition, the proposed framework is supported by a bench of transformation rules of AGOL artifacts, which can be effectively used to derive agent implementations in two concrete aspect-oriented implementation platforms, namely AspectT and Malaca.},
   keywords = {multi-agent systems
object-oriented languages
object-oriented programming
aspect-oriented domain-specific language
design abstractions
agent-oriented modeling languages
software lifecycle
AGOL
AspectT
Malaca
Domain specific languages
Multiagent systems
Software engineering
DSL
Concrete
Software agents
Specification languages
Electric breakdown
Software maintenance
Software reusability},
   DOI = {10.1109/EARLYASPECTS.2007.3},
   year = {2007},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Amrani, M. and Blouin, D. and Heinrich, R. and Rensink, A. and Vangheluwe, H. and Wortmann, A.},
   title = {Towards a Formal Specification of Multi-paradigm Modelling},
   booktitle = {2019 ACM/IEEE 22nd International Conference on Model Driven Engineering Languages and Systems Companion (MODELS-C)},
   pages = {419-424},
   abstract = {The notion of a programming paradigm is used to classify programming languages and their accompanying workflows based on their salient features. Similarly, the notion of a modelling paradigm can be used to characterise the plethora of modelling approaches used to engineer complex Cyber-Physical Systems (CPS). Modelling paradigms encompass formalisms, abstractions, workflows and supporting tool(chain) s. A precise definition of this modelling paradigm notion is lacking however. Such a definition will increase insight, will allow for formal reasoning about the consistency of modelling frameworks and may serve as the basis for the construction of new modelling, simulation, verification, synthesis, ...environments to support design of CPS . We present a formal framework aimed at capturing the notion of modelling paradigm, as a first step towards a comprehensive formalisation of multi-paradigm modelling. Our formalisation is illustrated by CookieCAD, a simple Computer-Aided Design paradigm used in the development of cookie stencils.},
   keywords = {CAD
cyber-physical systems
formal specification
reasoning about programs
modelling frameworks
formal framework
multiparadigm modelling
programming paradigm
complex cyber-physical systems
formal reasoning
computer-aided design paradigm
CookieCAD
cookie stencils
Model Driven Engineering
Multi Paradigm
Cyber Physical Systems
Formalisation},
   DOI = {10.1109/MODELS-C.2019.00067},
   year = {2019},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Amstel, M. F. v. and Brand, M. G. J. van den and Engelen, L. J. P.},
   title = {Using a DSL and Fine-Grained Model Transformations to Explore the Boundaries of Model Verification},
   booktitle = {2011 Fifth International Conference on Secure Software Integration and Reliability Improvement - Companion},
   pages = {120-127},
   abstract = {Traditionally, the state-space explosion problem in model checking is handled by applying abstractions and simplifications to the model that needs to be verified. In this paper, we propose a model-driven engineering approach that works the other way around. Instead of making a concrete model more abstract, we propose to refine an abstract model to make it more concrete. We propose to use fine-grained model transformations to enable model checking of models that are as close to the implementation model as possible. We applied our approach in a case study. The results show that it is possible to validate models that are more concrete when fine-grained transformations are applied.},
   keywords = {formal verification
software engineering
DSL
fine grained model transformation
model verification boundaries
state space explosion problem
model driven engineering approach
fine grained transformation
model checking
Concrete
Transforms
Semantics
Delay
Reliability
Space exploration
Model-Driven Engineering
Model Transformation
Domain-Specific Language
Verification},
   DOI = {10.1109/SSIRI-C.2011.26},
   year = {2011},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Andrén, F. P. and Strasser, T. and Kastner, W.},
   title = {Applying the SGAM methodology for rapid prototyping of smart Grid applications},
   booktitle = {IECON 2016 - 42nd Annual Conference of the IEEE Industrial Electronics Society},
   pages = {3812-3818},
   abstract = {In order to handle the increasing complexity of smart grid systems, detailed use case and requirements engineering has become indispensable. For this purpose the Smart Grid Reference Architecture Model (SGAM) has emerged as the major methodology. This paper presents a textual Domain Specific Language (DSL) based on SGAM, optimized for rapid prototyping of smart grid applications using a model-driven engineering approach with automatic code generation. The goal of this approach is to support the development process of smart Grid applications, from use case description to implementation. The paper presents a use case described by the DSL and shows how an IEC 61499 control application and an IEC 61850 communication configuration can be automatically generated.},
   keywords = {power system simulation
rapid prototyping (industrial)
smart power grids
specification languages
smart grid reference architecture model
SGAM
textual domain specific language
textual DSL
rapid prototyping
model-driven engineering approach
automatic code generation
IEC 61499 control application
IEC 61850 communication configuration
Unified modeling language
Smart grids
DSL
Automation
IEC Standards
Business
Computational modeling},
   DOI = {10.1109/IECON.2016.7794057},
   year = {2016},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Angyal, L. and Lengyel, L. and Charaf, H.},
   title = {A Synchronizing Technique for Syntactic Model-Code Round-Trip Engineering},
   booktitle = {15th Annual IEEE International Conference and Workshop on the Engineering of Computer Based Systems (ecbs 2008)},
   pages = {463-472},
   abstract = {The introduction of UML class diagrams has not raised the abstraction level of development to the extent that was intended: class diagrams are only the visual representations of source class skeletons implemented in a programming language. To improve the productivity, domain-specific languages are applied, which cover a narrow domain, and their high abstraction makes use of the domain experts easier. The simultaneous evolution of the source code and the software models causes the loss of synchronization. Round-tripping the domain-specific models is not supported by model-driven development tools, because the abstraction gap between the models and the generated code prevents the use of general approaches. However, developers should have the opportunity of choosing between the artifacts that are more efficient for applying the modifications. This paper introduces how different tools achieve the preservation of manually written code while the model is evolving. In contrast, we present our approach that allows the customization of the generated code. The abstraction gap is closed by performing model transformations and an incremental merge.},
   keywords = {programming languages
software engineering
software tools
Unified Modeling Language
syntactic model-code round-trip engineering
UML class diagrams
visual representations
programming language
model-driven development tools
abstraction gap
Skeleton
Productivity
Domain specific languages
Metamodeling
Microwave integrated circuits
Conferences
Computer languages
Merging
Proposals
Domain-Specific Models
Model-Driven Development
Three-way AST Differencing
AST Merging
Model-Code Synchronization},
   DOI = {10.1109/ECBS.2008.33},
   year = {2008},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Aouadj, M. and Desprats, T. and Lavinal, E. and Sibilla, M.},
   title = {AMSDL: A declarative language for adaptive monitoring control},
   booktitle = {2015 IFIP/IEEE International Symposium on Integrated Network Management (IM)},
   pages = {850-853},
   abstract = {More and more requirements are given on the ability to precisely control at run time the achievement of a network and communicating systems monitoring activity. This paper gives an overview of AMSDL (Adaptive Monitoring Strategy Description Language), which is a language under development dedicated at the expression of adaptive monitoring strategies. AMSDL will provide both the network managers and the software developers of autonomic modules with the capacity to easily declare, more than the resources to be managed, the logics that will govern the dynamic monitoring behavior according to the variations of functional, informational and operational requirements.},
   keywords = {computerised monitoring
specification languages
AMSDL
declarative language
adaptive monitoring control
adaptive monitoring strategy description language
dynamic monitoring behavior
Monitoring
DSL
Java
Syntactics
Adaptive systems
Generators
Engines
adaptive monitoring
domain specific language
policy-based management},
   ISBN = {1573-0077},
   DOI = {10.1109/INM.2015.7140392},
   year = {2015},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Aoun, C. G. and Alloush, I. and kermarrec, Y. and Champeau, J. and Zein, O. K.},
   title = {A mapping approach for Marine Observatory relying on enterprise architecture},
   booktitle = {OCEANS 2015 - MTS/IEEE Washington},
   pages = {1-10},
   abstract = {UnderWater Sensor Networks (UW-SNs) performs collaborative monitoring tasks over an underwater determined area. These tasks could be underwater or deep sea observatories. Acoustic sensors (Hydrophones) are responsible to acquire the data underwater then transfer it to components/devices. Marine Observatory (MO) is the scenario of data exchanged between the different components/devices of the Underwater Acoustic Sensor Networks (UW-ASNs). Hence, the MO infrastructure could be based on an (UW-ASNs). This observation should take into consideration the environmental constraints since it may require specific tools, materials and devices (marines cables, specific servers and routers, etc.). The logical and physical components that are used in these observatories supply interchange procedures between the various devices of the environment (Smart Sensors, Data Fusion Servers). These components provide new services due to the long period running of the network. In this paper, we present our extended MetaModel that is used to generate a new design tool (ArchiMO). Thus, we propose a mapping approach between the layers of the enterprise architecture standard. This approach throws instantly domain-specific concepts and constraints in layers on run-time design activity according to a satisfaction of a certain criteria/constraints. We illustrate our proposal with an underwater object localization example from the MO domain. Additionally, we generate the corresponding simulation code for a standard network simulator using our self-developed domain-specific model compiler. Our approach helps to manage the complexity, and to reduce the time of the entire development life cycle of an MO information system. It supplies in the MO context, a way to share the different viewpoints of the designers.},
   keywords = {environmental monitoring (geophysics)
hydrophones
oceanographic techniques
underwater acoustic communication
wireless sensor networks
marine observatory
MO information system
enterprise architecture
collaborative monitoring tasks
underwater observatories
deep sea observatories
acoustic sensors
underwater acoustic sensor networks
UW-ASN
MetaModel
ArchiMO design tool
underwater object localization
self-developed domain-specific model compiler
Design tools
Servers
Complexity theory
Observatories
Information systems
Software
Context
Smart Sensors
Data Fusion
ArchiMate
Meta-Model
Model Driven Engineers
Models
Simulation
Domain Specific Modeling Language},
   DOI = {10.23919/OCEANS.2015.7404633},
   year = {2015},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Averna, G. and Fulantelli, G. and Lenzitti, B. and Taibi, D. and Tegolo, D.},
   title = {A visual framework to support collaborative coding activities},
   booktitle = {2019 29th Annual Conference of the European Association for Education in Electrical and Information Engineering (EAEEIE)},
   pages = {1-6},
   abstract = {In this paper, we present a framework named SIRENE, a Web-based visual programming environment, where teachers and students can collaboratively interact, using a flexible and versatile definition of visual programming code instead of pre-established rules. After the description of the architecture of the SIRENE framework, the preliminary results of a pilot trial with secondary school students will be presented; these results will lead to the final remarks and directions for further developments.},
   keywords = {computer aided instruction
groupware
Internet
visual programming
visual framework
collaborative coding activities
Web-based visual programming environment
SIRENE framework
secondary school students
Visual programming framework
Multiparadigm languages
collaborative online programming
coding},
   ISBN = {2472-7687},
   DOI = {10.1109/EAEEIE46886.2019.9000432},
   year = {2019},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Bajaj, M. and Zwemer, D. and Peak, R. and Phung, A. and Scott, A. G. and Wilson, M.},
   title = {SLIM: collaborative model-based systems engineering workspace for next-generation complex systems},
   booktitle = {2011 Aerospace Conference},
   pages = {1-15},
   abstract = {Development of complex systems is a collaborative effort spanning disciplines, teams, processes, software tools, and modeling formalisms. It is the vision of model-based systems engineering (MBSE) to enable a consistent, coherent, interoperable, and evolving model of a system throughout its lifecycle. However, no currently available modeling language can represent all aspects of a system (including system-of-systems) at all levels of abstraction across the lifecycle.},
   keywords = {computer aided software engineering
formal verification
groupware
large-scale systems
open systems
software development management
systems engineering
collaborative model based system engineering
next generation complex system
software tools
SLIM
system lifecycle management
front-end conceptual abstraction
discipline specific model
plug-and-play
seamless interoperability
domain specific model
commercial-off-the-shelf tools
requirement verification
system simulation
risk analysis
change management
system development
conceptual architecture
SysML based analysis tool
SysML based integration tool
Solid modeling
Analytical models
Mathematical model
System analysis and design
Computational modeling},
   ISBN = {1095-323X},
   DOI = {10.1109/AERO.2011.5747539},
   year = {2011},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Bajwa, I. S. and Bordbar, B. and Anastasakis, K. and Lee, M.},
   title = {On a chain of transformations for generating alloy from NL constraints},
   booktitle = {Seventh International Conference on Digital Information Management (ICDIM 2012)},
   pages = {93-98},
   abstract = {Multi-Paradigm Modelling uses models from multiple domains to leverage the tools, techniques and expertise provided by each of the individual domains. Recent advances in model transformation technology allow automated production of one model from another to improve the application of multi-paradigm techniques. Systems development starts with the requirements gathering phase, which usually comprises of a textual description of the system requirements provided in Natural Language (NL). It is therefore evident that there is a clear scope for incorporating NL Processing techniques in Multi-Paradigm Modeling. However, using NLP methods pushes the boundaries of Multi-Paradigm Modeling to an extreme; indeed NLs are inherently ambiguous and open to interpretation. In this paper, we propose a novel approach based on standards (such as SBVR) that can cope with syntactic and semantic ambiguities in NL specifications and can map them to formal languages such as Alloy. The tool implementing our approach is currently the only available tool for translating NL specifications to formal languages such as Alloy, etc.},
   keywords = {formal languages
formal specification
language translation
natural language processing
transformations
Alloy generation
NL constraints
multiparadigm modelling
model transformation technology
automated production
multiparadigm techniques
systems development
textual description
system requirements
multiparadigm modeling
SBVR
syntactic ambiguities
semantic ambiguities
NL specifications
Unified modeling language
Metals
Semantics
Syntactics
Analytical models
Natural languages
Object oriented modeling
UML
Alloy
Natural Language
NL2OCL},
   DOI = {10.1109/ICDIM.2012.6360153},
   year = {2012},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Bao, S. and Porter, J. and Gokhale, A.},
   title = {Reasoning for CPS Education Using Surrogate Simulation Models},
   booktitle = {2016 IEEE 40th Annual Computer Software and Applications Conference (COMPSAC)},
   volume = {1},
   pages = {764-773},
   abstract = {With developing an affordable, easily accessible and scalable online CPS laboratory to promote CPS education system, we are faced with and focused on a number of cyber-physical challenges including the model design and simulation strategies. The authors provide a complete process to simulate a behavior of a user-design CPS conveyor system. The user-design model is sent to the background, treated offline, and extracted the simulation result and finally feedback to user as an animation. The solution approach has two main parts, as the aspect of the modeling work, complex domain-specific conveyor design are defined in the Generic Modeling Environment (GME), it can be mapped and transformed to the global grid, another domain-specific model, which contains only one kind of node with huge dimension so that all different species of components in complex model are mapped to the typical nodes in grid, and it is easy to operate and simulate the nodes in global grid to fit for the need when multiple experiments being mapped to the grid. In this work, we only concerned the scenario of one experiment. The transformation and mapping process is implemented through Graph Rewriting and Transformation. As a background simulation, the Robocodes code is automatically generated by GME interpreter from global grid and is applied to generate the path logic to transmit the package, according to the package type in each input ports. After acquiring the transmit speed and path, Robocode simulation outputs the coordinate and time information to generate the Java animation. The final Java animation will be feedback to the user side to see the result of package transmission flow.},
   keywords = {computer aided instruction
computer animation
computer science education
cyber-physical systems
graph grammars
Java
rewriting systems
CPS education
surrogate simulation model
scalable online CPS laboratory
user-design CPS conveyor system
complex domain-specific conveyor design
generic modeling environment
graph rewriting
cyber physical system
Java animation
GME interpreter
Robocodes code
graph transformation
Unified modeling language
Computational modeling
Education
Belts
Mathematical model
Software
Animation
Domain-specific modeling
The Generic Modeling Environment
Graph Rewriting and Transformation
Robocode},
   ISBN = {0730-3157},
   DOI = {10.1109/COMPSAC.2016.175},
   year = {2016},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Barreto, L. P. and Muller, G.},
   title = {Bossa: a DSL framework for application-specific scheduling policies},
   booktitle = {Proceedings Eighth Workshop on Hot Topics in Operating Systems},
   pages = {161},
   abstract = {We present a framework for easing the development of adaptable process scheduling infrastructures. This framework permits the development and installation of basic scheduling policies, which can be specialized using application-specific policies. We base our approach on a Domain-Specific Language (DSL) named Bossa. A DSL is a high-level language that provides appropriate abstractions, which captures domain expertise and eases program development. Implementing an OS using a DSL improves OS robustness because code becomes more readable, maintainable and more amenable to verification of properties. Our target is to specialize process schedulers for an application with soft-real time requirements that is able to specify adequate regulation strategies for its CPU requirements.},
   keywords = {operating systems (computers)
high level languages
programming environments
adaptable process scheduling infrastructures
application-specific policies
Bossa domain-specific language
high-level language
domain expertise
program development
process schedulers
soft-real time requirements
CPU requirements
DSL
Application specific processors
Processor scheduling
Kernel
Robustness
Domain specific languages
Variable structure systems
World Wide Web
Computer applications
Power system modeling},
   DOI = {10.1109/HOTOS.2001.990077},
   year = {2001},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Bartelt, C.},
   title = {Conflict Analysis at Collaborative Development of Domain Specific Models using Description Logics},
   booktitle = {2011 44th Hawaii International Conference on System Sciences},
   pages = {1-9},
   abstract = {Today the distribution of development locations, the co-evolution of models and the concurrency of work are typical for collaborative modeling in software projects. Software engineering teams demand modeling techniques at several abstraction levels to manage the complexity of software descriptions. Besides, software models are applied more and more for the specification of safety-critical systems. Hence software models take a hybrid role - as a matter of team communication and precise specification for refinement. Both aspects are considered in the research area of Model Driven Engineering (MDE). It provides methods to deal with formal specified meta-models of graphical (intuitive) modeling languages. Unfortunately the syntactical a semantically correct (consistent) integration of concurrently evolved models is poorly considered by the most MDE approaches. Especially the detection and analyzing of model merge conflicts can be automatized by using logical inference techniques. Therefore this paper proposes an approach based on description logics.},
   keywords = {safety-critical software
software development management
systems analysis
conflict analysis
collaborative development
domain specific models
description logics
work concurrency
software projects
software engineering teams
abstraction levels
software description complexity
safety-critical systems
model driven engineering
graphical modeling languages
intuitive modeling languages
Conferences
Complexity theory
Software engineering
Collaboration
Analytical models},
   ISBN = {1530-1605},
   DOI = {10.1109/HICSS.2011.126},
   year = {2011},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Basciani, F. and Rocco, J. d. and Ruscio, D. d. and Iovino, L. and Pierantonio, A.},
   title = {A Customizable Approach for the Automated Quality Assessment of Modelling Artifacts},
   booktitle = {2016 10th International Conference on the Quality of Information and Communications Technology (QUATIC)},
   pages = {88-93},
   abstract = {In Model-Driven Engineering (MDE) giving a precise definition of quality models, identifying which quality attributes are of interest for specific stakeholders, and how relating and aggregating together quality attributes are still open issues. The main limitations of currently available quality approaches are limited extensibility, artifact specificity, and manual assessment. This paper proposes an approach supporting the definition of custom quality models consisting of hierarchically organized quality attributes whose evaluation depends on metrics specifically conceived and applied on the modeling artifacts to be analysed. A domain specific language is proposed to specify how quality attributes and metrics have to be aggregated. An execution environment is also provided to apply the defined quality models on actual modeling artifacts so to enable their automated quality assessment. Real applications of the approach are presented by defining and applying explanatory quality models suitably conceived to assess the quality of metamodels and transformations retrieved from public repositories.},
   keywords = {software metrics
software quality
modelling artifacts quality assessment
model-driven engineering
MDE
quality attributes
quality approach
domain specific language
quality metrics
Measurement
Quality assessment
Object oriented modeling
Engines
Computational modeling
Model driven engineering
Model Quality
Artefact Quality},
   DOI = {10.1109/QUATIC.2016.025},
   year = {2016},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Behalek, M. and Šaloun, P.},
   title = {Simulation of Embedded Applications Implemented in Embedded Process Functional Language},
   booktitle = {2009 International Conference on Computational Intelligence, Modelling and Simulation},
   pages = {253-258},
   abstract = {Functional programming paradigm is very attractive for implementation of embedded systems. Process functional language can be very useful from this perspective. Process functional language was developed to integrate good properties of functional and imperative languages. We have created a language mutation called Embedded process functional language designed for implementation of embedded applications. An emulator simulating embedded process functional programs is needed for purpose of development and also for debugging. This paper aims on developed emulator and created embedded process functional language.},
   keywords = {embedded systems
functional languages
functional programming
program debugging
embedded process functional language
embedded system
imperative language
language mutation
program emulator
Computational modeling
Debugging
Application software
Computer science
Computer simulation
Genetic mutations
Hardware
Logic programming
embedded applications
Embedded process functional language (e-PFL)
domain specific language},
   ISBN = {2166-8531},
   DOI = {10.1109/CSSim.2009.11},
   year = {2009},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Bennett, M. and Borgen, R. and Havelund, K. and Ingham, M. and Wagner, D.},
   title = {Development of a Prototype Domain-Specific Language for Monitor and Control Systems},
   booktitle = {2008 IEEE Aerospace Conference},
   pages = {1-18},
   abstract = {This paper describes the domain-specific language (DSL) prototype developed for the NASA constellation launch control system (LCS) project. A key element of the LCS architecture, the DSL prototype is a specialized monitor and control language composed of constructs for specifying and programming test, checkout, and launch processing applications for flight and ground systems. The principal objectives of the prototyping activity were to perform a proof-of-concept of an approach to ultimately lower the lifecycle costs of application software for the LCS, and to explore mitigations for a number of development risks perceived by the project. The language has been implemented as a library that extends the Python scripting language, and validated in a successful demonstration of capability required for constellation.},
   keywords = {aerospace computing
aerospace control
authoring languages
control engineering computing
prototype domain-specific language
monitor systems
constellation launch control system project
lifecycle costs
Python scripting language
Prototypes
Domain specific languages
Monitoring
Control systems
DSL
Software prototyping
Application software
NASA
System testing
Costs},
   ISBN = {1095-323X},
   DOI = {10.1109/AERO.2008.4526660},
   year = {2008},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Bergstrom, E. and Pandey, R.},
   title = {Composing µSIC: A Lightweight Service Model for Wireless Sensor Networks},
   booktitle = {2007 International Conference on Sensor Technologies and Applications (SENSORCOMM 2007)},
   pages = {475-483},
   abstract = {Although wireless sensor network applications share a common set of limitations (e.g. resource scarcity and lossy radio communication models) a basic set of runtime services (e.g. routing, time synchronization, and code dissemination), applications are often designed in an ad-hoc fashion, reducing the amount of code reuse, making a component-based software engineering approach desirable. We present a micro service component model, entitled muSIC, that abstracts a sensor node as an entity that provides and uses services. This model is realized through the use of the muSIC runtime, a small and efficient message-oriented middleware (MOM) tailored for resource-constrained devices. The muSIC runtime can perform service-paging, a method of storing a service's state to flash memory and restoring it whenever the service is needed. Secondly, we provide a domain-specific language allowing applications to be expressed as a collection of services that run on top of the muSIC runtime and enables a multi-threaded programming model.},
   keywords = {middleware
multi-threading
object-oriented programming
wireless sensor networks
muSIC
component-based software engineering
microservice component model
message-oriented middleware
resource-constrained devices
service paging
multithreaded programming model
Runtime
Application software
Radio communication
Routing
Software engineering
Abstracts
Flash memory
Domain specific languages},
   DOI = {10.1109/SENSORCOMM.2007.4394966},
   year = {2007},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Bezzine, S. and Galtier, V. and Vialle, S. and Baude, F. and Bossy, M. and Doan, V. D. and Henrio, L.},
   title = {A Fault Tolerant and Multi-Paradigm Grid Architecture for Time Constrained Problems. Application to Option Pricing in Finance},
   booktitle = {2006 Second IEEE International Conference on e-Science and Grid Computing (e-Science'06)},
   pages = {49-49},
   abstract = {This paper introduces a Grid software architecture offering fault tolerance, dynamic and aggressive load balancing and two complementary parallel programming paradigms. Experiments with financial applications on a real multi-site Grid assess this solution. This architecture has been designed to run industrial and financial applications, that are frequently time constrained and CPU consuming, feature both tightly and loosely coupled parallelism requiring generic programming paradigm, and adopt client-server business architecture.},
   keywords = {Fault tolerance
Time factors
Pricing
Finance
Application software
Computer architecture
Parallel programming
Software architecture
Dynamic programming
Load management},
   DOI = {10.1109/E-SCIENCE.2006.261133},
   year = {2006},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Blainey, B.},
   title = {Keynote: Domain-specific models for innovation in analytics},
   booktitle = {2014 23rd International Conference on Parallel Architecture and Compilation Techniques (PACT)},
   pages = {301-301},
   abstract = {Big data is a transformational force for businesses and organizations of every stripe. The ability to rapidly and accurately derive insights from massive amounts of data is becoming a critical competitive differentiator so it is driving continuous innovation among business analysts, data scientists, and computer engineers. Two of the most important success factors for analytic techniques are the ability to quickly develop and incrementally evolve them to suit changing business needs and the ability to scale these techniques using parallel computing to process huge collections of data. Unfortunately, these goals are often at odds with each other because innovation at the algorithm and data model level requires a combination of domain knowledge and expertise in data analysis while achieving high scale demands expertise in parallel computing, cloud computing and even hardware acceleration. In this talk, I will examine various approaches to bridging these two goals, with a focus on domain-specific models that simultaneously improve the agility of analytics development and the achievement of efficient parallel scaling.},
   keywords = {Big Data
cloud computing
data analysis
data models
parallel processing
domain-specific models
data analytics
parallel computing
data model level
hardware acceleration
parallel scaling
Software
Hardware
Analytical models
Technological innovation
Acceleration
Business
Application Development
analytics},
   DOI = {10.1145/2628071.26359312},
   year = {2014},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Bock, F. and Sippl, C. and Heinzz, A. and Lauerz, C. and German, R.},
   title = {Advantageous Usage of Textual Domain-Specific Languages for Scenario-Driven Development of Automated Driving Functions},
   booktitle = {2019 IEEE International Systems Conference (SysCon)},
   pages = {1-8},
   abstract = {Current driving functions are continuously improved. As target vision of this development, the final state of unattended reliable navigation under all possible circumstances is defined. Besides the requirements and the test cases, the main accompanying specification artifact for the iterative development of such functions is the scenario catalog, which is usually created by hand. The included scenarios often differ in terms of the used abstraction level, the chosen natural language, and the degree of completeness depending on the current development phase. There is currently no methodology available, which allows the iterative evolution of textual scenario descriptions based on natural language and that can be used for the development of automated driving functions (ADF). As a solution approach, the methodology scenario-accompanied, text-based, iterative Evaluation of automated driving Functions (stiEF) as embedding workflow and an embedded textual domain-specific language (DSL) for scenario creation are presented. The DSL facilitates the iterative multilingual evolution of scenario descriptions and the generation of the corresponding simulation parameters and scenario sketches. For this, scenarios with different levels of detail are used as central specification artifacts. This approach avoids ambiguities in the descriptions, guides the user through their creation process, and ensures completeness. This is demonstrated by a prototypical realization.},
   keywords = {iterative methods
natural language processing
specification languages
traffic engineering computing
textual domain-specific languages
scenario-driven development
automated driving functions
iterative development
scenario catalog
iterative evolution
textual scenario descriptions
embedded textual domain-specific language
scenario creation
iterative multilingual evolution
scenario sketches
central specification artifacts
natural language
iterative evaluation
abstraction level
DSL
Natural languages
Testing
Unified modeling language
Vehicle dynamics
Roads
domain-specific language
automated driving function
scenario description
iterative
generation},
   ISBN = {2472-9647},
   DOI = {10.1109/SYSCON.2019.8836912},
   year = {2019},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Bonnieux, S. and Mosser, S. and Blay-Fornarino, M. and Hello, Y. and Nolet, G.},
   title = {Model driven programming of autonomous floats for multidisciplinary monitoring of the oceans},
   booktitle = {OCEANS 2019 - Marseille},
   pages = {1-10},
   abstract = {Monitoring of the oceans with autonomous floats is of great interest for many disciplines. Monitoring on a global scale needs a multidisciplinary approach to be affordable. For this purpose, we propose an approach that allows oceanographers from different specialities to develop applications for autonomous floats. However, developing such applications usually requires expertise in embedded systems, and they must be reliable and efficient with regards to the limited resources of the floats (e.g., energy, processing power). We have followed a Model Driven Engineering approach composed of i) a Domain Specific Language to allow oceanographers to develop applications, ii) analysis tools to ensure that applications are efficient and reliable, iii) a composition tool to allow the deployment of different applications on a same float, and iv) a code generator that produce efficient and reliable code for the float. We present our approach with a biological and a seismological application. We validate it with technical metrics and an experiment.},
   keywords = {design engineering
embedded systems
formal specification
geophysics computing
object-oriented programming
oceanographic techniques
program compilers
software architecture
specification languages
systems engineering
model driven engineering approach
oceanographers
float
seismological application
autonomous floats
multidisciplinary monitoring
model driven programming
domain specific language
code generator
biological application
Open area test sites
Sensors
Whales
Instruments
Monitoring
Acoustics
Oceans
Model Driven Engineering
embedded system
constrained resources},
   DOI = {10.1109/OCEANSE.2019.8867453},
   year = {2019},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Brambilla, M.},
   title = {Modeling and execution of software user interfaces},
   booktitle = {2015 3rd International Conference on Model-Driven Engineering and Software Development (MODELSWARD)},
   pages = {IS-9},
   abstract = {Summary form only given. Software front-end development is a costly and inefficient process, where manual coding is the predominant development approach, reuse of design artifacts is low, and cross-platform portability remains difficult, despite some trends towards HTML-based templating. In this sense, the availability of a platform-independent modeling language for describing the user interaction can bring several benefits to the development process of user interfaces. This speech focuses on the modeling of software UIs through graphical domain-specific languages and in particular shows the new standard adopted by OMG called IFML (Interaction Flow Modeling Language) at work. The speech illustrates the basic concepts of IFML, presents the design best practices and integration with other modelling languages, and discusses some large-scale industrial experiences (also featuring quantitative measures of productivity) achieved through IFML and associated full code generation techniques.},
   keywords = {human computer interaction
hypermedia markup languages
software portability
user interfaces
software user interface
software front-end development
cross-platform portability
HTML-based templating
modeling language
software UI
domain-specific language
OMG
IFML
interaction flow modeling language
code generation technique
predominant development approach},    year = {2015},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Breuker, D.},
   title = {Towards Model-Driven Engineering for Big Data Analytics -- An Exploratory Analysis of Domain-Specific Languages for Machine Learning},
   booktitle = {2014 47th Hawaii International Conference on System Sciences},
   pages = {758-767},
   abstract = {Graphical models and general purpose inference algorithms are powerful tools for moving from imperative towards declarative specification of machine learning problems. Although graphical models define the principle information necessary to adapt inference algorithms to specific probabilistic models, entirely model-driven development is not yet possible. However, generating executable code from graphical models could have several advantages. It could reduce the skills necessary to implement probabilistic models and may speed up development processes. Both advantages address pressing industry needs. They come along with increased supply of data scientist labor, the demand of which cannot be fulfilled at the moment. To explore the opportunities of model-driven big data analytics, I review the main modeling languages used in machine learning as well as inference algorithms and corresponding software implementations. Gaps hampering direct code generation from graphical models are identified and closed by proposing an initial conceptualization of a domain-specific modeling language.},
   keywords = {Big Data
computer graphics
data analysis
inference mechanisms
learning (artificial intelligence)
program compilers
specification languages
model-driven engineering
big data analytics
domain-specific languages
graphical models
general purpose inference algorithms
machine learning problems
probabilistic models
model-driven development
modeling languages
direct code generation
domain-specific modeling language
Inference algorithms
Computational modeling
Random variables
Unified modeling language
Data models
Adaptation models
Machine Learning},
   ISBN = {1530-1605},
   DOI = {10.1109/HICSS.2014.101},
   year = {2014},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Broeckhoven, F. Van and Troyer, O. De},
   title = {ATTAC-L: A modeling language for educational virtual scenarios in the context of preventing cyber bullying},
   booktitle = {2013 IEEE 2nd International Conference on Serious Games and Applications for Health (SeGAH)},
   pages = {1-8},
   abstract = {Cyber bullying (bullying via electronic communication tools) is a relatively recent phenomenon that especially occurs among early adolescents. As cyber bullying may have a serious impact on the mental (and physical) well-being of victims, it is important to develop effective evidence-based interventions against cyber bullying. The “Friendly ATTAC”-project has the aim to develop so-called virtual interactive scenarios (i.e. digital games) to modify behavior patterns associated with cyber bullying among youngsters. The scenarios will be developed during brainstorming sessions involving people from the different disciplines and with different backgrounds, but specialized in the domain of cyber bullying. To allow this non-technical people to specify the virtual interactive scenarios that should be developed, we have developed a domain specific modeling language that allow them to do so in an intuitive and close to natural language way. This paper presents this language in an informal way.},
   keywords = {human computer interaction
serious games (computing)
simulation languages
specification languages
virtual reality
educational virtual scenario
ATTAC-L
cyber bullying prevention
electronic communication tools
evidence-based interventions
friendly ATTAC-project
virtual interactive scenario
behavior patterns
domain specific modeling language
natural language
serious games
Lifting equipment
Games
cyber bullying
domain specific modeling languages},
   DOI = {10.1109/SeGAH.2013.6665300},
   year = {2013},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Bromberg, Y. and Grace, P. and Réveillère, L.},
   title = {Starlink: Runtime Interoperability between Heterogeneous Middleware Protocols},
   booktitle = {2011 31st International Conference on Distributed Computing Systems},
   pages = {446-455},
   abstract = {Interoperability remains a challenging and growing problem within distributed systems. A range of heterogeneous network and middleware protocols which cannot interact with one another are now widely used, for example, the set of remote method invocation protocols, and the set of service discovery protocols. In environments where systems and services are composed dynamically, e.g. pervasive computing and systems-of-systems, the protocols used by two systems wishing to interact is unknown until runtime and hence interoperability cannot be guaranteed. In such situations, dynamic solutions are required to identify the differences between heterogeneous protocols and generate middleware connectors (or bridges) that will allow the systems to inter operate. In this paper, we present the Starlink middleware, a general framework into which runtime generated interoperability logic (in the form of higher level models) can be deployed to connect two heterogeneous protocols. For this, it provides: i) an abstract representation of network messages with a corresponding generic parser and composer, ii) an engine to execute coloured automata that represent the required interoperability behaviour between protocols, and iii) translation logic to describe the exchange of message content from one protocol to another. We show through case-study based evaluation that Starlink can bridge heterogeneous protocol types. Starlink is also compared against base-line protocol benchmarks to show that acceptable performance can still be achieved in spite of the high-level nature of the solution.},
   keywords = {automata theory
middleware
open systems
protocols
runtime interoperability
heterogeneous middleware protocol
distributed system
heterogeneous network
remote method invocation protocol
service discovery protocol
Starlink middleware
runtime generated interoperability logic
translation logic
abstract representation
coloured automata
Automata
Runtime
Bridges
Color
Semantics
protocol
interoperability
domain specific language},
   ISBN = {1063-6927},
   DOI = {10.1109/ICDCS.2011.65},
   year = {2011},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Bures, T. and Malohlava, M. and Hnetynka, P.},
   title = {Using DSL for Automatic Generation of Software Connectors},
   booktitle = {Seventh International Conference on Composition-Based Software Systems (ICCBSS 2008)},
   pages = {138-147},
   abstract = {Component-based engineering is a recognized paradigm, which models an application as a collection of reusable components. The key idea behind components is that they contain only the business logic and communicate with one another only via well-defined interfaces. The communication paths among components (so called bindings) are in modern component systems realized by software connectors, which allow explicit modeling of communication and also its implementation at runtime. An important aspect of using connectors is the possibility of their automatic generation, which saves a significant amount of development work. However, the generation itself is not a trivial task, since there is a big semantic gap between the abstract specification of a connector at design time and its implementation at runtime. In this paper, we present an approach to generating implementations of software connectors. The approach is based on a new domain specific language for describing templates of connector implementations and a transformation framework using the Strate-go/XT term rewriting system for generating source code of connectors.},
   keywords = {rewriting systems
software reusability
software connectors automatic generation
component-based engineering
reusable components collection
business logic
modern component systems
domain specific language
rewriting system
connectors source code
DSL
Connectors
Application software
Runtime
Computer architecture
Middleware
Network servers
Software systems
Software engineering
composition
interoperability
component
connector
code generation},
   DOI = {10.1109/ICCBSS.2008.17},
   year = {2008},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Café, D. C. and Santos, F. V. dos and Hardebolle, C. and Jacquet, C. and Boulanger, F.},
   title = {Multi-paradigm semantics for simulating SysML models using SystemC-AMS},
   booktitle = {Proceedings of the 2013 Forum on specification and Design Languages (FDL)},
   pages = {1-8},
   abstract = {SysML is an industrial standard for the modeling of systems, providing a graphical way to model structure and behavior. Despite its flexibility, SysML lacks semantics to give language elements a precise meaning. Current implementations of the standard allow multiple interpretations of syntactical elements and can cause misunderstandings when porting a model among tools. Our work focuses on the definition of concrete semantics for SysML to enable correct interpretation of heterogeneous models. We also add semantic adaptation elements to guarantee that interactions among different formalisms are unambiguous. We demonstrate our approach by generating SystemC-AMS code automatically from SysML diagrams for a case study with two distinct formalisms. This kind of translation allows the validation of system behavior through simulation.},
   keywords = {Semantics
Unified modeling language
Adaptation models
Computational modeling
Standards
Engines
Mathematical model
Model Transformation
Semantic Adaptation
System Modeling
System Simulation
SysML
SystemC-AMS},
   ISBN = {1636-9874},    year = {2013},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Cao, Y. and Lu, Q. and Xu, T. and Tang, T. and Wang, H. and Xu, Y.},
   title = {Integrating DSL-CBI and NuSMV for Modeling and Verifiying Interlocking Systems},
   booktitle = {2011 Fifth International Conference on Secure Software Integration and Reliability Improvement - Companion},
   pages = {136-143},
   abstract = {The Computer Based Interlocking System (CBI) is used to ensure safe train movements at a railway station. For a given station, all the train routes and the concrete safety rules associated with these are defined in the interlocking table. Currently, the development and verification of interlocking tables is entirely manual process, which is inefficient and error-prone due to the complexity of the CBI and the human interferences. Besides, the complexity and volume of the verification results tend to make users feel extremely non-understandable. In order to tackle these problems, we introduce a toolset based on Domain Specific Language for Computer Based Interlocking Systems (DSL-CBI) to automatically generate and verify the interlocking table, and then mark the conflicting routes in the railway station. In this paper, we also discuss the advantages of the toolset and the significant contribution in developing CBI based on the proposed toolset.},
   keywords = {railway safety
specification languages
DSL-CBI
NuSMV
computer based interlocking system
safe train movements
railway station
domain specific language
Unified modeling language
Rail transportation
DSL
Computational modeling
Computers
XML
Semantics
Computer Based Interlocking System (CBI)
Domain Specific Language for Computer Based Interlocking Systems (DSL-CBI)
interlocking table
counter-example visualization},
   DOI = {10.1109/SSIRI-C.2011.28},
   year = {2011},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Caracciolo, A. and Lungu, M. F. and Nierstrasz, O.},
   title = {A Unified Approach to Architecture Conformance Checking},
   booktitle = {2015 12th Working IEEE/IFIP Conference on Software Architecture},
   pages = {41-50},
   abstract = {Software erosion can be controlled by periodically checking for consistency between the de facto architecture and its theoretical counterpart. Studies show that this process is often not automated and that developers still rely heavily on manual reviews, despite the availability of a large number of tools. This is partially due to the high cost involved in setting up and maintaining tool-specific and incompatible test specifications that replicate otherwise documented invariants. To reduce this cost, our approach consists in unifying the functionality provided by existing tools under the umbrella of a common business-readable DSL. By using a declarative language, we are able to write tool-agnostic rules that are simple enough to be understood by untrained stakeholders and, at the same time, can be interpreted as a rigorous specification for checking architecture conformance.},
   keywords = {program testing
software architecture
architecture conformance checking
software erosion
de facto architecture
test specifications
common business-readable DSL
declarative language
tool-agnostic rules
domain specific language
Computer architecture
Concrete
Software
DSL
Mathematical model
Manuals
Monitoring
architecture
erosion
conformance checking},
   DOI = {10.1109/WICSA.2015.11},
   year = {2015},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Casadei, R. and Pianini, D. and Viroli, M.},
   title = {Simulating large-scale aggregate MASs with alchemist and scala},
   booktitle = {2016 Federated Conference on Computer Science and Information Systems (FedCSIS)},
   pages = {1495-1504},
   abstract = {Recent works in the context of large-scale adaptive systems, such as those based on opportunistic IoT-based applications, promote aggregate programming, a development approach for distributed systems in which the collectivity of devices is directly targeted, instead of individual ones. This makes the resulting behaviour highly insensitive to network size, density, and topology, and as such, intrinsically robust to failures and changes to working conditions (e.g., location of computational load, communication technology, and computational infrastructure). Most specifically, we argue that aggregate programming is particularly suitable for building models and simulations of complex large-scale reactive MASs. Accordingly, in this paper we describe SCAFI (Scala Fields), a Scala-based API and DSL for aggregate programming, and its integration with the ALCHEMIST simulator, and usage scenarios in the context of smart mobility.},
   keywords = {application program interfaces
multi-agent systems
specification languages
large-scale aggregate MAS
large-scale adaptive systems
opportunistic IoT-based applications
Internet of Things
distributed systems
Scala-based API
application program interface
DSL
domain-specific language
ALCHEMIST simulator
smart mobility context
Aggregates
Programming
Calculus
Context
Libraries
Robustness
aggregate programming
Scala
simulation},    year = {2016},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Čeliković, M. and Luković, I. and Aleksić, S. and Ivančević, V.},
   title = {A MOF based meta-model of IIS∗Case PIM concepts},
   booktitle = {2011 Federated Conference on Computer Science and Information Systems (FedCSIS)},
   pages = {825-832},
   abstract = {In this paper, we present platform independent model (PIM) concepts of IIS*Case tool for information system (IS) modeling and design. IIS*Case is a model driven software tool that provides generation of executable application prototypes. The concepts are described by Meta Object Facility (MOF) specification, one of the commonly sed approaches for describing meta-models. One of the main reasons for having IIS*Case PIM concepts specified through the meta-model, is to provide software documentation in a formal way, as well as a domain analysis purposed to create a domain specific langage to support IS design. Using the meta-model of PIM concepts, we can generate test cases that may assist in software tool verification.},
   keywords = {information systems
program verification
software tools
specification languages
system documentation
MOF based metamodel
platform independent model concepts
IIS*Case tool
model driven software tool
executable application prototypes
meta object facility specification
software documentation
domain analysis
domain specific language
software tool verification
Databases
Unified modeling language
Data models
Servers
Barium
Computer aided software engineering},    year = {2011},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Chandrasekharan, A. and Schmitz, K. and Kuhne, U. and Drechsler, R.},
   title = {Ensuring safety and reliability of IP-based system design – A container approach},
   booktitle = {2015 International Symposium on Rapid System Prototyping (RSP)},
   pages = {76-82},
   abstract = {The application of built-to-order embedded hardware designs in safety critical systems requires a high design quality and robustness during operation. Flawless execution of the involved software can be compromised by malfunctioning hardware components or by software-induced errors. Furthermore, intellectual property (IP) tends to become unavoidable in modern hardware designs. Any unexpected behavior of IP components may cause unrecoverable system errors. In order to construct correct and safe systems from unverified and potentially malicious components, we propose a system integration approach which encapsulates IP blocks in verifiable container modules. The synthesis of these container modules is driven by a domain specific language (DSL) augmented with sequential extended regular expressions (SEREs). The approach is demonstrated by showing the synthesis of an effective countermeasure against software-induced memory disturbance errors.},
   keywords = {data encapsulation
formal languages
industrial property
programming languages
reliability
security of data
specification languages
IP-based system design
system integration approach
IP block encapsulation
verifiable container modules
domain specific language
sequential extended regular expressions
DSL
SERE
software-induced memory disturbance error countermeasure
safety critical systems
intellectual property
specification language
Containers
Monitoring
IP networks
Safety
Hardware
Robustness
Container-Verification
Safe IP Integration
Model-to-HDL Synthesis},
   ISBN = {2150-5519},
   DOI = {10.1109/RSP.2015.7416550},
   year = {2015},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Chao, Huang and Chee Wai, Lee and Kale, L. V.},
   title = {Support for adaptivity in ARMCI using migratable objects},
   booktitle = {Proceedings 20th IEEE International Parallel & Distributed Processing Symposium},
   pages = {9 pp.},
   abstract = {Many new paradigms of parallel programming have emerged that compete with and complement the standard and well-established MPI model. Most notable, and successful, among these are models that support some form of global address space. At the same time, approaches based on migratable objects (also called virtualized processes) have shown that resource management concerns can be separated effectively from the overall parallel programming effort. For example, Charm++ supports dynamic load balancing via an intelligent adaptive run-time system. It is also becoming clear that a multi-paradigm approach that allows modules written in one or more paradigms to coexist and co-operate will be necessary to tame the parallel programming challenge. ARMCI is a remote memory copy library that serves as a foundation of many global address space languages and libraries. This paper presents our preliminary work on integrating and supporting ARMCI with the adaptive run-time system of Charm++ as a part of our overall effort in the multi-paradigm approach},
   keywords = {application program interfaces
message passing
object-oriented programming
parallel programming
resource allocation
software libraries
storage allocation
ARMCI
migratable objects
MPI model
virtualized processes
resource management
Charm++ objects
dynamic load balancing
intelligent adaptive runtime system
remote memory copy library
global address space languages
Programming profession
Adaptive systems
Libraries
Load management
Chaos
Resource virtualization
Intelligent systems},
   ISBN = {1530-2075},
   DOI = {10.1109/IPDPS.2006.1639720},
   year = {2006},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Charaf, H.},
   title = {Developing Mobile Applications for Multiple Platforms},
   booktitle = {2011 Second Eastern European Regional Conference on the Engineering of Computer Based Systems},
   pages = {2-2},
   abstract = {Developing software for mobile devices requires special attention, and it still requires more large effort compared to software development for desktop computers and servers. With the introduction and popularity of wireless devices, the diversity of the platforms has also been increased. There are different platforms and tools from different vendors such as Microsoft, Sun, Nokia, SonyEricsson and many more. Because of the relatively low-level programming interface, software development (e.g. for Symbian) platform is a tiresome and error prone task, whereas Android and Windows Mobile contains higher level structures. This keynote introduces the problem of the software development for incompatible mobile platforms. Moreover, it provides a Model-Driven Architecture (MDA) and Domain Specific Modeling Language (DSML)-based solution. We will also discuss the relevance of the model-based approach that facilitates a more efficient software development because the reuse and the generative techniques are key characteistics of model-based computing. In the presented approach, the platform-independence lies in the model transformation. This keynote illustrates the creation of model compliers on a metamodeling basis by a software package called Visual Modeling and Transformation System (VMTS), which is a multipurpose modeling and metamodel-based transformation system. A case study is also presented on how model compilers can be used to generate user interface handler code for different mobile platforms from the same platform-independent input models.},
   keywords = {mobile computing
simulation languages
software architecture
software reusability
user interfaces
mobile application
software development
Microsoft
Sun
Nokia
SonyEricsson
Symbian
Android
Windows Mobile
model-driven architecture
domain specific modeling language
software reuse technique
software generative technique
VMTS software package
visual modeling and transformation system
user interface handler code
Computational modeling
Informatics
Programming
Educational institutions
Economics
Mobile communication
Research and development},
   DOI = {10.1109/ECBS-EERC.2011.43},
   year = {2011},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Chen, B. and Guo, G. and Qiu, X.},
   title = {The Application of Multi-paradigm Modeling in Social Computation},
   booktitle = {2013 Fourth International Conference on Digital Manufacturing & Automation},
   pages = {1396-1400},
   abstract = {Recently, the research on irregular emergent events management had become the hot field in complex system modeling and simulation. In order to solve the social computation in irregular emergent events, A-C-P (Artificial Society, Computational Experiments, Parallel Execution) is the best solution. We bring the multi-paradigm modeling theory to the modeling and simulation for artificial society. Model transformation is used to cover the multi-field in artificial society, Co-simulation is used to connect the heterogeneous system in computation experiments. We give the Multi-Paradigm Modeling based computation experiment framework. The advantages of the application are summarized in the end.},
   keywords = {artificial intelligence
social sciences computing
A-C-P technique
model transformation
parallel execution
computational experiment
artificial society
irregular emergent events management
social computation
multiparadigm modeling
Manufacturing
Automation
Multi-Paradigm Modeling
Co-Simulation},
   DOI = {10.1109/ICDMA.2013.333},
   year = {2013},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Chen, D. and Panfilenko, D. V. and Khabbazi, M. R. and Sonntag, D.},
   title = {A model-based approach to qualified process automation for anomaly detection and treatment},
   booktitle = {2016 IEEE 21st International Conference on Emerging Technologies and Factory Automation (ETFA)},
   pages = {1-8},
   abstract = {Modern machineries are becoming complex cyber-physical systems with increasingly intelligent support for process automation. For the dependability and performance, a combination of measures for fault avoidance, robust architecture, and runtime anomaly handling is necessary. These in turn call for a formalization of knowledge across different system lifecycle stages and a provision of novel methods and tools for qualified system synthesis and effective risk management. This paper presents a model-based approach to qualified process automation for the operation and maintenance of production systems. The contribution is centered on the formalizations of a wide range of system concerns, and thereby a consolidation of the rationale behind the design of run-time process logic in BPMN2.0. In particular, the approach allows an integration of formal system descriptions, FTA and FEMA based anomaly analysis, and executable process models for effective anomaly detection and treatment. The approach adopts mature modeling methods and tools through EAST-ADL. In this paper, a prototype tool-chain with MetaEdit+ Domain-Specific Modeling (DSM) Workbench, HiP-HOPS Tool and Camunda BPM Platform is also presented.},
   keywords = {cyber-physical systems
maintenance engineering
production engineering computing
production management
prototypes
risk management
complex cyber-physical system
intelligent support
fault avoidance
robust architecture
runtime anomaly handling
turn call
knowledge formalization
qualified system synthesis
effective risk management
model-based approach
qualified process automation
production system maintenance
production system operation
run-time process logic design
BPMN2.0
formal system description integration
FTA-based anomaly analysis
FEMA-based anomaly analysis
anomaly detection
anomaly treatment
EAST-ADL
prototype tool-chain
MetaEdit+
domain-specific modeling
DSM
HiP-HOPS Tool
Camunda BPM Platform
Analytical models
Servers
Automation
Biological system modeling
Ontologies
Process control
Semantics
Evolvable Production Systems (EPS)
Cyber-Physical Systems (CPS)
Model-Based Development (MBD)
Domain-Specific Modeling (DSM)
Process Automation (PA)
Business Process Model and Notation (BPMN2.0)
Industry 4.0},
   DOI = {10.1109/ETFA.2016.7733731},
   year = {2016},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Chen, K. and Sztipanovits, J. and Neema, S.},
   title = {A Case Study on Semantic Unit Composition},
   booktitle = {International Workshop on Modeling in Software Engineering (MISE'07: ICSE Workshop 2007)},
   pages = {3-3},
   abstract = {In previous work we have discussed a semantic anchoring framework that enables the semantic specification of Domain-Specific Modeling languages by specifying semantic anchoring rules to predefined semantic units. This framework is further extended to support heterogeneous systems by developing a method for the composition of semantic units. In this paper, we explain the semantic unit composition through a case study.},
   keywords = {programming language semantics
simulation languages
semantic unit composition
semantic anchoring framework
domain-specific modeling languages
Data models
Automata
Software systems
Add-drop multiplexers
Software engineering},
   ISBN = {2156-7891},
   DOI = {10.1109/MISE.2007.1},
   year = {2007},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Ciccozzi, F.},
   title = {UniComp: A Semantics-Aware Model Compiler for Optimised Predictable Software},
   booktitle = {2018 IEEE/ACM 40th International Conference on Software Engineering: New Ideas and Emerging Technologies Results (ICSE-NIER)},
   pages = {41-44},
   abstract = {In Model-Driven Engineering, executables are generated from domain-specific modelling languages (DSMLs) through two steps: generation of program code in a third-generation programming languages (3GLs, like C++ or Java) from a model, and compilation of the generated code to object code. 3GL code generation raises three issues. (1) Code generators are DSML- and 3GL-specific, hence they can not be used for other DSMLs or 3GLs than those they were designed for. (2) Existing code generators do not exploit model semantics; hence, 3GL programs do not always semantically reflect models. (3) Existing 3GL compilers are unable to exploit model semantics; hence, they are not able to operate model-specific optimisations. (2) and (3) seriously threaten predictability of the generated executables. We advocate the need and provides a solution proposal for an innovative model compilation framework based on model semantics to produce executables without translations to 3GLs. Model compilation will be based on a common semantics, the Semantics of a Foundational Subset for Executable UML Models (fUML), and will semantically underpin any DSML whose execution semantics can be specified with fUML.},
   keywords = {program compilers
programming language semantics
programming languages
software engineering
Unified Modeling Language
DSML whose execution semantics
Executable UML Models
common semantics
innovative model compilation framework
generated executables
model-specific optimisations
3GL compilers
3GL programs
model semantics
3GL-specific
(1) Code generators
3GL code generation
generated code
3GLs
third-generation programming languages
program code
domain-specific modelling languages
Model-Driven Engineering
optimised predictable software
Semantics-aware Model compiler
Semantics
Analytical models
Generators
Predictive models
Optimization
Software
UML
ALF
fUML
compilation
predictability},    year = {2018},
   type = {Conference Proceedings}
}

@article{
   author = {Coli, V. L. and Tournier, P. and Dolean, V. and Kanfoud, I. E. and Pichot, C. and Migliaccio, C. and Blanc-Féraud, L.},
   title = {Detection of Simulated Brain Strokes Using Microwave Tomography},
   journal = {IEEE Journal of Electromagnetics, RF and Microwaves in Medicine and Biology},
   journalAlt = {IEEE Journal of Electromagnetics, RF and Microwaves in Medicine and Biology},
   volume = {3},
   number = {4},
   pages = {254-260},
   abstract = {Brain strokes are one of the leading causes of disability and mortality in adults in developed countries. Ischemic stroke (85% of total cases) and hemorrhagic stroke (15%) must be treated with opposing therapies, and thus, the nature of the stroke must be determined quickly in order to apply the appropriate treatment. Recent studies in biomedical imaging have shown that strokes produce variations in the complex electric permittivity of brain tissues, which can be detected by means of microwave tomography. Here, we present some synthetic results obtained with an experimental microwave tomography-based portable system for the early detection and monitoring of brain strokes. The determination of electric permittivity first requires the solution of a coupled forward-inverse problem. We make use of massive parallel computation from domain decomposition method and regularization techniques for optimization methods. Synthetic data are obtained with electromagnetic simulations corrupted by noise, which have been derived from measurements errors of the experimental imaging system. Results demonstrate the possibility to detect hemorrhagic strokes with microwave systems when applying the proposed reconstruction algorithm with edge preserving regularization.},
   keywords = {bioelectric phenomena
biological tissues
brain
image reconstruction
inverse problems
medical image processing
microwave imaging
optimisation
permittivity
optimization methods
electromagnetic simulations
brain strokes
biomedical imaging
microwave tomography-based portable system
microwave systems
domain decomposition method
brain tissues
electric permittivity
hemorrhagic stroke
ischemic stroke
mortality
simulated brain strokes
Stroke (medical condition)
Signal reconstruction
parallel processing
Tomography
Computational modeling
mathematical programming
dielectric constant
parallel programming
brain stroke imaging
domain-specific language
gradient based minimization algorithm
regularization methods
total variation
hemorrhagic brain stroke detection
high-speed parallel computing
iterative microwave tomographic imaging
massively parallel computing
numerical modeling
open source FreeFem++ solver
whole-microwave measurement system
brain modeling},
   ISSN = {2469-7257},
   DOI = {10.1109/JERM.2019.2921076},
   year = {2019},
   type = {Journal Article}
}

@inproceedings{
   author = {Combemale, B. and Crégut, X. and Pantel, M.},
   title = {A Design Pattern to Build Executable DSMLs and Associated V&V Tools},
   booktitle = {2012 19th Asia-Pacific Software Engineering Conference},
   volume = {1},
   pages = {282-287},
   abstract = {Model executability is now a key concern in model-driven engineering, mainly to support early validation and verification (V&V). Some approaches allow to weave executability into metamodels, defining executable domain-specific modeling languages (DSMLs). Model validation can then be achieved by simulation and graphical animation through direct interpretation of the conforming models. Other approaches address model executability by model compilation, allowing to reuse the virtual machines or V&V tools existing in the target domain. Nevertheless, systematic methods are currently not available to help the language designer in the definition of such an execution semantics and related tools. For instance, simulators are mostly hand-crafted in a tool specific manner for each DSML. In this paper, we propose to reify the elements commonly used to support state-based execution in a DSML. We infer a design pattern (called Executable DSML pattern) providing a general reusable solution for the expression of the executability concerns in DSMLs. It favors flexibility and improves reusability in the definition of semantics-based tools for DSMLs. We illustrate how this pattern can be applied to ease the development of V&V tools.},
   keywords = {simulation languages
software reusability
virtual machines
executable DSML
V&V tools
model executability
model-driven engineering
early validation and verification
metamodels
domain-specific modeling languages
model compilation
virtual machine reuse
state-based execution
design pattern
Semantics
Unified modeling language
Runtime
Computational modeling
Abstracts
Animation
Concrete
Model Driven Engineering
Software Language Engineering
Validation & Verification},
   ISBN = {1530-1362},
   DOI = {10.1109/APSEC.2012.79},
   year = {2012},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Czauski, T. and Turner, H. and White, J. and Eade, S.},
   title = {NERD -- No Effort Rapid Development: A Framework for Provisioning Mobile Cloud Industrial Control Applications},
   booktitle = {2014 2nd IEEE International Conference on Mobile Cloud Computing, Services, and Engineering},
   pages = {57-66},
   abstract = {Industrial Control Systems (ICS), such as wastewater treatment systems, are frequently composed of hundreds of devices distributed over a large geographic area. While mobile applications have been used with good success in managing ICSs, traditional methods of distributing applications (e.g. app stores) are not well suited to the task of distributing ICS mobile applications, as the highly individualized and often proprietary individual components of ICSs have vastly different interfaces leading to a need to download hundreds of applications. We propose the No Effort Rapid Development (NERD) framework to address the challenges of in-field human-machine interface (HMI) discovery, provisioning, and co-evolution with related ICSs. Mobile cloud services offer the ability to simplify on-demand HMI distribution and operation of ICSs. NERD leverages existing ICS device-markers (e.g. QR-codes or RFID tags) for rapid cyber-physical discovery and provisioning of HMIs in the field. Device-markers have a very limited data capacity, and to achieve on-device storage of HMIs we propose using a compact data-driven domain specific language that emphasizes data sources and sinks between the HMI and ICS cloud based services. Our approach seamlessly links controls in the physical domain with specific resources in the digital domain, such as device-specific interfaces or ICS-wide control interfaces. We provide a quantitative evaluation of NERD and show how NERD can simplify the process of in-field discovery and provisioning of HMIs and related applications.},
   keywords = {cloud computing
control engineering computing
industrial control
mobile computing
production engineering computing
NERD framework
no effort rapid development
mobile cloud industrial control applications
industrial control systems
ICS
wastewater treatment systems
mobile applications
human-machine interface
HMI discovery
cyber-physical discovery
cloud based services
Automation
Mobile communication
Mobile handsets
Maintenance engineering
DSL
Monitoring
Software
SCADA Systems
Mobile Cloud Computing
Domain Specific Languages
Software Maintenance
Man-Machine Systems
Application Distribution
Cyber-Physical Systems},
   DOI = {10.1109/MobileCloud.2014.10},
   year = {2014},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Demirkol, S. and Challenger, M. and Getir, S. and Kosar, T. and Kardas, G. and Mernik, M.},
   title = {SEA_L: A Domain-specific Language for Semantic Web enabled Multi-agent Systems},
   booktitle = {2012 Federated Conference on Computer Science and Information Systems (FedCSIS)},
   pages = {1373-1380},
   abstract = {Autonomous, reactive and proactive features of software agents make development of agent-based software systems complex. A Domain-specific Language (DSL) can provide the required abstraction and hence support a more fruitful methodology for the development of Multi-agent Systems (MASs) especially working on the new challenging environments such as the Semantic Web. Based on our previously introduced domain-specific metamodel, in this paper we propose a textual concrete syntax of a DSL for MASs working on the Semantic Web and show how the specifications of this DSL can be utilized during the code generation of exact MASs. The new DSL is called Semantic web Enabled Agent Language (SEA_L). The syntax of SEA_L is supported with textual modeling toolkits developed with Xtext. The practical use of SEA_L is illustrated with a case study which considers the modeling of a multi-agent based e-barter system.},
   keywords = {computational linguistics
electronic commerce
formal specification
multi-agent systems
program compilers
semantic Web
simulation languages
software agents
SEA_L
domain-specific language
autonomous software agents
reactive software agents
proactive software agents
agent-based software systems
MAS
semantic Web enabled multiagent systems
domain-specific metamodel
textual concrete syntax
DSL
code generation
semantic Web enabled agent language
textual modeling toolkits
Xtext
multiagent based e-barter system
Syntactics
Semantics
Concrete
Abstracts
Ontologies
Domain-specific Languages
Metamodel
Multiagent Systems},    year = {2012},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Deshmukh, M. and Weps, B. and Isidro, P. and Gerndt, A.},
   title = {Model driven language framework to automate command and data handling code generation},
   booktitle = {2015 IEEE Aerospace Conference},
   pages = {1-9},
   abstract = {On-board computer software (OBSW) is an integral part of every space mission. It has been continuously growing in size and complexity. The insufficient level of automation in the development process of such software leads to low software re-usability and drives up the costs. This paper presents a generic approach to describe and model the on-board software in terms of data that is processed by it. Domain Specific Language (DSL) based framework is developed using which provides a DSL editor, a model validator, and a code generator. Using the framework, a system data model is created. The C++ code is generated from it which is then customized to implement low-level behavior. As a proof of concept, the telecommand handling functionality of OBSW is developed to prove the feasibility of applying the solution to the whole system. Based on the analysis conducted on the source code of the TET-1 satellite of the German Aerospace Center (DLR), a DSL is designed and implemented. The resulting DSL-based framework is tested with an example model and target code customization, showing its ease of use and proving that it behaves as expected.},
   keywords = {aerospace computing
C++ language
program compilers
software reusability
source code (software)
model driven language framework
automatic command code generation
on-board computer software
space mission
development process
generic approach
data processing
domain specific language
DSL editor
model validator
code generator
system data model
C++ code generation
low-level behavior
telecommand handling functionality
OBSW
source code
TET-1 satellite
German Aerospace Center
DLR
target code customization
automatic data handling code generation
Software
Data models
DSL
Grammar
Data handling
Space vehicles
Aerospace electronics},
   ISBN = {1095-323X},
   DOI = {10.1109/AERO.2015.7118991},
   year = {2015},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Díaz, O. and Arellano, C.},
   title = {Integrating Microblogging Into Domain Specific Language Editors},
   booktitle = {2013 International Conference on Cloud and Green Computing},
   pages = {219-225},
   abstract = {Micro logging is emerging as a suitable means for question-answering in working settings. This leads to different efforts to seamlessly integrate microblogging into the daily-used tools. Specifically, microblogging is being regarded as particularly useful during software development, akin to the tradition of Q&A forums. This paper looks at a particular kind of software: the one being developed by domain experts through the use of Domain Specific Languages (DSLs). We believe this setting is specially amenable to benefit from Q&A microblogging due to inherent limitations of the target audience. This brings the twist of domain specific ness into microblogging, i.e. the Q&A process is now framed by the semantics of the DSL constructs. This permits the introduction of editing assistants that embed domain knowledge about the kind of questions that can be posed, and the way answers can be selected. This opens an opportunity for more focused and assisted microblogging. This paper introduces Crowd Call, an in place microblogging mediator for DSL editors. The aim is to make microblogging a natural gesture during the conception of the DSL expressions, making transparent the interplay between the DSL editor and the Social Networking Services. In addition, Crowd Call can be configured to the constructs and resolution strategies of the DSL at hand so that questions and answers are framed by the semantics of the DSL. The approach is illustrated for three DSLs: the Google Spreadsheets formula language, SQL and Sticklet. We show how Crowd Call-mediated microblogging is tuned for the semantics of each DSL.},
   keywords = {question answering (information retrieval)
social networking (online)
specification languages
SQL
text editing
question answering
software development
domain experts
domain specific language editors
Q and A microblogging
Q and A process
DSL constructs
domain knowledge
inplace microblogging mediator
DSL editors
DSL expressions
social networking services
resolution strategies
Google Spreadsheets formula language
Sticklet
CrowdCall-mediated microblogging
DSL semantics
DSL
Google
Semantics
Software
Social network services
Communities
Computer languages
Microblogging
Domain Specific Languages},
   DOI = {10.1109/CGC.2013.42},
   year = {2013},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Drechsler, R. and Kühne, U.},
   title = {Safe IP Integration Using Container Modules},
   booktitle = {2014 Fifth International Symposium on Electronic System Design},
   pages = {1-4},
   abstract = {In modern hardware and system design flows, tight time-to-market constraints can only be met by reusing existing code. Building blocks like floating-point units, embedded processors or bus components are readily available as Intellectual Property (IP). However, this practice of putting together third-party components conflicts with the high quality requirements which are common in the domain of safety-critical systems, since the correctness of the used IP blocks is difficult or impossible to verify. In this paper, we propose an approach for safe IP integration by isolating suspicious blocks inside provably safe container modules. In this way, system level properties can be checked assuming the correct behavior of the wrapped IP blocks. As a first step in this direction, we show how a container module implementing a bus protocol can be generated and verified automatically. We rely on a model-driven design approach using a domain specific language and model-to-text transformations.},
   keywords = {logic circuits
microprocessor chips
safety-critical software
model-to-text transformations
domain specific language
model-driven design approach
bus protocol
IP blocks
safety-critical systems
third-party components
intellectual property
bus components
embedded processors
floating-point units
building blocks
time-to-market constraints
container modules
safe IP integration
Containers
System-on-chip
IP networks
Hardware
Computer architecture
Protocols
DSL
hardware design
system level design
safety},
   DOI = {10.1109/ISED.2014.8},
   year = {2014},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Dubois, M. and El Mostapha, Aboulhamid and Rousseau, F.},
   title = {Towards an Efficient Simulation of Multi-Language Descriptions of Heterogeneous Systems},
   booktitle = {APCCAS 2006 - 2006 IEEE Asia Pacific Conference on Circuits and Systems},
   pages = {538-541},
   abstract = {Heterogeneous systems design requires executing models using different simulators. Usually, simulators are connected and synchronized together by using mechanisms such as shared memory or TCP/IP. Current approaches have many drawbacks: they are not adapted to distributed environments, the simulation performance may be very disappointing, and each simulator has its own paradigm. We propose a new approach to simulate models described with different languages such as SystemC or ESyS.NET on a distributed environment. All the models are translated into a unique internal format in order to be able to optimize a distributed and multi-paradigm simulation of the models. Optimizations include different mechanisms such as regrouping of threads in a single one while respecting the semantics of the models or the splitting of a model in order to execute it on several computer resources},
   keywords = {distributed databases
programming language semantics
programming languages
multilanguage descriptions
heterogeneous systems design
memory
TCP/IP
SystemC
ESyS.NET
semantics
Computational modeling
Yarn
Kernel
Discrete event simulation
Analytical models
TCPIP
Merging
Acceleration
Computer simulation
Signal processing},
   DOI = {10.1109/APCCAS.2006.342527},
   year = {2006},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Dümmel, N. and Westfechtel, B. and Ehmann, M.},
   title = {Work in Progress: Gathering Requirements and Developing an Educational Programming Language},
   booktitle = {2019 IEEE Global Engineering Education Conference (EDUCON)},
   pages = {1-4},
   abstract = {In this paper we discuss requirements for an educational programming language. Analyzing these requirements and some of the existing languages and educational tools, we have realized that a new language should be developed to cover our needs. For example, various programming paradigms must be supported by the language without explicitly focusing on a specific paradigm, i.e. you should be capable to write a procedural program without using objects. The procedural paradigm was deemed to be the most integral part of the language and has been already implemented and is currently tested in an introductory course. Thus, we also present some of the currently implemented features and provide an example of their utilization in our introductory programming course.},
   keywords = {computer aided instruction
computer science education
educational courses
programming languages
educational programming language
educational tools
procedural program
procedural paradigm
introductory programming course
Programming profession
Java
Education
Tools
Syntactics
multiparadigm
introductory course},
   ISBN = {2165-9567},
   DOI = {10.1109/EDUCON.2019.8725073},
   year = {2019},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Durelli, G. C. and Spada, F. and Pilato, C. and Santambrogio, M. D.},
   title = {Scala-Based Domain-Specific Language for Creating Accelerator-Based SoCs},
   booktitle = {2016 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)},
   pages = {225-232},
   abstract = {Nowadays, thanks to technology miniaturization and industrial standards, it is possible to create System-on-Chip (SoC) architectures featuring a combination of many components, like processor cores and specialized hardware accelerators. However, designing an SoC to accelerate an embedded application is particularly complex. After decomposing this application into tasks and assigning each of them to a processing element, the designer must create the required hardware components and integrate them into the final system. Currently, this process is not well supported by commercial tool flows and has to be manually performed. This is time consuming and error prone. This paper proposes a Domain-Specific Language (DSL) based on Scala to specify the architecture of accelerator-based SoCs. We leverage this DSL to coordinate commercial High-Level Synthesis (HLS) tools in order to create the corresponding accelerators with proper standard interfaces for system-level integration.},
   keywords = {high level synthesis
integrated circuit design
specification languages
system-on-chip
scala-based domain-specific language
accelerator-based SoC
technology miniaturization
industrial standards
system-on-chip architectures
SoC architectures
processor cores
hardware accelerators
SoC design
embedded application
hardware components
DSL
Scala
high-level synthesis tools
HLS tools
system-level integration
Hardware
Software
Computer architecture
Image edge detection
Protocols
Acceleration},
   DOI = {10.1109/IPDPSW.2016.169},
   year = {2016},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Dwarakanath, A. and Era, D. and Priyadarshi, A. and Dubash, N. and Podder, S.},
   title = {Accelerating Test Automation through a Domain Specific Language},
   booktitle = {2017 IEEE International Conference on Software Testing, Verification and Validation (ICST)},
   pages = {460-467},
   abstract = {Test automation involves the automatic execution of test scripts instead of being manually run. This significantly reduces the amount of manual effort needed and thus is of great interest to the software testing industry. There are two key problems in the existing tools & methods for test automation - a) Creating an automation test script is essentially a code development task, which most testers are not trained on, and b) the automation test script is seldom readable, making the task of maintenance an effort intensive process. We present the Accelerating Test Automation Platform (ATAP) which is aimed at making test automation accessible to non-programmers. ATAP allows the creation of an automation test script through a domain specific language based on English. The English-like test scripts are automatically converted to machine executable code using Selenium WebDriver. ATAP's English-like test script makes it easy for non-programmers to author. The functional flow of an ATAP script is easy to understand as well thus making maintenance simpler (you can understand the flow of the test script when you revisit it many months later). ATAP has been built around the Eclipse ecosystem and has been used in a real-life testing project. We present the details of the implementation of ATAP and the results from its usage in practice.},
   keywords = {program testing
specification languages
Selenium WebDriver
Eclipse ecosystem
ATAP
accelerating test automation platform
code development task
software testing industry
test script execution
domain specific language
test automation
Automation
DSL
Tools
Selenium
Natural languages
Java
Programming
Xtext},
   DOI = {10.1109/ICST.2017.52},
   year = {2017},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Dwijatmiko, T. H. and Nguyen, R.},
   title = {An implementation of domain specific languages to microprocessor's Memory Built in Self Repair testing},
   booktitle = {2013 IEEE 15th Electronics Packaging Technology Conference (EPTC 2013)},
   pages = {399-402},
   abstract = {Memory Built in Self Repair (MBISR) test in microprocessor testing has always been a very challenging. The main challenges are the complexity of the memory structure and the device to device design variations. Because of this complexity, separate groups with different focus are needed to address the challenge. The test engineers are the experts on Automated Test Equipment (ATE) platforms, while the IP owners are the experts on particular microprocessor's IP. To minimize the test program development and maintenance costs, the test engineers aim to provide a generic solution for all devices. Therefore, to cater for the variations, XML (Extensible Markup Language) has been used to represent the product specific definitions and configurations which will be maintained by the IP owners. However, the surge of new microprocessor designs and more advance innovation to the memory IPs lead to device to device variations increase. In the other hand XML is too static to handle these variations increase and has limited capability to express higher-order structures like conditionals. Therefore a domain specific language (DSL) is adapted to effectively deal with this issue. DSL as opposed to XML is a programming language which provides flexibility as offered by the general purpose languages, such as Java and C++. Yet, it is targeted to a particular kind of problem with its purpose of having separation of business and technical aspect, making it concise and easy to understand by the domain specialists. Therefore DSL fits perfectly as an easy to use language for the IP owners to express freely the product specifications. This paper showcases an example of DSL based solution to MBISR testing in microprocessor.},
   keywords = {automatic test equipment
built-in self test
integrated circuit reliability
microprocessor chips
XML
domain specific languages
memory built in self repair testing
microprocessor testing
memory structure
automated test equipment
test program development
maintenance costs
extensible markup language
product specific definitions
microprocessor designs
programming language
product specifications
DSL
Business
Maintenance engineering
Microprocessors
IP networks
Java},
   DOI = {10.1109/EPTC.2013.6745750},
   year = {2013},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {É, Leclercq and Savonnet, M. and Troya-Galvis, A. and Büttner, S.},
   title = {Investigating a multi-paradigm system for the management of archaeological data: Corpus Lapidum Burgundiae},
   booktitle = {2013 Digital Heritage International Congress (DigitalHeritage)},
   volume = {1},
   pages = {679-682},
   abstract = {Scientific Information Systems (SIS) must move beyond data repositories and closed systems, to allow collaborations among different research disciplines, to include new types of data, to control data quality, and to enable semantic interoperability. Archaeological data include textual information, measures, sketches, photographies, 3D models, and a vast amount of links between data and historical information sources. We develop a formal model for ontology-based annotations that conforms to a semi-ring algebraic structure and we define a subset of algebraic operators to query annotations. We show how our approach is instantiated in a collaborative Web platform for the Burgundy Stone project.},
   keywords = {archaeology
ontologies (artificial intelligence)
query processing
scientific information systems
multiparadigm system
archaeological data management
corpus Lapidum Burgundiae
SIS
data repository
closed systems
data quality
semantic interoperability
textual information
3D models
historical information sources
ontology-based annotations
semiring algebraic structure
query annotations
algebraic operators
Burgundy Stone project
collaborative Web platform
Information services
Electronic publishing
Internet
Ontologies
Semantics
Data models
Databases
Scientific Information System
Archaeological Corpus
Ontology-based Annotation
Semantic Wiki},
   DOI = {10.1109/DigitalHeritage.2013.6743816},
   year = {2013},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Efkemann, C. and Peleska, J.},
   title = {Model-Based Testing for the Second Generation of Integrated Modular Avionics},
   booktitle = {2011 IEEE Fourth International Conference on Software Testing, Verification and Validation Workshops},
   pages = {55-62},
   abstract = {In this paper the authors present the current research and development activities regarding automated testing of Integrated Modular Avionics controllers in the European research project SCARLETT. The authors describe the goals of the SCARLETT project and explain its background of Integrated Modular Avionics. Furthermore, they explain different levels of testing of components required for certification. A domain-specific modelling language designed for the IMA platform is presented. This language is used to create models from which tests of different levels can be generated automatically. The authors expect significant improvements in terms of effort to create and maintain test procedures compared to conventional test creation.},
   keywords = {aerospace computing
avionics
program testing
simulation languages
model-based testing
integrated modular avionics
SCARLETT research project
domain-specific modelling language
Aerospace electronics
Testing
Generators
Aircraft
Europe
Random access memory
Concrete
IMA
SCARLETT
TTCN-3
domain-specific modelling},
   DOI = {10.1109/ICSTW.2011.72},
   year = {2011},
   type = {Conference Proceedings}
}

@article{
   author = {Engell, S. and Mosterman, P. J.},
   title = {Guest Editorial Computer Automated Multiparadigm Modeling (CAMPAM)},
   journal = {IEEE Transactions on Control Systems Technology},
   journalAlt = {IEEE Transactions on Control Systems Technology},
   volume = {12},
   number = {2},
   pages = {221-222},
   keywords = {Control systems
Automatic control
Automotive engineering
Unified modeling language
Computational modeling
Algorithm design and analysis
Systems engineering and theory
Design engineering
Control system synthesis
Application software},
   ISSN = {1558-0865},
   DOI = {10.1109/TCST.2004.826710},
   year = {2004},
   type = {Journal Article}
}

@inproceedings{
   author = {Etcheverry, L. and Marotta, A. and Ruggia, R.},
   title = {Data quality assessment in Genome Wide Association Studies (GWAS)},
   booktitle = {5th Iberian Conference on Information Systems and Technologies},
   pages = {1-5},
   abstract = {Genome Wide Association Studies (GWAS) are developed to find direct or indirect relations from given genomic configurations to physical characteristics or specific diseases. In order to build new GWAS, avoiding the complexities of field based studies, a statistical technique called meta-analysis can be used. Bad or unknown data quality has been largely identified as a major problem in meta-analysis since it generates lack of confidence and inhibits its exploitation. This paper addresses GWAS data quality issues and presents a domain specific model for data quality assessment, which has been developed taking into account meta-analysis requirements.},
   keywords = {biology computing
data analysis
genomics
statistical analysis
genome wide association studies
genomic configurations
statistical technique
meta analysis
GWAS data quality
domain specific model
data quality assessment
Bioinformatics
Data models
Biological system modeling
Accuracy
data quality
meta-analysis
GWAS},
   ISBN = {2166-0735},    year = {2010},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Falch, T. L. and Elster, A. C.},
   title = {ImageCL: An image processing language for performance portability on heterogeneous systems},
   booktitle = {2016 International Conference on High Performance Computing & Simulation (HPCS)},
   pages = {562-569},
   abstract = {Modern computer systems typically conbine multicore CPUs with accelerators like GPUs for inproved performance and energy efficiency. However, these systems suffer from poor performance portability - code tuned for one device must be retuned to achieve high performance on another. Image processing is increasing in importance, with applications ranging from seismology and medicine to Photoshop. Based on our experience with medical image processing, we propose ImageCL, a high-level domain-specific language and source-to-source compiler, targeting heterogeneous hardware. ImageCL resembles OpenCL, but abstracts away performance optimization details, allowing the programmer to focus on algorithm development, rather than performance tuning. The latter is left to our source-to-source compiler and auto-tuner. From high-level ImageCL kernels, our source-to-source compiler can generate multiple OpenCL implementations with different optimizations applied. We rely on auto-tuning rather than machine models or expert programmer knowledge to determine which optimizations to apply, making our tuning procedure highly robust. Furthermore, we can generate high performing implementations for different devices from a single source code, thereby improving performance portability. We evaluate our approach on three image processing benchmarks, on different GPU and CPU devices, and are able to outperform other state of the art solutions in several cases, achieving speedups of up to 4.57x.},
   keywords = {graphics processing units
image processing
program compilers
image processing language
performance portability
heterogeneous systems
multicore CPUs
accelerators
energy efficiency
medical image processing
high-level domain-specific language
source-to-source compiler
heterogeneous hardware
OpenCL
performance optimization
high-level ImageCL kernels
GPU device
CPU device
Performance evaluation
Optimization
Kernel
Pipelines
Hardware
source-to-source compilation
auto-tuning
heterogeneous computing},
   DOI = {10.1109/HPCSim.2016.7568385},
   year = {2016},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Ferry, N. and Rossini, A. and Chauvel, F. and Morin, B. and Solberg, A.},
   title = {Towards Model-Driven Provisioning, Deployment, Monitoring, and Adaptation of Multi-cloud Systems},
   booktitle = {2013 IEEE Sixth International Conference on Cloud Computing},
   pages = {887-894},
   abstract = {In the landscape of cloud computing, the competition between providers has led to an ever growing number of cloud solutions offered to consumers. The ability to run and manage multi-cloud systems (i.e., applications on multiple clouds) allows exploiting the peculiarities of each cloud solution and hence optimising the performance, availability, and cost of the applications. However, these cloud solutions are typically heterogeneous and the provided features are often incompatible. This diversity hinders the proper exploitation of the full potential of cloud computing, since it prevents interoperability and promotes vendor lock-in, as well as it increases the complexity of development and administration of multi-cloud systems. This problem needs to be addressed promptly. In this paper, we provide a classification of the state-of-the-art of cloud solutions, and argue for the need for model-driven engineering techniques and methods facilitating the specification of provisioning, deployment, monitoring, and adaptation concerns of multi-cloud systems at design-time and their enactment at run-time.},
   keywords = {cloud computing
formal specification
open systems
model-driven provisioning
model-driven deployment
model-driven monitoring
model-driven adaptation
multicloud systems
cloud solutions
interoperability
vendor lock-in
model-driven engineering techniques
Adaptation models
Monitoring
Licenses
Libraries
Java
provisioning
deployment
adaptation
multi-cloud
model-driven engineering
domain-specific modelling language
models@run-time
CloudML},
   ISBN = {2159-6190},
   DOI = {10.1109/CLOUD.2013.133},
   year = {2013},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Figueiredo, E. and Maio, P. and Silva, N. and Lopes, R.},
   title = {DSL-Based Configuration of Solid Referential Management System: A Case Study},
   booktitle = {2018 International Conference on Computational Science and Computational Intelligence (CSCI)},
   pages = {890-894},
   abstract = {For the last decade, uebe.Q is being adopted by companies in different business areas and countries for managing compliance with solid referential information systems, such as ISO 9000 (for quality) and ISO 1400 (for environment). This is a long-term developed software, encompassing extensive, solid and valuable business logic. When it is deployed for/on a company, it usually demands an extensive and specific adaptation (i.e. software refinement) and configuration process involving DigitalWind's ISO 9000 and ISO 1400 experts as well as software development and operation teams. However, a recent business model change imposed that the evolution and configuration of the software, shifts from DigitalWind (and especially from the development team) to external consultants and to other business partners, along with the fact that different third-party's systems and respective data/information need to be integrated with minimal intervention of the development team. This paper presents and overview of the re-engineering process taken to handle this business model change by adopting (i) ontologies for the specification of business concepts, (ii) closed-world assumption (CWA) rules for the specification of the dynamics of the system and (iii) Domain Specific Language (DSL) for the configuration of the system by domain/business experts. The DSL approach is further described in detail.},
   keywords = {business data processing
information systems
ISO standards
ontologies (artificial intelligence)
software engineering
specification languages
ontologies
DigitalWind ISO 1400
DigitalWind ISO 9000
DSL approach
Domain Specific Language
re-engineering process
software development
business logic
solid referential information systems
compliance management
solid referential management system
DSL-based configuration
DSL
Ontology
Alignment
Software Re-engineering
Solid Referential information System},
   DOI = {10.1109/CSCI46756.2018.00176},
   year = {2018},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Franceschini, R. and Challenger, M. and Cicchetti, A. and Denil, J. and Vangheluwe, H.},
   title = {Challenges for Automation in Adaptive Abstraction},
   booktitle = {2019 ACM/IEEE 22nd International Conference on Model Driven Engineering Languages and Systems Companion (MODELS-C)},
   pages = {443-448},
   abstract = {Models are well-defined abstractions that provide cost-effective representations of the real-world for a precise purpose. When dealing with complex problems, there usually exist multiple abstractions, typically describing partially overlapping details of the system under study, and resulting in a hierarchy of abstractions. Adaptive abstraction leverages these levels with the aim of dynamically adapting the abstractions used during system execution. In this paper, we describe such process in terms of a MAPE-K (Monitor-Analyze-Plan-Execute over a shared Knowledge) control loop to discuss the challenges towards adaptive abstraction automation. In particular, we elaborate on adaptively selecting a candidate over multiple abstractions, an unaddressed issue in the literature. The discussion is supported by a running example in an agent-based simulation scenario.},
   keywords = {knowledge management
multi-agent systems
systems engineering
traffic engineering computing
complex problems
multiple abstractions
partially overlapping details
system execution
adaptive abstraction automation
cost-effective representations
agent-based simulation
monitor-analyze-plan-execute over a shared knowledge
Adaptive system
Multi-Abstraction
Multi Paradigm
System Modeling
Agent based Simulation
Traffic Simulation},
   DOI = {10.1109/MODELS-C.2019.00071},
   year = {2019},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Franchi, E.},
   title = {A Domain Specific Language Approach for Agent-Based Social Network Modeling},
   booktitle = {2012 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining},
   pages = {607-612},
   abstract = {Although in the past twenty years agent-based modeling has been widely adopted as a research tool in the fields of social and political sciences, there is lack of software instruments specifically created for social network simulations. Restricting the field of interest specifically to social network models and simulations instead of supporting general agent-based ones, allows for the creation of easier to use, more focused tools. In this work, we propose PyNetSYM, an agent-based modeling framework designed to be friendly to programmers and non-programmers alike. PyNetSYM provides a domain-specific language to specify social network simulations expressed as agent-based models. PyNetSYM was created to deal with large simulations and to work effortlessly with other social network analysis toolkits.},
   keywords = {social networking (online)
social sciences
software agents
domain specific language approach
agent-based social network modeling
social science
political science
PyNetSYM
Object oriented modeling
DSL
Social network services
Libraries
Message systems
Analytical models
Concurrent computing
Social Network Analysis
Agent Based Modeling},
   DOI = {10.1109/ASONAM.2012.102},
   year = {2012},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Freudenstein, P. and Nussbaumer, M.},
   title = {Constructing Advanced Web-Based Dialog Components with Stakeholders – A DSL Approach},
   booktitle = {2008 Eighth International Conference on Web Engineering},
   pages = {38-44},
   abstract = {Complex dialogs with comprehensive underlying data models are gaining increasing importance in todaypsilas Web applications. This in turn accelerates the need for highly dynamic dialogs offering guidance to the users and reducing cognitive overload. Beyond that, requirements from the fields of Web accessibility, platform-independence and Web service integration arise. Considering the resulting complexity, a systematic engineering approach becomes important. Besides addressing the specific characteristics of these dialogs, key success factors from a communication perspective like strong user involvement and clear business objectives must be taken into account. To this end, we present an evolutionary, extensible approach for the model-driven construction of advanced dialogs which is based on a Domain-specific Language (DSL). We introduce a modeling notation based on Petri net constructs and XForms as well as a supporting Web-based editor, both focusing on simplicity and fostering communications. The technical framework allows for quick prototyping and flexible changes. In conclusion, complex, device-independent dialogs with rich behavior and appearance can be constructed and evolved with intense stakeholder collaboration.},
   keywords = {Internet
Petri nets
specification languages
Web-based dialog component
Web accessibility
Web service integration
domain-specific language
Petri net
XForms
Web-based editor
Dialog
User Interaction
DSL
Web Engineering
Model-driven
Stakeholder collaboration},
   DOI = {10.1109/ICWE.2008.39},
   year = {2008},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Fujii, A. and Nakayama, M. and Tanaka, K. and Nagamura, K.},
   title = {EDI support system over RESTful Web API},
   booktitle = {IEEE 8th International Symposium on Intelligent Systems and Informatics},
   pages = {63-70},
   abstract = {Recently Web API (Application Programming Interface) is widely utilized for the service interfaces in enterprise applications. In this article, the possibility of applying Web API to electronic commerce, especially to EDI (Electronic Data Interchange), is discussed. We propose architecture called “Open EDI” as a platform for such activities. And the notation of “Cloud_Object” is introduced that is the structured operational unit for EDI. We aim the system works as a general web applications without specific operational environment for the dataexchanges.},
   keywords = {application program interfaces
electronic commerce
electronic data interchange
Internet
EDI support system
RESTful Web API
application programming interface
open EDI architecture
Clouds
Business
Mashups
Catalogs
XML
Couplings
Programming
Web API
RESTful
B2B
e-commerce
EDI},
   ISBN = {1949-0488},
   DOI = {10.1109/SISY.2010.5647213},
   year = {2010},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Fujita, S. and Moulin, C. and Sugawara, K. and Bartès, J.},
   title = {The design of awareness and operation module for the symbiotic applications},
   booktitle = {9th IEEE International Conference on Cognitive Informatics (ICCI'10)},
   pages = {625-630},
   abstract = {The symbiotic application is designed to achieve the function of supporting a user based on the knowledge of social and perceptual interaction. The architecture of the symbiotic application was described at the ICCI'08. In this paper, we described the design of symbiotic base mechanism for the cognition functions and the decision functions in a symbiotic application. The symbiotic base mechanism converts the signals from the real space and the digital space to the awareness. The symbiotic base mechanism do the action on actuators based on the operation by the cognition functions and the decision functions. The cognition functions and the decision functions are achieved by the intelligent multi-agent system such as an OMAS and a ADIPS/DASH. On the other hand, the symbiotic base mechanism is constructed by a multi-agent system which is called by the Symbiotic Multi-Agent: SYMA. The example scenario is shown by the combination of multi-paradigm/multi-agent framework.},
   keywords = {cognition
multi-agent systems
ubiquitous computing
perceptual interaction
social interaction
symbiotic base mechanism
cognition functions
actuators
decision functions
intelligent multiagent system
OMAS
ADIPS-DASH
symbiotic multiagent system
multiparadigm-multiagent framework
SYMA
awareness and operation module
Symbiosis
Computer architecture
Humans
Schedules
Brain modeling
Symbiotic Computing
Cognition Layer model
Awareness
Social-ware
Multi-agent system},
   DOI = {10.1109/COGINF.2010.5599834},
   year = {2010},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Gargantini, A. and Vavassori, P.},
   title = {CITLAB: A Laboratory for Combinatorial Interaction Testing},
   booktitle = {2012 IEEE Fifth International Conference on Software Testing, Verification and Validation},
   pages = {559-568},
   abstract = {Although the research community around combinatorial interaction testing has been very active for several years, it has failed to find common solutions on some issues. First of all, there is not a common abstract nor concrete language to express combinatorial problems. Combinatorial testing generator tools are strongly decoupled making difficult their interoperability and the exchange of models and data. In this paper, we propose an abstract and concrete specific language for combinatorial problems. It features and formally defines the concepts of parameters and types, constraints, seeds, and test goals. The language is defined by means of XTEXT, a framework for the definition of domain-specific languages. XTEXT is used to derive a powerful editor integrated with eclipse and with all the expected features of a modern editor. Eclipse is also used to build an extensible framework in which test generators, importers, and exporters can be easily added as plugins.},
   keywords = {Java
open systems
program testing
software tools
specification languages
combinatorial interaction testing
combinatorial testing generator tool
interoperability
abstract specific language
concrete specific language
XTEXT
domain specific language
modern editor
eclipse
CITLAB
Testing
DSL
Generators
Syntactics
Grammar
Cameras
combinatorial testing
domain specific languages},
   ISBN = {2159-4848},
   DOI = {10.1109/ICST.2012.141},
   year = {2012},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Gärtner, J. and Musliu, N. and Schafhauser, W. and Slany, W.},
   title = {TEMPLE - A domain specific language for modeling and solving staff scheduling problems},
   booktitle = {2011 IEEE Symposium on Computational Intelligence in Scheduling (SCIS)},
   pages = {58-64},
   abstract = {We present TEMPLE, a domain specific language for modeling and solving staff scheduling problems. TEMPLE provides a set of intuitive abstractions and notations allowing to formulate the constraints of a particular problem in a very compact and natural way. After modeling a staff scheduling problem in TEMPLE, three generic local search algorithms can immediately be applied to the corresponding optimization problem. We show how real-life staff scheduling problems can be both effectively modeled as well as efficiently solved using our approach. Finally, we report on a practical application of TEMPLE in a commercial staff scheduling software.},
   keywords = {optimisation
personnel
search problems
simulation languages
specification languages
domain specific language
TEMPLE language
staff scheduling problem modeling
staff scheduling problem solving
local search algorithm
optimization problem
staff scheduling software
Processor scheduling
Optimization
Scheduling
Schedules
Computational modeling
Law},
   DOI = {10.1109/SCIS.2011.5976550},
   year = {2011},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Gatto, N. and Kusmenko, E. and Rumpe, B.},
   title = {Modeling Deep Reinforcement Learning Based Architectures for Cyber-Physical Systems},
   booktitle = {2019 ACM/IEEE 22nd International Conference on Model Driven Engineering Languages and Systems Companion (MODELS-C)},
   pages = {196-202},
   abstract = {Reinforcement learning is a sub-field of machine learning where an agent aims to learn a behavior or a policy maximizing a reward function by trial and error. The approach is particularly interesting for the design of autonomous cyber-physical systems such as self-driving cars. In this work we present a generative, domain-specific modeling framework for the design, training and integration of reinforcement learning systems. It consists of a neural network modeling language which is used to design the models to be trained, e.g. actor and critic networks, and a training language used to describe the training procedure and set the corresponding hyperparameters. The underlying component model allows the modeler to embed the trained networks in larger component & connector architectures. We illustrate our framework by the example of a self-driving racing car.},
   keywords = {automobiles
cyber-physical systems
learning (artificial intelligence)
neural nets
traffic engineering computing
machine learning
autonomous cyber-physical systems
self-driving cars
deep reinforcement learning systems
neural network modeling language
component and connector architectures
trial and error
cyber-physical systems, machine learning, reinforcement learning, domain-specific languages},
   DOI = {10.1109/MODELS-C.2019.00033},
   year = {2019},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Gautier, T. and Lementec, F. and Faucher, V. and Raffin, B.},
   title = {X-kaapi: A Multi Paradigm Runtime for Multicore Architectures},
   booktitle = {2013 42nd International Conference on Parallel Processing},
   pages = {728-735},
   abstract = {The paper presents X-KAAPI, a compact runtime for multicore architectures that brings multi parallel paradigms (parallel independent loops, fork-join tasks and dataflow tasks) in a unified framework without performance penalty. Comparisons on independent loops with OpenMP and on dense linear algebra with QUARK/PLASMA confirm our design decisions. Applied to EUROPLEXUS, an industrial simulation code for fast transient dynamics, we show that X-KAAPI achieves high speedups on multicore architectures by efficiently parallelizing both independent loops and dataflow tasks.},
   keywords = {multiprocessing systems
parallel processing
parallelization
EUROPLEXUS industrial simulation code
PLASMA
QUARK
dense linear algebra
OpenMP
performance penalty
dataflow tasks
fork-join tasks
parallel independent loops
multiparallel paradigms
multicore architectures
X-KAAPI multiparadigm runtime
Runtime
Multicore processing
Plasmas
Load modeling
Computational modeling
Instruction sets
Adaptation models},
   ISBN = {2332-5690},
   DOI = {10.1109/ICPP.2013.86},
   year = {2013},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Geisler, B. J. and Mitropoulos, F. J. and Kavage, S.},
   title = {GAMESPECT: Aspect Oriented Programming for a Video Game Engine using Meta-languages},
   booktitle = {2019 SoutheastCon},
   pages = {1-8},
   abstract = {Video game programming is an area where code duplication is extremely prevalent. Similar types of tasks are performed in multiple places throughout a game engine codebase. For example: game balance, logging, and memory allocation are just a few of the areas which are located across disparate locations of the codebase. Meanwhile, aspect oriented programming (AOP) was created to make use of common themes in a codebase and allow for advice to be given during compilation or runtime. GAMESPECT is a Domain Specific language (DSL) which resides in a higher level language space, above the typical languages used by game engines such as Unreal Engine 4. The language is written with the popular XText language toolset and contains advices in the spirit of aspect oriented programming: point cuts and join points. These advices can be executed at runtime when the programmer wants to finetune values or perform debugging. The advising is made possible through the Clang toolchain. Unique to this approach, GAMESPECT takes a source language and converts into multiple target languages. Depending on the context, GAMESPECT can generate C++, LUA, Blueprints or Skookum Script. This type of source to source translation is made possible through GAMESPECT’s “composition specifications”. With GAMESPECT, video game designers can increase their productivity and reduce the required lines of code for certain tasks by a 9–40% reduction. In addition, it provides for an AOP platform which is agnostic to the underlying game code. The applicability of this approach extends beyond game programming into software engineering as a whole.},
   keywords = {Games
Engines
Weaving
Programming
C++ languages
DSL
Tools
multilanguage
metalanguage
aspect oriented
video game engine
scripting language
UE4},
   ISBN = {1558-058X},
   DOI = {10.1109/SoutheastCon42311.2019.9020369},
   year = {2019},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Gerl, A. and Becher, S.},
   title = {Policy-Based De-Identification Test Framework},
   booktitle = {2019 IEEE World Congress on Services (SERVICES)},
   volume = {2642-939X},
   pages = {356-357},
   abstract = {Protecting privacy of individuals is a basic right, which has to be considered in our data-centered society in which new technologies emerge rapidly. To preserve the privacy of individuals de-identifying technologies have been developed including pseudonymization, personal privacy anonymization, and privacy models. Each having several variations with different properties and contexts which poses the challenge for the proper selection and application of de-identification methods. We tackle this challenge proposing a policy-based de-identification test framework for a systematic approach to experimenting and evaluation of various combinations of methods and their interplay. Evaluation of the experimental results regarding performance and utility is considered within the framework. We propose a domain-specific language, expressing the required complex configuration options, including data-set, policy generator, and various de-identification methods.},
   keywords = {data protection
policy-based de-identification test framework
data-centered society
personal privacy anonymization
privacy models
privacy protection
pseudonymization
domain-specific language
Privacy
Data models
General Data Protection Regulation
Load modeling
Distributed information systems
Generators
Big Data
Data privacy
Domain specific language
Performance evaluation
Privacy preserving},
   ISBN = {2642-939X},
   DOI = {10.1109/SERVICES.2019.00101},
   year = {2019},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Getir, S. and Challenger, M. and Demirkol, S. and Kardas, G.},
   title = {The Semantics of the Interaction between Agents and Web Services on the Semantic Web},
   booktitle = {2012 IEEE 36th Annual Computer Software and Applications Conference Workshops},
   pages = {619-624},
   abstract = {Development of agent systems is naturally a complex task due to the fundamental characteristics of agents. In addition, agent internals and inter-agent behavior models inside Multi-agent Systems (MAS) may become even more difficult to implement when interactions of agents with web services on the Semantic Web are taken into account. Our approach consists of the utilization of a Domain-specific Modeling Language (DSML) during MAS development in order to cope with the abovementioned challenge. This paper describes how the formal semantics of this DSML can be defined by especially focusing on its viewpoint on agent-semantic service interactions and discusses the use of this semantics definition on MAS validation. Determined semantic rules are both defined and implemented by using Alloy specification language which has a strong description capability based on both relational and first-order logic.},
   keywords = {formal logic
multi-agent systems
semantic Web
simulation languages
specification languages
Web services
interaction semantics
agent system development
agent internal behavior models
interagent behavior models
multiagent systems
domain-specific modeling language
DSML
formal semantics
agent-semantic service interactions
MAS validation
semantic rules
Alloy specification language
relational logic
first-order logic
Semantics
Metals
Grounding
Analytical models
Syntactics
Semantics of Languages
Alloy
Domain Specific Modeling Languages},
   DOI = {10.1109/COMPSACW.2012.112},
   year = {2012},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Giachetti, G. and Marin, B. and Pastor, O.},
   title = {Using UML profiles to interchange DSML and UML models},
   booktitle = {2009 Third International Conference on Research Challenges in Information Science},
   pages = {385-394},
   abstract = {A key requirement for MDD solutions is to have a modeling language that allows the correct representation of conceptual models. Nowadays, there are two options that are the most widely used for the definition of these modeling languages: 1) the specification of a domain-specific modeling language (DSML) or 2) the customization of UML. In practice, these two modeling alternatives are viewed as opposite solutions. However, since both alternatives provide benefits for the application of MDD solutions, in this paper, we present a proposal that uses UML profile extension mechanisms to interchange modeling information between DSML-based models and UML models. This proposal shows how these two modeling alternatives can be integrated in a unique MDD solution.},
   keywords = {formal specification
specification languages
DSML models
MDD solutions
domain-specific modeling language
UML profile extension mechanisms
Unified modeling language
Proposals
Costs
Documentation
UML profile
DSML
UML
MDD},
   ISBN = {2151-1357},
   DOI = {10.1109/RCIS.2009.5089302},
   year = {2009},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Gibbs, J. D. and Sarjoughian, H. S.},
   title = {Assessing the impact of a modeling tool and its support for verification and validation},
   booktitle = {2009 International Symposium on Performance Evaluation of Computer & Telecommunication Systems},
   volume = {41},
   pages = {73-80},
   abstract = {Domain-specific tools for modeling and simulation (M&S) of computer network systems are aimed at simplifying the tasks of model developers and simulationists. In determining the extent to which a particular domain-specific M&S tool fits their needs, the developers must consider both how the tool can assist in the model development process, and how the tool may prevent or hinder them from achieving their objectives. We have considered two M&S tools in the domain of computer networks, IT Guru and the INET framework, and some of the ways in which they affect various aspects of simulation model development, with emphasis on the verification and validation (V&V) process as applied to net-centric enterprise systems. We have developed a metric for evaluating a domain-specific M&S tool based on certain qualitative characteristics. We will demonstrate how this metric can be applied to evaluate IT Guru and INET, and also offer some observations on how the metric can be applied to other domains besides computer networking.},
   keywords = {computer networks
formal verification
domain-specific modeling tool
computer network system
domain-specific simulation tool
model development process
IT Guru
INET framework
formal validation
net-centric enterprise system
Computer simulation
Computational modeling
Hardware
Computer science
Collaborative software
Software testing
Knowledge engineering
Logic
Access protocols
independent verification and validation
modeling
Net-Centric Enterprise Systems
OMNET++
OPNET},    year = {2009},
   type = {Conference Proceedings}
}

@article{
   author = {Gill, C. D. and Cytron, R. K. and Schmidt, D. C.},
   title = {Multiparadigm scheduling for distributed real-time embedded computing},
   journal = {Proceedings of the IEEE},
   journalAlt = {Proceedings of the IEEE},
   volume = {91},
   number = {1},
   pages = {183-197},
   abstract = {Increasingly complex requirements, coupled with tighter economic and organizational constraints, are making it hard to build complex distributed real-time embedded (DRE) systems entirely from scratch. Therefore, the proportion of DRE systems made up of commercial-off-the-shelf (COTS) hardware and software is increasing significantly. There are relatively few systematic empirical studies, however, that illustrate how suitable COTS-based hardware and software have become for mission-critical DRE systems. This paper provides the following contributions to the study of real-time quality-of-service (QoS) assurance and performance in COTS-based DRE systems: it presents evidence that flexible configuration of COTS middleware mechanisms, and the operating system (OS) settings they use, allows DRE systems to meet critical QoS requirements over a wider range of load and jitter conditions than statically configured systems; it shows that in addition to making critical QoS assurances, noncritical QoS performance can be improved through flexible support for alternative scheduling strategies; and it presents an empirical study of three canonical scheduling strategies; specifically the conditions that predict success of a strategy for a production-quality DRE avionics mission computing system. Our results show that applying a flexible scheduling framework to COTS hardware, OSs, and middleware improves real-time QoS assurance and performance for mission-critical DRE systems.},
   keywords = {quality of service
processor scheduling
distributed object management
embedded systems
application program interfaces
aerospace computing
multiparadigm scheduling
distributed real-time embedded computing
organizational constraints
economic constraints
commercial-off-the-shelf hardware
mission-critical DRE systems
quality-of-service assurance
QoS performance
avionics mission computing system
flexible scheduling framework
middleware
Embedded computing
Real time systems
Hardware
Mission critical systems
Economic forecasting
Operating systems
Jitter},
   ISSN = {1558-2256},
   DOI = {10.1109/JPROC.2002.805822},
   year = {2003},
   type = {Journal Article}
}

@inproceedings{
   author = {Greifenberg, T. and Look, M. and Roidl, S. and Rumpe, B.},
   title = {Engineering tagging languages for DSLs},
   booktitle = {2015 ACM/IEEE 18th International Conference on Model Driven Engineering Languages and Systems (MODELS)},
   pages = {34-43},
   abstract = {To keep a DSL clean, readable and reusable in different contexts, it is useful to define a separate tagging language. A tag model logically adds information to the tagged DSL model while technically keeping the artifacts separated. Using a generic tagging language leads to promiscuous tag models, whereas defining a target DSL-specific tag language has a high initial overhead. This paper presents a systematic approach to define a DSL-specific tag language and a corresponding schema language, combining the advantages of both worlds: (a) the tag language specifically fits to the DSL, (b) the artifacts are kept separated and enabling reuse with different tag decorations, (c) the tag language follows a defined type schema, and (d) systematic derivation considerably reduces the effort necessary to implement the tag language. An example shows that it can at least partially be realized by a generator and applied for any kind of DSL.},
   keywords = {formal specification
specification languages
MDSE
model-driven software engineering
schema language
DSL-specific tag language
domain specific language
tagging language
Unified modeling language
DSL
Tagging
Monitoring
Generators
Grammar
Context
Software Engineering
Modeling
MDE
GSE},
   DOI = {10.1109/MODELS.2015.7338233},
   year = {2015},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Grobelny, P.},
   title = {The expert system approach in development of loosely coupled software with use of Domain Specific Language},
   booktitle = {2008 International Multiconference on Computer Science and Information Technology},
   pages = {119-123},
   abstract = {This paper addresses the problem of supporting the software development process through the artificial intelligence. The expert systems could advise the domain engineer in programming without the detailed experience in programming languages. He will use and integrate, with the help of deductive database and domain knowledge, the previously developed software components to new complex functionalities. The service oriented architecture (SOA) and loosely coupled software allow to fulfill these requirements. The objective of this document is to provide the knowledge representation of atomic Web services which will be registered as the facts in the deductive database as well as the inferring techniques. Also, the use of domain specific language (DSL) for modeling domain engineerpsilas requests to the expert system will be considered within this document.},
   keywords = {deductive databases
expert systems
knowledge representation
programming languages
software architecture
Web services
expert system
loosely coupled software
domain specific language
software development process
artificial intelligence
deductive database
domain knowledge
software components
service oriented architecture
atomic Web services
Domain specific languages
Programming
Computer languages
DSL},
   DOI = {10.1109/IMCSIT.2008.4747227},
   year = {2008},
   type = {Conference Proceedings}
}

@inbook{
   author = {Gul, Agha and Peter, Wegner and Akinori, Yonezawa},
   title = {A Logical Theory of Concurrent Objects and Its Realization in the Maude Language},
   booktitle = {Research Directions in Concurrent Object-Oriented Programming},
   publisher = {MITP},
   pages = {314-390},
   abstract = {This chapter contains sections titled: Introduction, Maude and Concurrent Rewriting, Rewriting Logic, A Logical Theory of Concurrent Objects, Simple Maude, More Examples, Maude and MaudeLog as Multiparadigm Logic Programming Languages, Semantics, Related Work, Concluding Remarks, Acknowledgements, References},
   ISBN = {9780262297004}, http://ieeexplore.ieee.org/document/6277509   url = {http://ieeexplore.ieee.org/document/6277509},
   year = {2003},
   type = {Book Section}
}

@inproceedings{
   author = {Gulliksson, R. and Camilleri, J. J.},
   title = {A Domain-Specific Language for Normative Texts with Timing Constraints},
   booktitle = {2016 23rd International Symposium on Temporal Representation and Reasoning (TIME)},
   pages = {60-69},
   abstract = {We are interested in the formal modelling and analysis of normative documents containing temporal restrictions. This paper presents a new language for this purpose, based on the deontic modalities of obligation, permission, and prohibition. It allows the specification of normative clauses over actions, which can be conditional on guards and timing constraints defined using absolute or relative discrete time. The language is compositional, where each feature is encoded as a separate operator. This allows for a straightforward operational semantics and a highly modular translation into timed automata. We demonstrate the use of the language by applying it to a case study and showing how this can be used for testing, simulation and verification of normative texts.},
   keywords = {formal languages
programming language semantics
domain-specific language
normative texts
timing constraints
formal modelling
formal analysis
normative documents
temporal restrictions
deontic modalities
normative clauses
relative discrete time
operational semantics
highly modular translation
timed automata
Contracts
Semantics
Syntactics
Automata
Proposals
Delays
electronic contracts
UPPAAL
QuickCheck
embedded DSL},
   ISBN = {2332-6468},
   DOI = {10.1109/TIME.2016.14},
   year = {2016},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Guo, X. and Dutta, R. G. and Mishra, P. and Jin, Y.},
   title = {Automatic RTL-to-Formal Code Converter for IP Security Formal Verification},
   booktitle = {2016 17th International Workshop on Microprocessor and SOC Test and Verification (MTV)},
   pages = {35-38},
   abstract = {The wide usage of hardware intellectual property (IP) cores from untrusted vendors has raised security concerns in the integrated circuit (IC) industry. Existing testing methods are designed to validate the functionality of the hardware IP cores. These methods often fall short in detecting unspecified (often malicious) logic. Formal methods like Proof-Carrying Hardware (PCH), on the other hand, can help eliminate hardware Trojans and/or design backdoors by formally proving security properties on soft IP cores despite the high proof development cost. One of the causes to the high cost is the manual conversion of the hardware design from RTL code to a domain-specific language prior to verification. To mitigate this issue and to lower the overall cost of PCH framework, we propose an automatic code converter for translating VHDL to Formal-HDL, a domain specific language for representing hardware designs in Coq language. Our code converter provides support to wide variety of hardware designs. Towards the goal of speeding up the verification procedure in our PCH framework, the code converter is the important first step. The applicability of the tool is demonstrated by converting soft IP cores of AES to its Coq equivalent code.},
   keywords = {codes
convertors
formal verification
hardware description languages
logic circuits
microprocessor chips
security
Coq equivalent code
AES
Coq language
formal-HDL
VHDL
domain-specific language
soft IP cores
security properties
hardware Trojans
PCH
proof-carrying hardware
hardware IP cores
integrated circuit industry
intellectual property
IP security formal verification
automatic RTL-to-formal code converter
Hardware
IP networks
Hardware design languages
Trojan horses
Syntactics
Hardware Security
Hardware IP Protection},
   ISBN = {2332-5674},
   DOI = {10.1109/MTV.2016.23},
   year = {2016},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Haghighi, M. and Cliff, D.},
   title = {Multi-agent Support for Multiple Concurrent Applications and Dynamic Data-Gathering in Wireless Sensor Networks},
   booktitle = {2013 Seventh International Conference on Innovative Mobile and Internet Services in Ubiquitous Computing},
   pages = {320-325},
   abstract = {WSNs have gained increasing attention for monitoring various variables of interest for wide variety of applications ranging from tracking environmental conditions to medical and structural monitoring. There are many WSN hardware platforms with a wide range of on-board resources. There also exist many software solutions for programming and re-programming WSNs. Most of the existing software solutions are either tightly coupled to their associated hardware, or very application-specific. Such diversity introduces many challenges for application developers. In this paper we propose a novel middleware solution, which runs on Java (SE and ME) programming platforms for easy task distribution and data gathering integrated in a modulated architecture that supports the serving of multiple concurrent applications, dynamic reprogramming, good scalability, and multiple operational paradigms.},
   keywords = {Java
middleware
multi-agent systems
multiprocessing programs
software architecture
telecommunication computing
wireless sensor networks
multiagent support
multiple concurrent applications
dynamic data-gathering
WSN hardware platforms
on-board resources
software solutions
middleware solution
Java SE programming platforms
Java ME programming platforms
task distribution
modulated architecture
dynamic reprogramming
Hardware
Sun
Monitoring
Sensomax
multi-agent
concurrency
dynamic
WSN
multi-paradigm},
   DOI = {10.1109/IMIS.2013.60},
   year = {2013},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Hahn, C. and Nesbigall, S. and Warwas, S. and Zinnikus, I. and Klusch, M. and Fischer, K.},
   title = {Model-driven Approach to the Integration of Multiagent Systems and Semantic Web Services},
   booktitle = {2008 12th Enterprise Distributed Object Computing Conference Workshops},
   pages = {317-324},
   abstract = {This paper discusses an innovative mean on model-driven agent-based coordination of semantic Web services. The general idea is to define a platform independent meta-model for semantic Web services and integrate it into a platform independent metamodel for multiagent systems. A model-driven semantic Web services matchmaker agent in combination with model transformations between the platform independent metamodel and existing semantic Web service formats like OWL-S allow the seamless integration of semantic Web services into multiagent systems.},
   keywords = {knowledge representation languages
multi-agent systems
semantic Web
software agents
Web services
model-driven agent-based coordination approach
multiagent system
semantic Web service matchmaker agent
platform independent metamodel
model transformation
OWL-S
domain specific modeling language
agent-oriented software engineering
Multiagent systems
Service oriented architecture
Artificial intelligence
Outsourcing
Face detection
Collaboration
Humans
Engines},
   ISBN = {2325-6605},
   DOI = {10.1109/EDOCW.2008.43},
   year = {2008},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Hallo, L. and Payne, B. and Gorod, A.},
   title = {Model-Based Approach to System of Systems Engineering: Reevaluating the Role of Simulation},
   booktitle = {2019 14th Annual Conference System of Systems Engineering (SoSE)},
   pages = {266-271},
   abstract = {The complexity of modern engineered systems is growing quickly due to the rapidly evolving nature of today's environment. Current management practices are limited in their structural capacity for coping with such swift transformation, pointing to an urgent need for new approaches in management of complex engineered systems. The model-based approach has emerged as a new promising method to complexity management. However, it is still unclear what role simulation plays in this approach and whether the role differs based on the type of a system under consideration and/or the degree of complexity involved. In this paper, the authors conduct a comparative analysis between the disciplines of System Engineering (SE) and System of Systems Engineering (SoSE), and the significance of simulation in these areas. The paper concludes that simulation represents a major part of modeling of System of Systems (SoS), leading the authors to introduce a new term, Modeling and Simulation Based System of Systems Engineering (M&SBSoSE), to underline the importance of incorporating and integrating simulation into modeling applications in SoSE. It is further also proposed that simulation of SoS should be multi-paradigm to increase the scope of simulation effectiveness in a complex dynamic environment.},
   keywords = {computer simulation
formal specification
systems engineering
model-based approach
modern engineered systems
complex engineered systems
complexity management
complex dynamic environment
management practices
system engineering
modeling and simulation based system of systems engineering
System of Systems Engineering
Simulation
Modeling
Model-Based Systems Engineering (MBSE)
Modeling and Simulation Based System of Systems Engineering (M&SBSoSE)},
   DOI = {10.1109/SYSOSE.2019.8753868},
   year = {2019},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Hamdaqa, M. and Tahvildari, L.},
   title = {Stratus ML: A Layered Cloud Modeling Framework},
   booktitle = {2015 IEEE International Conference on Cloud Engineering},
   pages = {96-105},
   abstract = {The main quest for cloud stakeholders is to find an optimal deployment architecture for cloud applications that maximizes availability, minimizes cost, and addresses portability and scalability. Unfortunately, the lack of a unified definition and adequate modeling language and methodologies that address the cloud domain specific characteristics makes architecting efficient cloud applications a daunting task. This paper introduces Stratus ML: a technology agnostic integrated modeling framework for cloud applications. Stratus ML provides an intuitive user interface that allows the cloud stakeholders (i.e., providers, developers, administrators, and financial decision makers) to define their application services, configure them, specify the applications' behaviour at runtime through a set of adaptation rules, and estimate cost under diverse cloud platforms and configurations. Moreover, through a set of model transformation templates, Stratus ML maintains consistency between the various artifacts of cloud applications. This paper presents Stratus ML and illustrates its usefulness and practical applicability from different stakeholder perspectives. A demo video, usage scenario and other relevant information can be found at the Stratus ML webpage.},
   keywords = {cloud computing
software architecture
stratus ML
layered cloud modeling framework
cloud stakeholders
optimal deployment architecture
cloud applications
unified definition
adequate modeling language
cloud domain specific characteristics
intuitive user interface
Stratus ML Web page
Clouds
Adaptation models
Unified modeling language
Availability
Computational modeling
Runtime
Software
Cloud Modeling Framework
Domain Specific Modeling Language
StratusML
Template-based Model Transformation},
   DOI = {10.1109/IC2E.2015.42},
   year = {2015},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Hamdi, H. and Mosbah, M.},
   title = {A DSL Framework for Policy-Based Security of Distributed Systems},
   booktitle = {2009 Third IEEE International Conference on Secure Software Integration and Reliability Improvement},
   pages = {150-158},
   abstract = {Securing distributed systems remains a significant challenge for several reasons. First, the security features required in an application may depend on the environment in which the application is operating, the type of data exchanged, and the capability of the end-points of communication. Second, the security mechanisms deployed could apply to both communication and application layers in the system, making it difficult to understand and manage overall system security. This paper presents a policy-based approach to meeting these needs. We propose a framework based on a domain-specific language for the specification, verification and implementation of security policies for distributed systems. Based on a set of abstractions, this framework allows to develop modular security policies and independent of the underlying system. Thus, security policies can be developed by a developer who is not necessarily computer security expert.},
   keywords = {formal specification
program verification
programming languages
security of data
domain-specific language
policy-based security
distributed systems
data exchange
system security
specification
verification
DSL
Communication system security
Data security
Domain specific languages
Computer security
Peer to peer computing
Costs
Distributed computing
Context-aware services
Authorization
Security policy
compilation
implementation},
   DOI = {10.1109/SSIRI.2009.43},
   year = {2009},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Harrison, W. L. and Allwein, G.},
   title = {Language Abstractions for Hardware-based Control-Flow Integrity Monitoring},
   booktitle = {2018 International Conference on ReConFigurable Computing and FPGAs (ReConFig)},
   pages = {1-6},
   abstract = {Control-Flow Integrity (CFI) is a software protection mechanism that detects a class of code reuse attacks by identifying anomalous control-flows within an executing program. Hardware-based CFI has the promise of the security benefits of CFI without the performance overhead and complexity of software-based CFI: generally speaking, hardware-based monitors are more difficult to bypass, offer lower performance overheads than software-based monitors, and, furthermore, hardware-based CFI can be performed without the necessity of altering application binaries or instrumenting language compilers. Although hardware-based CFI is an active area of research and there is a growing literature describing CFI strategies at a high-level, there is, to the authors' best knowledge, no work on languages specially tailored to the specification and implementation of CFI monitors. This article presents a proof-of-concept domain-specific language with built-in abstractions for expressing control-flow constraints along with a compiler that targets the functional hardware description language ReWire. While the case study is small, it indicates, we argue, an approach to rapid-prototyping hardware-based monitors enforcing CFI that is quick, flexible, and extensible as well as being amenable to formal verification.},
   keywords = {data flow analysis
formal verification
hardware description languages
program compilers
security of data
hardware-based control-flow integrity monitoring
anomalous control-flows
hardware-based CFI
software-based CFI
software-based monitors
instrumenting language compilers
CFI strategies
control-flow constraints
rapid-prototyping hardware-based monitors
functional hardware description language
ReWire language
Monitoring
Hardware
Biomedical monitoring
Security
Embedded systems
Computer languages
component
formatting
style
styling
insert},
   ISBN = {2640-0472},
   DOI = {10.1109/RECONFIG.2018.8641707},
   year = {2018},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {He, D. and Muller, G. and Lawall, J. L.},
   title = {Distributing MPEG movies over the Internet using programmable networks},
   booktitle = {Proceedings 22nd International Conference on Distributed Computing Systems},
   pages = {161-170},
   abstract = {Distributing video over the Internet is an increasingly important application. Nevertheless, the real-time and high bandwidth requirements of video make video distribution over today's Internet a challenge. Adaptive approaches can be used to respond to changes in bandwidth availability while limiting the effect of such changes on perceptual quality and resource consumption. Nevertheless, most existing adaptation mechanisms have limited scalability and do not effectively exploit the heterogeneity of the Internet. In this paper, we describe the design and implementation of a MPEG video broadcasting service based on active networks. In an active network, routers can be programmed to make routing decisions based on local conditions. Because decisions are made locally, adaptation reacts rapidly to changing conditions and is unaffected by conditions elsewhere in the network. Programmability allows the adaptation policy to be tuned to the structure of the transmitted data, and to the properties of local clients. We use the PLAN-P domain-specific language for programming active routers; this language provides high-level abstractions and safety guarantees that allow complex protocols to be developed rapidly and reliably. Our experiments show that our approach to video distribution permits the decoding of up to 9 times as many frames in a heavily loaded network as distribution using standard routers.},
   keywords = {Internet
telecommunication network routing
client-server systems
video servers
broadcasting
protocols
MPEG movie distribution
programmable networks
real-time high bandwidth requirements
MPEG video broadcasting service
active networks
routers
routing decisions
local conditions
programmability
adaptation policy
local clients
PLAN-P domain-specific language
high-level abstractions
safety guarantees
complex protocols
decoding
heavily loaded network
Motion pictures
IP networks
Bandwidth
Availability
Scalability
Multimedia communication
Routing
Domain specific languages},
   ISBN = {1063-6927},
   DOI = {10.1109/ICDCS.2002.1022253},
   year = {2002},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Heller, T. and Fey, D. and Rehak, M.},
   title = {An auto-tuning approach for optimizing base operators for non-destructive testing applications on heterogeneous multi-core architectures},
   booktitle = {16th IEEE International Symposium on Object/component/service-oriented Real-time distributed Computing (ISORC 2013)},
   pages = {1-9},
   abstract = {The field of non-destructive testing imposes rising performance requirements related to the compute resources necessary to satisfy application needs. The creation of scalable applications in that field, which efficiently utilize today's mostly heterogeneous compute resources has proven to be complicated. In order to allow domain experts coming from a materials science background, to exploit modern heterogenous computing architectures, new classes of frameworks for efficient applications need to be developed. This paper proposes a new framework to develop efficient operators and operator chains for applications in the field of non-destructive testing, based on a self-organizing autotuning approach. The framework provides a C++ Interface to define base operators and implements an Embedded Domain Specific Language (EDSL) using C++ Expression Templates (ETs) which allows a succinct definition of an Operator Chain. The framework applies various kinds of optimizations by utilizing C++ Template Metaprogramming techniques. These optimizations include feedback based auto-tuning and auto-parallelization of the resulting Pipeline based on the advanced dataflow and future's techniques provided by the High Performance ParalleX (HPX), a general purpose parallel C++ runtime system.},
   keywords = {C++ language
data flow computing
materials science computing
multiprocessing systems
nondestructive testing
parallel programming
pipeline processing
resource allocation
base operator optimization
nondestructive testing application
heterogeneous multicore architectures
performance requirements
heterogeneous compute resources
materials science
heterogenous computing architectures
operator chains
self-organizing autotuning approach
C++ interface
Embedded Domain Specific Language
EDSL
C++ expression templates
C++ template metaprogramming technique
feedback based autotuning
pipeline autoparallelization
advanced dataflow technique
High Performance ParalleX
HPX
general purpose parallel C++ runtime system
Optimization
Pipelines
Testing
Hardware
Abstracts
Multicore processing
Auto-Tuning
Auto-Parallelization
Non-destructive Testing},
   ISBN = {2375-5261},
   DOI = {10.1109/ISORC.2013.6913243},
   year = {2013},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Hentschel, M. and Delcroix, M. and Ogawa, A. and Nakatani, T.},
   title = {Feature-Based Learning Hidden Unit Contributions for Domain Adaptation of RNN-LMs},
   booktitle = {2018 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)},
   pages = {1692-1696},
   abstract = {In recent years, many approaches have been proposed for domain adaptation of neural network language models. These methods can be separated into two categories. The first is model-based adaptation, which creates a domain specific language model by re-training the weights in the network on the in-domain data. This requires domain annotation in the training and test data. The second is feature-based adaptation, which uses topic features to perform mainly bias adaptation of network input or output layers in an unsupervised manner. Recently, a scheme called learning hidden unit contributions was proposed for acoustic model adaptation. We propose applying this scheme to feature-based domain adaptation of recurrent neural network language model. In addition, we also investigate the combination of this approach with bias-based domain adaptation. For the experiments, we use a corpus based on TED talks and the CSJ lecture corpus to show perplexity and speech recognition results. Our proposed method consistently outperforms a pure non-adapted baseline and the combined approach can improve on pure bias adaptation.},
   keywords = {recurrent neural nets
speech recognition
unsupervised learning
RNN-LM
TED talks
CSJ lecture corpus
feature-based domain adaptation
acoustic model adaptation
network input
topic features
domain annotation
domain specific language model
neural network language models
bias-based domain adaptation
recurrent neural network language model
Adaptation models
Training
Acoustics
Data models
Artificial neural networks
Logic gates},
   ISBN = {2640-0103},
   DOI = {10.23919/APSIPA.2018.8659468},
   year = {2018},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Heuchert, M.},
   title = {Conceptual Modeling Meets Customer Journey Mapping: Structuring a Tool for Service Innovation},
   booktitle = {2019 IEEE 21st Conference on Business Informatics (CBI)},
   volume = {01},
   pages = {531-540},
   abstract = {Customer experience has become the main differentiator for competition in the digital age. Customer Journey Mapping (CJM) is a technique that aims to understand the customer's decision process and experience by taking a customer perspective and modeling his/her different steps. CJM facilitates innovation by proposing new or improved services. In a joint research project, we aimed at creating a CJM approach that allows for the participation of a broad audience in the creation process that especially has no experience in CJM or modeling. When studying the related literature, it becomes clear that methodological guidance in CJM is absent. While there are domain specific modeling languages for CJM, these do not include an overarching framework of how they should be carried out in an organizational setting. In lieu of proposing "yet another modeling language", we present a framework for CJM that embeds a modeling approach in an overarching method. We utilized the Action Design Research method to tackle our problem with the particular focus on the participation of inexperienced personnel. Then, we generalized the learnings from the development process into methodological guidelines.},
   keywords = {customer relationship management
decision making
innovation management
organisational aspects
simulation languages
CJM approach
domain specific modeling languages
modeling language
conceptual modeling
customer journey mapping
service innovation
customer experience
customer perspective
improved services
action design research method
methodological guidelines
digital age
Context modeling
Technological innovation
Grammar
Unified modeling language
Business
Conferences
Tools
Customer Journey Mapping, Conceptual Modeling, Action Research, Design Science},
   ISBN = {2378-1971},
   DOI = {10.1109/CBI.2019.00068},
   year = {2019},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Hill, J. H.},
   title = {Measuring and Reducing Modeling Effort in Domain-Specific Modeling Languages with Examples},
   booktitle = {2011 18th IEEE International Conference and Workshops on Engineering of Computer-Based Systems},
   pages = {120-129},
   abstract = {Domain-specific modeling languages (DSMLs) facilitate rapid and ``correct-by-construction'' realization of concepts for the target domain. Although DSMLs provide such benefits, there is implied (or hidden) modeling effort---in terms of user actions---associated with using a DSML that can negatively impact its effectiveness. It is therefore critical that DSML developers understand the meaning of modeling effort and how to reduce it so their DSML is of high quality. This paper provides two contributions to research on developing DSMLs. First, the paper defines a metric for measuring model effort. Secondly, this paper discusses several techniques, with examples, reducing (or improving) modeling effort. The techniques discussed in the paper have been applied to an open-source DSML called the Platform Independent Component Modeling Language (PICML), which is currently used in both academic and industry settings for designing and implementing large-scale distributed systems. Finally, results show that it is possible to reduce modeling effort without requiring user studies to analyze such concerns.},
   keywords = {distributed processing
object-oriented languages
public domain software
simulation languages
domain specific modeling language
correct-by-construction realization
DSML developers
modeling effort reduction
open source DSML
platform independent component modeling language
large-scale distributed system
Computational modeling
Mathematical model
Complexity theory
Analytical models
Humans
Computers
Semantics
domain-specific modeling languages
model complexity
measure
reduction},
   DOI = {10.1109/ECBS.2011.22},
   year = {2011},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Huai-Dong, Chen and Xiao-Zhen, Zhang},
   title = {A multi-paradigm learning model based on multi-agent technology},
   booktitle = {Proceedings. International Conference on Machine Learning and Cybernetics},
   volume = {3},
   pages = {1387-1390 vol.3},
   abstract = {This paper proposes a multiparadigm. learning model (MPLM) based on multiagent technology for learners. In this model, a psychological and emotional, model is introduced into student model, which makes the student model feed back the learning state of corresponding student better. Thus, teacher agent can meet the personalized needs. by adjusting the pedagogical paradigm and with the reorganization of learning resource of resource service agent. MPLM fulfils the learning and reviewing task through the collaboration of multiagents. This paper mainly discusses the frame model of MPLM and its working process as well.},
   keywords = {multi-agent systems
learning (artificial intelligence)
user modelling
feedback
computer aided instruction
multiparadigm learning model
multiagent technology
MPLM
psychological model
emotional, model
student model
feed back
personalized needs
Psychology
Problem-solving
Information science
Electronic mail
Feeds
Collaborative work
Communications technology
Distance learning
Computer science education
Time factors},
   DOI = {10.1109/ICMLC.2002.1167433},
   year = {2002},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Huang, C. and Osaka, A. and Kamei, Y. and Ubayashi, N.},
   title = {Automated DSL construction based on software product lines},
   booktitle = {2015 3rd International Conference on Model-Driven Engineering and Software Development (MODELSWARD)},
   pages = {1-8},
   abstract = {DSL (Domain-Specific Language) is one of the important approaches for software abstraction. In the past decades, DSLs have been provided by expert engineers familiar with domain knowledge and programming language processors. It is not easy for ordinary programmers to construct DSLs for their own purposes. To deal with this problem, we propose a language workbench called Argyle that can automatically generate a DSL by only specifying a set of functions needed to the DSL and an execution platform supported by the DSL. Argyle is based on software product lines and consists of the following two steps: 1) development of the core assets for constructing a family of DSLs and 2) DSL configuration using these core assets. To demonstrate the effectiveness of our approach, we developed a prototype DSL for supporting MSR (Mining Software Repositories), the most active research field in software engineering.},
   keywords = {programming languages
software product lines
automated DSL construction
software product line
domain-specific language
programming language processor
Argyle
MSR
mining software repository
software engineering
DSL
Metals
Program processors
Syntactics
Encoding
Language Workbench},    year = {2015},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Hudson, M. and Sprinkle, J.},
   title = {Simplification of Semantically-Rich Model Transformations through Generated Transformation Blocks},
   booktitle = {2011 18th IEEE International Conference and Workshops on Engineering of Computer-Based Systems},
   pages = {260-268},
   abstract = {This paper demonstrates a novel concept for the simplification of model transformations in which composite or complex objects are inserted into an existing model through a well-defined interface. The technique utilizes a model transformation from the domain of the modeling language into the domain of model transformation languages. The user specifies these semantically rich blocks using the original domain-specific modeling language. Then, a transformation generates the necessary model transformation graph to create an instance of the semantically rich, user-defined pattern. Users insert these generated patterns into their customized transformations. The approach is helpful for endogenous transformations in which existing objects may be refactored. It will also serve as a teaching tool for users who are unfamiliar with model transformations: specifically how to represent a newly-created model in the transformation domain. Finally, the approach is designed to reduce specification errors of model transformations in which new (semantically rich) blocks are inserted at key points, as the correctness of the semantically rich blocks is guaranteed, based on their construction in the original domain.},
   keywords = {graph theory
simulation languages
software engineering
semantically-rich model transformations
generated transformation blocks
domain-specific modeling language
model transformation graph
Unified modeling language
Computational modeling
Complexity theory
Generators
Syntactics
Mathematical model
Pattern matching
Model transformation
generative transformations
transformation simplification
domain-specific modeling},
   DOI = {10.1109/ECBS.2011.28},
   year = {2011},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Ilumoka, A. A.},
   title = {Efficient prediction of crosstalk in VLSI interconnections using neural networks},
   booktitle = {IEEE 9th Topical Meeting on Electrical Performance of Electronic Packaging (Cat. No.00TH8524)},
   pages = {87-90},
   abstract = {The unique approach proposed for VLSI crosstalk prediction involves the creation of parameterized models of primitive interconnect structures-wirecells-using modular artificial neural networks (MANNs). The finite element method, a circuit simulator and a neural network multi-paradigm prototyping system are coupled together to produce a library of re-usable MANN-based wirecell models.},
   keywords = {crosstalk
integrated circuit interconnections
VLSI
integrated circuit metallisation
integrated circuit packaging
neural nets
integrated circuit modelling
finite element analysis
circuit simulation
crosstalk prediction
VLSI interconnections
neural networks
VLSI crosstalk prediction
parameterized models
primitive interconnect structures
wirecells
modular artificial neural networks
MANNs
finite element method
circuit simulator
neural network multi-paradigm prototyping system
re-usable MANN-based wirecell model library
Very large scale integration
Artificial neural networks
Predictive models
Finite element methods
Virtual prototyping
Coupling circuits
Libraries},
   DOI = {10.1109/EPEP.2000.895499},
   year = {2000},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Ilumoka, A. A.},
   title = {Efficient prediction of interconnect crosstalk using neural networks},
   booktitle = {Proceedings 12th IEEE Internationals Conference on Tools with Artificial Intelligence. ICTAI 2000},
   pages = {122-125},
   abstract = {Interconnect crosstalk prediction has become increasingly important with deep submicron downscaling of ICs and wafer scale integration. Existing tools for management of the emi problem are computationally expensive and not very broad in application. The unique approach proposed involves the creation of parameterized models of primitive interconnect structures, wirecells, using modular artificial neural networks (MANNs). The finite element method, a circuit simulator and a neural network multi-paradigm prototyping system are coupled together to produce a library of re-usable MANN-based wirecell models. The method is especially attractive because it is capable of modeling the simultaneous effect of several uncorrelated variables such as interconnect length, width, thickness, separation, conductor and insulating medium characteristics on crosstalk and delay. Equi-coupling contours called isocouples are derived for noise characterization to guide design activities such as placement (e.g. matched devices placed on same isocouple). Experimental results from a transconductance amplifier demonstrate the viability of the approach.},
   keywords = {crosstalk
neural nets
finite element analysis
circuit simulation
integrated circuit interconnections
delays
wafer-scale integration
circuit CAD
interconnect crosstalk prediction
neural networks
deep submicron downscaling
wafer scale integration
wirecells
modular artificial neural networks
finite element method
circuit simulator
multiparadigm prototyping system
delay
equicoupling contours
isocouples
experimental results
transconductance amplifier
Artificial neural networks
Semiconductor device modeling
Finite element methods
Computational modeling
Virtual prototyping
Coupling circuits},
   ISBN = {1082-3409},
   DOI = {10.1109/TAI.2000.889856},
   year = {2000},
   type = {Conference Proceedings}
}

@article{
   author = {Ilumoka, A. A.},
   title = {Efficient and accurate crosstalk prediction via neural net-based topological decomposition of 3-D interconnect},
   journal = {IEEE Transactions on Advanced Packaging},
   journalAlt = {IEEE Transactions on Advanced Packaging},
   volume = {24},
   number = {3},
   pages = {268-276},
   abstract = {Crosstalk-related issues have become increasingly important with deep submicron downscaling of ICs and wafer scale integration. In today's systems-on-a-chip, the delay through a wire is often greater than the delay through the gate driving it. Furthermore, because of significant parasitic effects, crosstalk between signals on wires can cause major problems. Improved management of the EMI problem is made possible via EDA tools which have the capability of accurately and efficiently modeling electromagnetic interference effects in nanoscale VLSI. However, existing tools are computationally expensive and do not have broad application. The novel methodology proposed in this paper involves topological decomposition of small portions of interconnect (referred to as wirecells) at an extreme level of detail and the creation of parameterized models of these primitive interconnect structures using modular artificial neural networks (MANNs). The technique uses a finite element method program coupled with a circuit simulator and a neural network multi-paradigm prototyping system to produce a library of standard MANN-based wirecell models. It is especially attractive because none of the existing approaches is capable of fully modeling the simultaneous effect on delay and crosstalk of several uncorrelated variables such as interconnect length, width, thickness, separation, metal and insulating medium conductivity and relative permittivity for multiple systems of conductors. The library models derived are used to predict delay noise and crosstalk resulting from interconnect structures embedded in actual analog and digital circuitry.},
   keywords = {integrated circuit interconnections
crosstalk
electromagnetic interference
neural nets
integrated circuit modelling
VLSI
finite element analysis
circuit simulation
integrated circuit noise
integrated circuit packaging
electronic design automation
learning by example
delay estimation
topology
crosstalk prediction
neural net-based topological decomposition
3D interconnect
electromagnetic interference effects
EMI problem
wirecell models
parameterized models
modular artificial neural networks
modular ANNs
finite element method program
circuit simulator
neural network multi-paradigm prototyping system
delay noise
library models
noise characterization
packaging
FEM program
Neural networks
Artificial neural networks
Wafer scale integration
Delay systems
Wire
Electronic design automation and methodology
Electromagnetic modeling},
   ISSN = {1557-9980},
   DOI = {10.1109/6040.938293},
   year = {2001},
   type = {Journal Article}
}

@inproceedings{
   author = {Jacobi, S. and Hahn, C. and Raber, D.},
   title = {Integration of Multiagent Systems and Service Oriented Architectures in the Steel Industry},
   booktitle = {2010 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology},
   volume = {2},
   pages = {479-482},
   abstract = {In the course of globalization competitive pressure is rising in most industrial sectors. High quality products are basic prerequisites for companies of high wage countries to be present on the global market. Improved adherence to delivery date, increased flexibility despite to decreased production costs are some examples of the challenges to be managed just to keep current positions. In general, these requirements are mostly requirements on the processes - not on the actual products. Economic efficiency is not any longer just a property of products and quality, but more and more a property of processes. Thus, process capability is getting more important beside production capability. This paper shows how service-oriented architectures (SOA) and multi-agent systems (MAS) can be integrated using a model-driven approach. In fact, a model transformation from SoaML - a metamodel for SOA - to DSML4MAS - a domain-specific modeling language for MAS - is utilized for the integration. The relevance of this approach is proven by applying it to a real-world industry scenario. This includes modeling a segment of a production chain of Saarstahl AG - a global respected steel manufacturer. The presented approach helps to increase flexibility of mid and short term planning and scheduling along the chosen segment and thus improve processes.},
   keywords = {multi-agent systems
production engineering computing
production planning
scheduling
software architecture
steel industry
multiagent systems
service oriented architectures
globalization competitive pressure
high quality products
global market
process capability
economic efficiency
model driven approach
SoaML
metamodel
DSML4MAS
domain-specific modeling language
production chain
Saarstahl AG
short term planning
short term scheduling
Unified modeling language
Planning
Service oriented architecture
Steel
Supply chains
Materials
Service-Oriented Architectures
Model-driven Integration
MDA
model transformations},
   DOI = {10.1109/WI-IAT.2010.218},
   year = {2010},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Jacobs, A. and Conger, C. and George, A. D.},
   title = {Multiparadigm Space Processing for Hyperspectral Imaging},
   booktitle = {2008 IEEE Aerospace Conference},
   pages = {1-11},
   abstract = {Projected demands for future space missions, where on-board sensor processing and autonomous control rapidly expand computational requirements, are outpacing technologies and trends in conventional embedded microprocessors. To achieve higher levels of performance as well as relative performance versus power consumption, new processing technologies are of increasing interest for space systems. Technologies such as reconfigurable computing based upon FPGAs and vector processing based upon SIMD processor extensions, often in tandem with conventional software processors in the form of multiparadigm computing, offer a compelling solution. This paper will explore design strategies and mappings of a hyperspectral imaging (HSI) classification algorithm for a mix of processing paradigms on an advanced space computing system, featuring MPI-based parallel processing with multiple PowerPC microprocessors each coupled with kernel acceleration via FPGA and/or AltiVec resources. Design of key components of HSI including autocorrelation matrix calculation, weight computation, and target detection will be discussed, and hardware/software performance tradeoffs evaluated. Additionally, several parallel-partitioning strategies will be considered for extending single-node performance to a clustered architecture. Performance factors in terms of execution time and parallel efficiency will be examined on an experimental testbed. Power consumption will be investigated, and tradeoffs between performance and power consumption analyzed. This work is part of the Dependable Multiprocessor (DM) project at Honeywell and the University of Florida, one of the four experiments in the Space Technology 8 (ST-8) mission of NASA's New Millennium Program.},
   keywords = {aerospace computing
image classification
matrix algebra
microprocessor chips
parallel processing
reconfigurable architectures
multiparadigm space processing
hyperspectral imaging classification algorithm
space missions
onboard sensor processing
embedded microprocessors
space systems
reconfigurable computing
FPGA
vector processing
SIMD processor extensions
multiparadigm computing
advanced space computing system
MPI-based parallel processing
multiple PowerPC microprocessors
kernel acceleration
AltiVec resources
autocorrelation matrix calculation
weight computation
target detection
Dependable Multiprocessor project
Space Technology 8 mission
NASA New Millennium Program
Hyperspectral imaging
Space technology
Energy consumption
Microprocessors
Field programmable gate arrays
Hyperspectral sensors
Process control
Embedded computing
Algorithm design and analysis},
   ISBN = {1095-323X},
   DOI = {10.1109/AERO.2008.4526468},
   year = {2008},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Jiao, C. and Liu, B.},
   title = {ACD++: A domain specific language for cell-DEVS modelling},
   booktitle = {2017 9th International Conference on Modelling, Identification and Control (ICMIC)},
   pages = {277-283},
   abstract = {This paper introduces a library ACD++ for modeling and simulation of cellular models based on Cell-DEVS formalism. The goal is to allow the modeling of cellular models more flexible and adaptive. ACD++ is implemented in Ruby programming language, providing an internal Domain Specific Language (DSL) to simplify the construction of cellular models. Ruby's meta-programming characteristics and plentiful syntactic sugar enables the easy expression of complex logics behind the models. The Cell-DEVS formalism proved consistent with the DEVS hierarchy, improving the description of complex systems. Another strength lies in the extensibility of the DSL, allowing the modelers to introduce their domain specific vocabulary to facilitate the definition of specific models. The use of this library has allowed the development more flexible and adaptive, significantly reducing development time.},
   keywords = {cellular automata
discrete event simulation
discrete event systems
formal specification
large-scale systems
programming languages
specification languages
cellular models
Ruby programming language
internal Domain Specific Language
Cell-DEVS formalism
DEVS hierarchy
modelers
domain specific vocabulary
specific models
library ACD
Computer architecture
DSL
Microprocessors
Adaptation models
Integrated circuit modeling
Vocabulary
Couplings
Cell-DEVS
cellular model
modeling and simulation},
   DOI = {10.1109/ICMIC.2017.8321653},
   year = {2017},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Jiao, F. and Wang, L.},
   title = {A Business Component Model for Domain-Specific Software},
   booktitle = {2009 International Conference on Computational Intelligence and Software Engineering},
   pages = {1-4},
   abstract = {It is of practical significance and great value to find a component model for integrating software. Through the induction from a class of oil-drilling engineering applications, we proposed a modeling technique for domain-specific software based on business component component. In this paper, a goal-tree based domain-specific model for oil-drilling engineering is suggested. It offers the benefits of extensibility, modularity and reusability. Furthermore, a business component model for mapping domain-specific model into real system is proposed. The specialties of business component model contribute to the integration of heterogeneous modules.},
   keywords = {business data processing
integrated software
oil drilling
production engineering computing
software reusability
business component model
domain-specific software
software integration
oil-drilling engineering applications
mapping domain-specific model
heterogeneous modules
Business communication
Design engineering
Service oriented architecture
Computer integrated manufacturing
Drilling
Web services
Educational institutions
Scalability
Buildings
Application software},
   DOI = {10.1109/CISE.2009.5364062},
   year = {2009},
   type = {Conference Proceedings}
}

@article{
   author = {Jin-Shyan, Lee and Pau-Lo, Hsu},
   title = {Design and implementation of the SNMP agents for remote monitoring and control via UML and Petri nets},
   journal = {IEEE Transactions on Control Systems Technology},
   journalAlt = {IEEE Transactions on Control Systems Technology},
   volume = {12},
   number = {2},
   pages = {293-302},
   abstract = {For large-scale and long-distance distributed systems, this paper proposes a systematical multiparadigm approach to develop the simple network management protocol (SNMP) agents for remote monitoring and control. The standard unified modeling language (UML) is adopted for modeling the system, and then the Petri-net model is applied to achieve both qualitative and quantitative analyses for the system's dynamic behavior. In real applications, the present design can be further implemented with Java and ladder diagrams on programmable logic controllers (PLC). The developed system has been used successfully in a mobile switching center (MSC) of Taiwan Cellular Corporation for the remote monitoring and control, through the Internet, of its environmental conditions, including the temperature, humidity, power, and security, with a total of 316 sensors and 140 actuators.},
   keywords = {transport protocols
telecontrol
computerised monitoring
programmable controllers
Java
control system CAD
large-scale systems
control systems
Petri nets
specification languages
simple network management protocol agents
unified modeling language
remote monitoring
remote control
programmable logic controllers
long-distance distributed systems
large-scale distributed systems
systematical multiparadigm approach
ladder diagrams
mobile switching center
software-intensive system
application-level protocol
TCP/IP
client/server relationship
teleoperated Internet
Programmable control
Temperature sensors
Protocols
Humidity control},
   ISSN = {1558-0865},
   DOI = {10.1109/TCST.2004.824287},
   year = {2004},
   type = {Journal Article}
}

@inproceedings{
   author = {Johnston, D. and Fleury, M. and Downton, A.},
   title = {Multi-paradigm framework for parallel image processing},
   booktitle = {Proceedings International Parallel and Distributed Processing Symposium},
   pages = {8 pp.},
   abstract = {A software framework for the parallel execution of sequential programs using C++ classes is presented. The functional language Concurrent ML is used to implement the underlying harness and to design the programming interfaces. The hardware-independent harness promises a composable multi paradigm, unified approach to parallelism across different technologies: PowerPC, DSP and FPGA. Performance results for an image processing case study are given.},
   keywords = {image processing
parallel programming
C++ language
software libraries
ML language
software performance evaluation
parallel architectures
field programmable gate arrays
digital signal processing chips
multiprocessing systems
multi-paradigm framework
parallel image processing
software framework
parallel execution
sequential programs
C++ classes
functional language
Concurrent ML
programming interfaces
hardware-independent harness
composable multi paradigm
PowerPC
DSP
FPGA
performance results
Application software
Hardware
Synthetic aperture radar
Programming profession
Radar imaging
Large-scale systems
Computer architecture
Laboratories
Functional programming},
   ISBN = {1530-2075},
   DOI = {10.1109/IPDPS.2003.1213420},
   year = {2003},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Johnstone, A. and Scott, E.},
   title = {Generalised reduction modified LR parsing for domain specific language prototyping},
   booktitle = {Proceedings of the 35th Annual Hawaii International Conference on System Sciences},
   pages = {3666-3675},
   abstract = {Domain specific languages should support syntax that is comfortable,for specialist users. We discuss the impact of the standard deterministic parsing techniques such as LALR(1) and LL(1) on the design of programming languages and the desirability of more flexible parsers in a development environment. We present a new bottom-up nondeterministic parsing algorithm (GRMLR) that combines a modified notion of reduction with a Tomita-style breadth-first search of parallel parsing stacks. We give experimental results,for standard programming language grammars and LR(0), SLR(1) and LR(1) tables; the weaker tables generate significant amounts of nondeterminism. We show that GRMLR parsing corrects errors in the standard Tomita algorithm without incurring the performance overheads associated with other published solutions. We also demonstrate that the performance of GRMLR is upper-bounded by the performance of Tomita's algorithm, and that,for once realistic language grammar GRMLR only needs to search around 74% of the nodes. Our heavily instrumented development version of the algorithm achieves parsing rates of around 4000-10000 tokens per second on a 400 MHz Pentium II processor. Proof of correctness and details of our implementation are omitted here for space reasons but are available in an accompanying technical report.},
   keywords = {context-free grammars
high level languages
domain specific language prototyping
generalised reduction modified LR parsing
syntax
deterministic parsing techniques
LL(1)
LALR(1)
design programming languages
development environment
bottom-up nondeterministic parsing algorithm
reduction
breadth-first search
parallel parsing stacks
LR(1) tables
LR(0) tables
SLR(1) tables
nondeterminism
GRMLR
Pentium II processor
correctness proof
400 MHz
Domain specific languages
Prototypes
Computer science
Computer languages
Software engineering
Standards development
Error correction
Standards publication
Instruments
Writing},
   DOI = {10.1109/HICSS.2002.994495},
   year = {2002},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Kalnina, E. and Sostaks, A.},
   title = {Towards Concrete Syntax Based Find for Graphical Domain Specific Languages},
   booktitle = {2019 ACM/IEEE 22nd International Conference on Model Driven Engineering Languages and Systems Companion (MODELS-C)},
   pages = {236-242},
   abstract = {One of the main reasons why Model-Driven Engineering (MDE) technologies including Domain-specific modelling languages (DSML) have not reached the expected acceptance in the industry is a poor tool support. One of the features with a limited support even in commercial modelling tools is search (find). Typically, MDE tools support only a simple keyword-based textual search functionality. The same is true for the tools built using Domain-specific language (DSL) tool definition frameworks. It is proposed to provide the concrete syntax-based find functionality as a service of a DSL tool definition framework. The find diagrams are defined in a concrete syntax of a DSL. A definition of a DSL is used to provide a language-specific find functionality in the DSL tool.},
   keywords = {computational linguistics
formal specification
simulation languages
software engineering
software tools
specification languages
domain-specific modelling languages
commercial modelling tools
MDE tools support
DSL tool definition framework
syntax
keyword-based textual search functionality
model-driven engineering technologies
domain-specific language tool definition frameworks
graphical domain-specific languages
DSL tool definition frameworks
find},
   DOI = {10.1109/MODELS-C.2019.00038},
   year = {2019},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Karjalainen, M. and Maki-Patola, T.},
   title = {Physics-based modeling of musical instruments for interactive virtual reality},
   booktitle = {IEEE 6th Workshop on Multimedia Signal Processing, 2004.},
   pages = {223-226},
   abstract = {In this paper, we describe how different the physics-based modeling paradigms can be in making a sound synthesis of musical instruments. We also discuss different ways to construct user interfaces for interactive virtual reality applications. For multi-paradigm modeling, we have investigated how digital waveguides (DWGs), finite difference time domain schemes (DFTDs), wave digital filters (WDFs), modal decomposition models, and source-filter models interrelate and mix together. We have investigated both the user interface control of these models in a cave-like virtual room using special hand-held controllers. Modeling examples of a 'virtual air guitar" and a virtual bell-xylophone are described and demonstrated.},
   keywords = {musical instruments
virtual reality
user interfaces
finite difference time-domain analysis
wave digital filters
musical acoustics
acoustic signal processing
acoustic waveguides
acoustic wave scattering
musical instrument
interactive virtual reality
physics-based modeling paradigm
sound synthesis
multiparadigm modeling
digital waveguide
finite difference time domain scheme
wave digital filter
modal decomposition model
source-filter model
user interface control
virtual air guitar
virtual bell-xylophone
Instruments
Finite difference methods
Laboratories
Time domain analysis
Admittance
Digital filters},
   DOI = {10.1109/MMSP.2004.1436533},
   year = {2004},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Karrer, C. and Alicke, K. and Günther, H. O.},
   title = {Engineering adaptive production control strategies for complex discrete manufacturing - with an illustration from the EMS industry},
   booktitle = {2009 IEEE International Conference on Industrial Engineering and Engineering Management},
   pages = {1141-1145},
   abstract = {Shopfloor reality shows that many companies with complex discrete production systems have not yet found a satisfying approach to production control. Even though a large variety of theoretical approaches exists in literature, many companies do not engineer an individual production control strategy (PCS), but stick to sub-optimal standard logic provided by their Enterprise Resource Planning (ERP) software or to simple Kanban systems, what leads to suboptimal operational performance. We illustrate this challenge with a case study from industry and present an ongoing research effort to develop an engineering process to derive, parameterize, and update individual PCS. The process relies on a systems analysis perspective we propose and a simulation framework we developed. Important feedback loops known from Lean Manufacturing are considered. The vast solution space is explored starting from a simple hypothetical production system. Later, complexity drivers are stepwise reintegrated and the found dominant PCS is refined accordingly.},
   keywords = {adaptive control
enterprise resource planning
kanban
engineering adaptive production control
discrete manufacturing
complex discrete production system
production control strategy
enterprise resource planning software
Kanban system
systems analysis
feedback loops
lean manufacturing
complexity drivers
Programmable control
Production control
Medical services
Industrial control
Manufacturing industries
Personal communication networks
Electrical equipment industry
Companies
Production systems
systems engineering
multi-paradigm simulation
EMS industry},
   ISBN = {2157-362X},
   DOI = {10.1109/IEEM.2009.5372969},
   year = {2009},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Karsai, G. and Balasubramanian, D. and Dubey, A. and Otte, W. R.},
   title = {Distributed and Managed: Research Challenges and Opportunities of the Next Generation Cyber-Physical Systems},
   booktitle = {2014 IEEE 17th International Symposium on Object/Component/Service-Oriented Real-Time Distributed Computing},
   pages = {1-8},
   abstract = {Cyber-physical systems increasingly rely on distributed computing platforms where sensing, computing, actuation, and communication resources are shared by a multitude of applications. Such 'cyber-physical cloud computing platforms' present novel challenges because the system is built from mobile embedded devices, is inherently distributed, and typically suffers from highly fluctuating connectivity among the modules. Architecting software for these systems raises many challenges not present in traditional cloud computing. Effective management of constrained resources and application isolation without adversely affecting performance are necessary. Autonomous fault management and real-time performance requirements must be met in a verifiable manner. It is also both critical and challenging to support multiple end-users whose diverse software applications have changing demands for computational and communication resources, while operating on different levels and in separate domains of security. The solution presented in this paper is based on a layered architecture consisting of a novel operating system, a middleware layer, and component-structured applications. The component model facilitates the construction of software applications from modular and reusable components that are deployed in the distributed system and interact only through well-defined mechanisms. The complexity of creating applications and performing system integration is mitigated through the use of a domain-specific model-driven development process that relies on a domain-specific modeling language and its accompanying graphical modeling tools, software generators for synthesizing infrastructure code, and the extensive use of model-based analysis for verification and validation.},
   keywords = {cloud computing
embedded systems
fault diagnosis
formal verification
mobile computing
program verification
resource allocation
security of data
software architecture
specification languages
next generation cyber-physical systems
distributed computing platforms
cyber-physical cloud computing platform
mobile embedded devices
constrained resource management
application isolation
autonomous fault management
real-time performance requirements
computational resources
communication resources
security
operating system
middleware layer
component-structured applications
modular components
reusable components
domain-specific model-driven development process
domain-specific modeling language
graphical modeling tools
software generators
infrastructure code synthesis
model-based analysis
verification
validation
Kernel
Unified modeling language
Real-time systems
Computational modeling
Computer architecture
distributed systems
cyber-physical systems},
   ISBN = {2375-5261},
   DOI = {10.1109/ISORC.2014.36},
   year = {2014},
   type = {Conference Proceedings}
}

@article{
   author = {Karsai, G. and Sztipanovits, J. and Ledeczi, A. and Bapty, T.},
   title = {Model-integrated development of embedded software},
   journal = {Proceedings of the IEEE},
   journalAlt = {Proceedings of the IEEE},
   volume = {91},
   number = {1},
   pages = {145-164},
   abstract = {The paper describes a model-integrated approach for embedded software development that is based on domain-specific, multiple-view models used in all phases of the development process. Models explicitly represent the embedded software and the environment it operates in, and capture the requirements and the design of the application, simultaneously. Models are descriptive , in the sense that they allow the formal analysis, verification, and validation of the embedded system at design time. Models are also generative, in the sense that they carry enough information for automatically generating embedded systems using the techniques of program generators. Because of the widely varying nature of embedded systems, a single modeling language may not be suitable for all domains; thus, modeling languages are often domain-specific. To decrease the cost of defining and integrating domain-specific modeling languages and corresponding analysis and synthesis tools, the model-integrated approach is applied in a metamodeling architecture, where formal models of domain-specific modeling languages-called metamodels-play a key role in customizing and connecting components of tool chains. This paper discusses the principles and techniques of model-integrated embedded software development in detail, as well as the capabilities of the tools supporting the process. Examples in terms of real systems will be given that illustrate how the model-integrated approach addresses the physical nature, the assurance issues, and the dynamic structure of embedded software.},
   keywords = {embedded systems
software engineering
formal verification
embedded software development
design-space exploration
model verification
model-based development
model-integrated computing
modeling language
domain-specific modeling languages
formal analysis
formal validation
software generators
system engineering
Embedded software
Embedded system
Embedded computing
Microwave integrated circuits
Design engineering
Timing
Automatic programming
Costs
Metamodeling},
   ISSN = {1558-2256},
   DOI = {10.1109/JPROC.2002.805824},
   year = {2003},
   type = {Journal Article}
}

@inproceedings{
   author = {Kavimandan, A. and Gokhale, A.},
   title = {Automated Middleware QoS Configuration Techniques for Distributed Real-time and Embedded Systems},
   booktitle = {2008 IEEE Real-Time and Embedded Technology and Applications Symposium},
   pages = {93-102},
   abstract = {Quite often the modeling tools used in the development lifecycle of distributed real-time and embedded (DRE) systems are middleware-specific, where they elevate middleware artifacts, such as configuration options, to first class modeling entities. Unfortunately, this level of abstraction does not resolve the complex issues in middleware configuration process for QoS assurance. This paper describes GT-QMAP (graph transformation for QoS mapping) model-driven engineering toolchain that combines (1) domain-specific modeling, to simplify specifying the QoS requirements of DRE systems intuitively, and (2) model transformations, to automate the mapping of domain-specific QoS requirements to middleware-specific QoS configuration options. The paper evaluates the automation capabilities of GT-QMAP in the context of three DRE system case studies. The results indicate that on an average the modeling effort is reduced by over 75%. Further, the results also indicate that GT-QMAP provides significant benefits in terms of scalability and automation as DRE system QoS requirements evolve during its entire development lifecycle.},
   keywords = {middleware
quality of service
real-time systems
software engineering
automated middleware QoS configuration techniques
distributed real-time systems
embedded systems
middleware artifacts
QoS assurance
graph transformation
QoS mapping
QoS requirements
Real time systems
Embedded system
Model driven engineering
Automation
Resource management
Scalability
Laboratories
MDE
Graph/model transformations
Middleware QoS configuration},
   ISBN = {1545-3421},
   DOI = {10.1109/RTAS.2008.29},
   year = {2008},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Keep, A. and Chauhan, A.},
   title = {Concrete Partial Evaluation in Ruby},
   booktitle = {2008 IEEE Fourth International Conference on eScience},
   pages = {346-347},
   abstract = {Modern scientific research is a collaborative process, with researchers from many disciplines and institutions working toward a common goal. Dynamic languages, like Ruby, provide a platform for quickly developing simulation and analysis tools, freeing researchers to focus on research instead of spending time developing infrastructure. Ruby is a particularly good fit, allowing incorporation of existing C libraries, simplifying Domain Specific Language creation, and providing both REST and SOAP web-based API libraries. Ruby also provides RPC-style distributed programming. Concrete partial evaluation of Ruby begins to address Ruby's biggest flaw, performance. The scientific community has already begun to recognize the potential of Ruby. An MPI extension to the language allows quick prototyping of MPI programs. More recently libraries supporting MapReduce have appeared. Web frameworks, such as the popular Ruby on Rails framework, provide tools for producing and consuming REST APIs.},
   keywords = {application program interfaces
distributed programming
high level languages
Internet
remote procedure calls
software libraries
concrete partial evaluation
Ruby
scientific research
collaborative process
dynamic languages
simulation tools
analysis tools
C libraries
domain specific language creation
REST Web-based API libraries
SOAP Web-based API libraries
RPC-style distributed programming
MPI extension
Concrete
Libraries
Safety
Program processors
Performance evaluation
Computer science
Collaborative work
Computational modeling
Analytical models
Domain specific languages
C
partial evaluation},
   DOI = {10.1109/eScience.2008.141},
   year = {2008},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Kerbyson, D. J. and Hoisie, A.},
   title = {Performance Modeling of the Blue Gene Architecture},
   booktitle = {IEEE John Vincent Atanasoff 2006 International Symposium on Modern Computing (JVA'06)},
   pages = {252-259},
   abstract = {In this paper, we propose a multi-paradigm and multi-grain parallel execution model based on SMP-Cluster, which integrates coarse grain, mid grain and fine grain parallelism. Multiple paradigms supported by our model include task parallel, data parallel, sequential execution, data pipeline and task-farming paradigm. It can be achieved by extending the OpenMP specification, and the extensions include directives for computing resource partition, data distribution and alignment, sequential execution and data pipeline, and functions for Master/Slave model in Macro-Task group. We also compare the performance of different implementations of three benchmark applications, using the same numerical algorithm but employing different programming approaches},
   keywords = {parallel architectures
parallel machines
performance evaluation
performance modeling
Blue Gene/L architecture
supercomputer
Sweep 3D
kernel application
sensitivity analysis
Laboratories
Computer architecture
Performance analysis
Supercomputers
Kernel
Delay
Bandwidth
Carbon capture and storage
Clocks},
   DOI = {10.1109/JVA.2006.39},
   year = {2006},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Kharbili, M. El and Ma, Q. and Kelsen, P. and Pulvermueller, E.},
   title = {CoReL: Policy-Based and Model-Driven Regulatory Compliance Management},
   booktitle = {2011 IEEE 15th International Enterprise Distributed Object Computing Conference},
   pages = {247-256},
   abstract = {Regulatory compliance management is now widely recognized as one of the main challenges still to be efficiently dealt with in information systems. In the discipline of business process management in particular, compliance is considered as an important driver of the efficiency, reliability and market value of companies. It consists of ensuring that enterprise systems behave according to some guidance provided in the form of regulations. This paper gives a definition of the research problem of regulatory compliance. We show why we expect a formal policy-based and model-driven approach to provide significant advantages in allowing enterprises to flexibly manage decision-making related to regulatory compliance. For this purpose, we contribute CoReL, a domain-specific modeling language for representing compliance requirements that has a graphical concrete syntax. Informal semantics of CoReL are introduced and its use is illustrated on an example. CoReL allows to leverage business process compliance modeling and checking, enhancing it with regard to, among other dimensions, user-friendliness, genericity, and traceability.},
   keywords = {business data processing
decision making
information systems
simulation languages
CoReL
policy-based regulatory compliance management
model-driven regulatory compliance management
business process management
enterprise systems
decision-making management
domain-specific modeling language
business process compliance modeling
business process compliance checking
Unified modeling language
Printers
Syntactics
Analytical models
Semantics
Regulatory Compliance
Policy
Business Processes
Domain Specific Language},
   ISBN = {1541-7719},
   DOI = {10.1109/EDOC.2011.23},
   year = {2011},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Kirkham, T. and Matthews, B. and Bunakov, V. and Jeffery, K.},
   title = {CAMEL and the modelling of cloud lifecycles},
   booktitle = {eChallenges e-2014 Conference Proceedings},
   pages = {1-6},
   abstract = {CAMEL groups existing domain specific languages for applications deployed in Cloud computing environments. Linking common terms between standards CAMEL has been implemented using the Eclipse Modelling Framework as an EMF model. Initial applications of the standard have been done in the High Performance Computing and Enterprise application domains where DSLs have been integrate into CAMEL to enable greater management of the Cloud Lifecycle through mode domain specific modelling.},
   keywords = {cloud computing
parallel processing
specification languages
CAMEL
cloud lifecycles
domain specific languages
cloud computing environments
Eclipse modelling framework
EMF model
high performance computing
enterprise application domains
DSL
domain specific modelling
Standards
Business
Computational modeling
Adaptation models
Monitoring
Joining processes},
   ISBN = {2166-1677},    year = {2014},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Kocurova, A. and Oussena, S. and Clark, T.},
   title = {Applied metamodelling to collaborative document authoring},
   booktitle = {2012 Federated Conference on Computer Science and Information Systems (FedCSIS)},
   pages = {1385-1390},
   abstract = {This document describes a domain specific language tailored for collaborative document authoring processes. The language can support communication between content management systems and user interfaces in web collaborative applications. It allows dynamic rendering of user interfaces based on a collaboration model specified by end users. The construction of the language is supported by a metamodel. We demonstrate the use of the proposed language by describing an implemented simple document authoring system.},
   keywords = {authoring languages
content management
graphical user interfaces
groupware
Internet
personal computing
rendering (computer graphics)
simulation languages
text analysis
metamodelling
domain specific language
collaborative document authoring process
content management systems
user interfaces
Web collaborative applications
dynamic rendering
collaboration model
end users
Collaboration
DSL
Unified modeling language
Containers
Engines
collaborative authoring
multi-structured document},    year = {2012},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Kogekar, A. and Kaul, D. and Gokhale, A. and Vandal, P. and Praphamontripong, U. and Gokhale, S. and Jing, Zhang and Yuehua, Lin and Gray, J.},
   title = {Model-driven generative techniques for scalable performability analysis of distributed systems},
   booktitle = {Proceedings 20th IEEE International Parallel & Distributed Processing Symposium},
   pages = {8 pp.},
   abstract = {The ever increasing societal demand for the timely availability of newer and feature-rich but highly dependable network-centric applications imposes the need for these applications to be constructed by the composition, assembly and deployment of off-the-shelf infrastructure and domain-specific services building blocks. Service oriented architecture (SOA) is an emerging paradigm to build applications in this manner by defining a choreography of loosely coupled building blocks. However, current research in SOA does not yet address the per for mobility (i.e., performance and dependability) challenges of these modern applications. Our research is developing novel mechanisms to address these challenges. We initially focus on the composition and configuration of the infrastructure hosting the individual services. We illustrate the use of domain-specific modeling languages and model weavers to model infrastructure composition using middleware building blocks, and to enhance these models with the desired performability attributes. We also demonstrate the use of generative tools that synthesize metadata from these models for performability validation using analytical, simulation and empirical benchmarking tools.},
   keywords = {simulation languages
middleware
meta data
model-driven generative technique
scalable performability analysis
distributed system
service oriented architecture
domain-specific modeling language
middleware building block
generative tool
metadata
performability validation
analytical benchmarking tool
simulation tool
empirical benchmarking tool
model driven development
generative programming
Performance analysis
Application software
Computer science
Programming
Assembly
Information analysis
Computer networks
Distributed computing
Performability},
   ISBN = {1530-2075},
   DOI = {10.1109/IPDPS.2006.1639593},
   year = {2006},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Köllner, C. and Dummer, G. and Rentschler, A. and Müller-Glaser, K. D.},
   title = {Designing a Graphical Domain-Specific Modelling Language Targeting a Filter-Based Data Analysis Framework},
   booktitle = {2010 13th IEEE International Symposium on Object/Component/Service-Oriented Real-Time Distributed Computing Workshops},
   pages = {152-157},
   abstract = {We demonstrate the application of a Model-Driven Software Development (MDSD) methodology using the example of an analysis framework designed for a data logging device in the field of vehicle testing. This mobile device is capable of recording the data traffic of automotive-specific bus systems like Controller Area Network (CAN), Local Interconnect Network (LIN), FlexRay and Media Orientied Systems Transport (MOST) in real-time. In order to accelerate the subsequent analysis of the tremendous amount of data, it is advisable to pre-filter the recorded log data on device, during the test-drive. To enable the test engineer of creating data analyses we built a component-based library on top of the languages System{C}/C++. Problematic with this approach is that still substantial programming knowledge is required for implementing filter algorithms, which is usually not the domain of a vehicle test engineer. In a next step we developed a graphical modelling language on top of our library and a graphical editor. The editor is able of verifying a model as well as of generating source code which eliminates the need of manually implementing a filter algorithm. In our contribution we show the design of the graphical language and the editor using the Eclipse platform and the Graphical Modelling Framework (GMF). We describe the automatic extraction of meta-information, such as available components, their interfaces and categorization annotations by parsing the library's C++ implementation with the help of Xtext. The editor will use that information to build a dedicated tool palette providing components that the designer can instantiate and interconnect using drag-and-drop.},
   keywords = {automobile industry
automobiles
C++ language
data analysis
field buses
mechanical engineering computing
simulation languages
software engineering
visual languages
graphical domain-specific modelling language design
filter-based data analysis framework
model-driven software development methodology
data logging device
vehicle testing
automotive-specific bus systems
controller area network
local interconnect network
FlexRay
media oriented system transport
component-based library
C++ language parsing
System C language
vehicle test engineer
source code
Eclipse platform
graphical modelling framework
meta-information automatic extraction
categorization annotations
Libraries
Vehicles
Automotive engineering
Filters
Application software
Programming
Software testing
Communication system traffic control
Traffic control
graphical DSL
component-based modelling},
   DOI = {10.1109/ISORCW.2010.33},
   year = {2010},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Koschke, R. and Schmidt, U. and Berger, B.},
   title = {[Engineering Paper] Built-in Clone Detection in Meta Languages},
   booktitle = {2018 IEEE 18th International Working Conference on Source Code Analysis and Manipulation (SCAM)},
   pages = {165-170},
   abstract = {Developers often practice re-use by copying and pasting code. Copied and pasted code is also known as clones. Clones may be found in all programming languages. Automated clone detection may help to detect clones in order to support software maintenance and language design. Syntax-based clone detectors find similar syntax subtrees and, hence, are guaranteed to yield only syntactic clones. They are also known to have high precision and good recall. Developing a syntax-based clone detector for each language from scratch may be an expensive task. In this paper, we explore the idea to integrate syntax-based clone detection into workbenches for language engineering. Such workbenches allow developers to create their own domain-specific language or to create parsers for existing languages. With the integration of clone detection into these workbenches, a clone detector comes as a free byproduct of the grammar specification. The effort is spent only once for the workbench and not multiple times for every language built with the workbench. We report our lessons learned in applying this idea for three language workbenches: the popular parser generator ANTLR and two language workbenches for domain-specific languages, namely, MPS, developed by JetBrains, and Xtext, which is based on the Eclipse Modeling Framework.},
   keywords = {C language
computational linguistics
grammars
public domain software
software maintenance
software reusability
specification languages
copied code
pasted code
programming languages
automated clone detection
syntactic clones
syntax-based clone detection
domain-specific language
language workbenches
meta languages
engineering paper
syntax subtrees
language design
grammar specification
eclipse modeling framework
Cloning
Syntactics
Detectors
Grammar
Task analysis
Computer languages
Tools
software clones
duplicated code
language workbenchs
antlr
mps
Xtext},
   ISBN = {2470-6892},
   DOI = {10.1109/SCAM.2018.00026},
   year = {2018},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Krupaviciute, A. and Fayn, J. and Rubel, P. and Verdier, C. and McAdams, E. and Nugent, C.},
   title = {Information System Architecture for Wearable Cardiac Sensors Personalization},
   booktitle = {2009 14th IEEE International Conference on Engineering of Complex Computer Systems},
   pages = {265-272},
   abstract = {New medical devices and services enabling citizenpsilas health care anywhere and anytime are expected in the near future. However, to become a reality these devices must be supported by personalized services which satisfy user needs. In this paper we propose a general approach to manage the complexity of ambiguously related information for providing enhanced, user-specific services in the self-care domain. The global architecture is driven by a compositional model between a domain-specific and a context-awareness model, which aggregates the citizenpsilas and the devices profiles, the citizenpsilas healthcare characteristics and available signal processing methods. The final objective is to support automatic composition of services helping any citizen to select an optimal and personalized sensor system and to improve decision-making.},
   keywords = {biomedical transducers
decision making
health care
medical information systems
ubiquitous computing
information system architecture
wearable cardiac sensors personalization
user-specific services
self-care
domain-specific model
context-awareness model
signal processing methods
personalized sensor system
decision-making
pervasive computing
Information systems
Sensor systems
Wearable sensors
Context modeling
Context-aware services
Medical services
Computer architecture
Information analysis
Biomedical engineering
Wearable computers
pervasive systems
ambient intelligence
context-awareness
personalization
cardiac sensors},
   DOI = {10.1109/ICECCS.2009.32},
   year = {2009},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Kuhlmann, M. and Sohr, K. and Gogolla, M.},
   title = {Comprehensive Two-Level Analysis of Static and Dynamic RBAC Constraints with UML and OCL},
   booktitle = {2011 Fifth International Conference on Secure Software Integration and Reliability Improvement},
   pages = {108-117},
   abstract = {Organizations with stringent security requirements like banks or hospitals frequently adopt role-based access control (RBAC) principles to simplify their internal permission management. Authorization constraints represent a fundamental advanced RBAC concept enabling precise restrictions on access rights. Thereby, the complexity of the resulting security policies increases so that tool support for comfortable creation and adequate validation is required. We propose a new approach to developing and analyzing RBAC policies using UML for modeling RBAC core concepts and OCL to realize authorization constraints. Dynamic (i. e., time-dependent) constraints, their visual representation in UML and their analysis are of special interest. The approach results in a domain-specific language for RBAC which is highly configurable and extendable with respect to new RBAC concepts and classes of authorization constraints and allows the developer to validate RBAC policies in an effective way. The approach is supported by a UML and OCL validation tool.},
   keywords = {authorisation
program verification
Unified Modeling Language
role based access control principle
internal permission management
authorization constraint
RBAC concept
access rights
security policies
domain specific language
OCL validation tool
UML validation tool
two-level analysis
object constraint language
Authorization
Context
DSL
Analytical models
Concrete
RBAC
Security
Reliability
Modeling
UML/OCL
Analysis},
   DOI = {10.1109/SSIRI.2011.18},
   year = {2011},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Kumar, A. and Panda, S. P.},
   title = {A Survey: How Python Pitches in IT-World},
   booktitle = {2019 International Conference on Machine Learning, Big Data, Cloud and Parallel Computing (COMITCon)},
   pages = {248-251},
   abstract = {This paper lights on Python amongst other different programming paradigms used in the IT World, which enhances development speed. Although, Python was conceptualized in the late 1980s and after its implementation in 1989, it has emerged as a new multi-paradigm language platform with advent of Big Data. Python includes various data structures, standard libraries with the implementation of sentiment analysis and data science code. The real aim is to provide awareness to all the programmers about various facts of python language. It tells how Python works with various commercial and social communities and provides complete and desirable results. There are many areas and applications where Python makes its own stand as compared to other programming languages.},
   keywords = {Python
multiparadigm language platform
Big Data
data structures
sentiment analysis
data science code
programming paradigms
IT world
Python language
Libraries
Machine learning
Programming
Python data structures
Python Applications
Python standard libraries.},
   DOI = {10.1109/COMITCon.2019.8862251},
   year = {2019},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Kunicina, N. and Zabasta, A. and Nikiforova, O. and Romanovs, A. and Patlins, A.},
   title = {Modern tools of career development and motivation of students in Electrical Engineering Education},
   booktitle = {2018 IEEE 59th International Scientific Conference on Power and Electrical Engineering of Riga Technical University (RTUCON)},
   pages = {1-6},
   abstract = {Rapid development of Cyber-Physical Systems (CPS) products and applications, encouraged by advances on the Internet of Things, generates high market demand on engineers with a multi-disciplinary background in mathematics, mechanics, computer science and electrical engineering. One of the challenges in the development of study programs and motivation of students is bridging the gap between industry needs and educational output, in terms of training the prospective researchers and engineers in the CPS field. Riga Technical University (RTU), in cooperation with the other members of Multi-Paradigm Modelling for Cyber-Physical Systems MPM4CPS Cost Action, applied their knowledge and methods to validate in practice the viability of the approach and the methods developed in the COST Action in order to support the introduction of industry-focused curricula at Higher Education Institutions in Partner' countries. In this research, we discuss experience of RTU in motivation of the students in the subject of the electrical engineering. We also discuss how cooperation between COST and ERASMUS project teams provides benefits to both projects, how the COST team efforts towards analysis of tendencies, industry needs and acquiring best education practice, have been applied by ERASMUS+ team in order to create industry-focused curricula in CPS for HEIs of Partner Countries.},
   keywords = {computer aided instruction
cyber-physical systems
educational courses
educational institutions
further education
Internet of Things
power engineering education
education practice
industry-focused curricula
career development
electrical engineering Education
computer science
study programs
CPS field
Riga Technical University
RTU
MultiParadigm Modelling
Higher Education Institutions
COST team efforts
market demand
MPM4CPS cost action
ERASMUS project teams
HEI
Electrical engineering
education
industry-focused curriculum
ERASMUS+},
   DOI = {10.1109/RTUCON.2018.8659905},
   year = {2018},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Lacoste-Julien, S. and Vangheluwe, H. and Lara, J. de and Mosterman, P. J.},
   title = {Meta-modelling hybrid formalisms},
   booktitle = {2004 IEEE International Conference on Robotics and Automation (IEEE Cat. No.04CH37508)},
   pages = {65-70},
   abstract = {This article demonstrates how meta-modelling can simplify the construction of domain-and formalism-specific modelling environments. Using AToM3 (a tool for multi-formalism and meta-modelling developed at McGill University), a model is constructed of a hybrid formalism, HS, that combines event scheduling constructs with ordinary differential equations. From this specification, an HS-specific visual modelling environment is synthesized. For the purpose of this demonstration, a simple hybrid model of a bouncing ball is modelled in this environment. It is envisioned that the future of modelling and simulation in general, and more specifically in hybrid dynamic systems design lies in domain-specific computer automated multi-paradigm modelling (CAMPaM) which combines multi-abstraction, multi-formalism, and meta-modelling. The small example presented in this article demonstrates the feasibility of this approach},
   keywords = {differential equations
entity-relationship modelling
formal specification
graph grammars
software tools
metamodelling hybrid formalisms
domain modelling environment
AToM3 tool
multiformalism model
McGill University
event scheduling
ordinary differential equations
visual modelling environment
bouncing ball
hybrid dynamic system design
computer automated multiparadigm modelling
multiabstraction
Computational modeling
Computer simulation
Control system synthesis
Automatic control
Computer science
Virtual prototyping
Concrete},
   DOI = {10.1109/CACSD.2004.1393852},
   year = {2004},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Laforcade, P. and Zendagui, B.},
   title = {A Domain-Specific Modeling Approach for Supporting the Development of Visual Instructional Design Languages and Tools},
   booktitle = {2009 Ninth IEEE International Conference on Advanced Learning Technologies},
   pages = {744-746},
   abstract = {In this paper we present, discuss and illustrate our domain-specific modeling orientation for helping communities of instructional designers to specify visual instructional design languages and to develop dedicated user-friendly graphical editors.},
   keywords = {simulation languages
visual languages
domain-specific modeling approach
instructional designer
visual instructional design language
user-friendly graphical editor
Vocabulary
Humans
Metamodeling
Least squares approximation
Model driven engineering
Communities
Machine learning
Manuals
Process design
Unified modeling language},
   ISBN = {2161-377X},
   DOI = {10.1109/ICALT.2009.128},
   year = {2009},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Lämmel, R. and Pek, E.},
   title = {Vivisection of a Non-Executable, Domain-Specific Language - Understanding (the Usage of) the P3P Language},
   booktitle = {2010 IEEE 18th International Conference on Program Comprehension},
   pages = {104-113},
   abstract = {P3P is the policy language with which websites declare the intended use of data that is collected about users of the site. We have systematically collected P3P-based privacy policies from websites listed in the Google directory, and analysed the resulting corpus with regard to different levels of validity, size or complexity metrics, different cloning levels, coverage of language constructs, and the use of the language's extension mechanism. In this manner, we have found interesting characteristics of P3P in the wild. For instance, cloning is exceptionally common in this domain, and encountered language extensions exceed the base language in terms of grammar complexity. Overall, this effort helps understanding the de-facto usage of the non-executable, domain-specific language P3P. Some elements of our methodology may be useful for other software languages as well.},
   keywords = {data privacy
programming languages
domain-specific language
P3P language
P3P-based privacy policies
grammar complexity
software languages
privacy preferences project language
Domain specific languages
Privacy
Cloning
Vocabulary
Reverse engineering
Computer languages
Software engineering
Decision making
Navigation
Internet
empirical study
P3P
software language engineering
metrics
coverage},
   ISBN = {1092-8138},
   DOI = {10.1109/ICPC.2010.45},
   year = {2010},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Leber, F. and Scheible, J.},
   title = {A Procedural Approach to Automate the Manual Design Process in Analog Integrated Circuit Design},
   booktitle = {ANALOG 2018; 16th GMM/ITG-Symposium},
   pages = {1-6},
   abstract = {This paper presents a novel approach to automating the design of analog integrated circuits: (1) the Expert Design Plan (EDP), a procedural generator, and (2) the EDP Language, a high-level description language for writing an EDP. An EDP is a parameterizable, executable script, which reproduces a designer's course of action when designing a circuit. Thus, an EDP formalizes the design expert's knowledge-based strategy and makes it reusable. Since it is essential that an EDP represents a circuit designers way of thinking and working as close as possible, the designers themselves should be enabled to create the EDP. Therefor, our approach provides a input method through a domain-specific language called EDP Language (EDPL). Using this language is intuitive and requires no special training. In an exemplary implementation of our approach, a common-source amplifier is automatically sized using a set of only 10 instructions. Even in the first usage our EDP approach has appeared to be more efficient than the manual sizing process.},    year = {2018},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Ledeczi, A. and Nordstrom, G. and Karsai, G. and Volgyesi, P. and Maroti, M.},
   title = {On metamodel composition},
   booktitle = {Proceedings of the 2001 IEEE International Conference on Control Applications (CCA'01) (Cat. No.01CH37204)},
   pages = {756-760},
   abstract = {Computer-based systems (CBS) development integrates various disciplines, such as hardware design, software engineering, and performance modeling, as well as the "base" engineering discipline in which the CBS will operate. As such, use of a "non-native" modeling language is not acceptable when performing CBS design, and rapid specification and development of domain-specific modeling languages (DSMLs) is necessary. We advocate a UML-based metamodeling technique to DSML specification and generation. A key feature of our approach is the composition of new metamodels from existing metamodels through the use of three newly defined UML operators-equivalence, implementation inheritance, and interface inheritance. The paper describes the development of these new operators, details how they are used in metamodel composition, and presents examples of metamodel composition.},
   keywords = {specification languages
inheritance
metamodel composition
computer-based systems development
rapid specification
domain-specific modeling languages
UML-based metamodeling technique
operators-equivalence
implementation inheritance
interface inheritance
Unified modeling language
Hardware
Design engineering
Software systems
Software design
Software engineering
Physics computing
Software performance
Metamodeling
Information processing},
   DOI = {10.1109/CCA.2001.973959},
   year = {2001},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Lee, S. U. and Hofmann, A. and Williams, B.},
   title = {A Model-Based Human Activity Recognition for Human–Robot Collaboration},
   booktitle = {2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
   pages = {736-743},
   abstract = {Human activity recognition is a crucial ingredient in safe and efficient human-robot collaboration. In this paper, we present a new model-based human activity recognition system called logical activity recognition system (LCARS). LCARS requires much less training data compared to learning-based works. Compared to other model-based works, LCARS requires minimal domain-specific modeling effort from users. The minimal modeling is for two reasons: i) we provide a systematic and intuitive way to encode domain knowledge for LCARS and ii) LCARS automatically constructs a probabilistic estimation model from the domain knowledge. Requiring minimal training data and modeling effort allows LCARS to be easily applicable to various scenarios. We verify this through simulations and experiments.},
   keywords = {human-robot interaction
inference mechanisms
learning (artificial intelligence)
domain knowledge
LCARS
probabilistic estimation model
minimal training data
safe robot collaboration
efficient human-robot collaboration
model-based human activity recognition system
logical activity recognition system
learning-based works
minimal domain-specific
minimal modeling},
   ISBN = {2153-0866},
   DOI = {10.1109/IROS40897.2019.8967650},
   year = {2019},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Leitner, A. and Weib, R. and Kreiner, C.},
   title = {Extending the multi-modeling domain representation from problem space to solution space},
   booktitle = {2012 IEEE 19th International Conference and Workshops on Engineering of Computer-Based Systems},
   pages = {330-334},
   abstract = {The quality of the domain model is an important success factor in Software Product Line Engineering (SPLE). We identify Feature-Oriented Domain Modeling (FODM) and Domain-Specific Modeling (DSM) as the most important modeling approaches in practice. Especially for the representation of complex, heterogeneous domains the choice of an appropriate modeling paradigm is crucial. Often, one modeling approach is not sufficient to develop an efficient domain model. Previously [1], we suggested an approach for the combined representation of the problem space with different modeling approaches. This combined solution has two main advantages: First, different groups of stakeholders can use their familiar terminology and modeling notation. Second, the complexity of the domain model representation can be reduced. Here, we give ideas and pose research questions for the extension of this multi-modeling approach to the solution space. First, it has to be investigated whether or not it is possible to abstract different notations of the solution space in the same way as in the problem space. Second, the possibility to use this framework as a base for model integration has to be investigated and third, the impact of this extension on the representation complexity, an important quality metric, has to be evaluated. We believe that this is desirable because different challenges of SPLE as well as MBD can be addressed with the proposed approach.},
   DOI = {10.1109/ecbs.2012.6487437},
   year = {2012},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Lengyel, L. and Levendovszky, T. and Angyal, L.},
   title = {Identification of crosscutting constraints in metamodel-based model transformations},
   booktitle = {IEEE EUROCON 2009},
   pages = {359-364},
   abstract = {This Model-Driven Development (MDD) facilitates the synthesis of application programs from models created using customized, domain-specific model processors. Model compilers can be realized by graph rewriting-based model transformation. In Visual Modeling and Transformation System (VMTS), metamodel-based rewriting rules facilitate to assign OCL constraints to model transformation rules. This approach supports validated model transformation. Unfortunately, the validation introduces a new concern that often crosscuts the functional concern of the transformation rules. To separate these concerns, an aspect-oriented solution is applied for constraint management. This paper introduces the identification method of the crosscutting constraints in metamodel-based model transformation rules. The presented algorithms facilitate the better understanding of the transformation, their easier constraint-based configuration, and make both the constraints and the rewriting rules reusable.},
   keywords = {object-oriented programming
program compilers
program verification
rewriting systems
specification languages
crosscutting constraint management
metamodel-based model transformation rule
model-driven development
application program synthesis
customized domain-specific model processor
model compiler
graph rewriting-based model transformation
visual modeling and transformation system
VMTS
OCL constraint
software validation
aspect-oriented programming
Algorithm design and analysis
System testing
Weaving
Programming
Time factors
Automation
Informatics
Microwave integrated circuits
Computer architecture
Genetic mutations
Aspect-Oriented Constraints
Constraint Weaving
Identifying Crosscutting Constraints
Metamodel-Based Model Transformation
OCL},
   DOI = {10.1109/EURCON.2009.5167656},
   year = {2009},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Li, F. and Li, D. and Wan, J. and Huang, X.},
   title = {Towards a Component-Based Model Integration Approach for Embedded Computer Control System},
   booktitle = {2008 International Conference on Computational Intelligence and Security},
   volume = {1},
   pages = {495-499},
   abstract = {A component-based model integration approach for the embedded computer control system (ECS) development is proposed in this paper. The three-layer architecture for modeling, verification as well as implementation is described. Model strategies such as multi-aspect & multi-view description method, DSML (domain specific modeling language) & FML(formal modeling language) description method as well as hierarchical component based modeling method are put forward. The focus of our approach is on creating an integrated embedded computer control system development environment for design, verification as well as implementation.},
   keywords = {control engineering computing
embedded systems
formal verification
object-oriented programming
software reusability
specification languages
component-based model integration approach
embedded computer control system
three-layer architecture
multiaspect description method
multiview description method
DSML
domain specific modeling language
FML
formal modeling language
Embedded computing
Control system synthesis
Object oriented modeling
Computational modeling
Computer architecture
Embedded software
Embedded system
Real time systems
Domain specific languages
Unified modeling language},
   DOI = {10.1109/CIS.2008.218},
   year = {2008},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Li, G. and Kou, Y. and Jiang, J. and Lin, Y. and Bie, Z.},
   title = {Researches on the reliability evaluation of integrated energy system based on Energy Hub},
   booktitle = {2016 China International Conference on Electricity Distribution (CICED)},
   pages = {1-9},
   abstract = {In this paper, the concept of Energy Hub was introduced to capture the coupling between multiple energy forms such as electricity, gas, heat and cooling in an Integrated Energy Systems (IESs). The reliability model for Energy Hubs was established based on a Smart Agent Communication (SAC) algorithm. In the model, the energy conversion efficiency, failure rate and repair time for various energy supply systems were considered, and thus the effects of coupling among different energy types on the IES reliability were taken into account. According to the SAC algorithm, an Energy Hub was defined as a smart agent which can communicate with other smart agent. Combined with the Monte Carlo simulation, a reliability evaluation approach is presented based on the SAC algorithm and Energy Hub model. In the presented approach, fault localization, fault isolation, system reconfiguration and fault recovery can be implemented autonomously, which effectively improves the system status assessment efficiency during the reliability evaluation of IESs. Finally, the proposed models and approaches are applied on the multi-paradigm modeling and simulation platform-AnyLogic, and the effectiveness of the model is validated by extensive cases studies.},
   keywords = {failure analysis
fault diagnosis
Monte Carlo methods
power transmission reliability
integrated energy system reliability evaluation
coupling capture
multiple energy forms
smart agent communication algorithm
SAC algorithm
energy conversion efficiency
failure rate
repair time
energy supply system
IES reliability
Monte Carlo simulation
Energy Hub model
fault localization
fault isolation
system reconfiguration
fault recovery
status assessment efficiency
AnyLogic simulation platform
Reliability
Resistance heating
Power system reliability
Couplings
Wind speed
Maintenance engineering
Generators
Integrated energy system
Reliability evaluation
Energy hub
Smart agent communication},
   ISBN = {2161-749X},
   DOI = {10.1109/CICED.2016.7576209},
   year = {2016},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Liang, H. and Yang, Y. and Sun, L. and Jiang, L.},
   title = {JSAC: A Novel Framework to Detect Malicious JavaScript via CNNs over AST and CFG},
   booktitle = {2019 International Joint Conference on Neural Networks (IJCNN)},
   pages = {1-8},
   abstract = {JavaScript (JS) is a dominant programming language in web/mobile development, while it is also notoriously abused by attackers due to its powerful characteristics, e.g., dynamic, prototype-based and multi-paradigm, which foil most static and dynamic analysis approaches. To detect malicious JS instances, several machine learning-based methods have been developed recently. However, these methods took JS as a natural language instead of a programming one, which can not capture its syntactic and semantic features. In this paper, we present JSAC, a novel framework to detect JS malware. It combines deep learning and program analysis techniques to capture the syntactic and semantic features of JS programs. Specifically, to get a JS program's syntactic information, we build its abstract syntax tree and employ a tree-based convolutional neural network (CNN) to extract features from it. To get its semantic information, we construct its control flow graph and feed it to another graph-based CNN. Last, the features extracted from two CNNs are fused for final detection. Evaluation on a corpus of 69,523 JS files indicates that JSAC outperforms 4 other models with 98.73% F1-score in detecting JS malware.},
   keywords = {authoring languages
convolutional neural nets
flow graphs
invasive software
Java
learning (artificial intelligence)
program diagnostics
security of data
dynamic analysis approaches
malicious JS instances
machine learning-based methods
natural language
semantic features
JSAC
deep learning
program analysis techniques
abstract syntax tree
tree-based convolutional neural network
semantic information
control flow graph
graph-based CNN
detect malicious JavaScript
dominant programming language
dynamic prototype-based
syntactic language
JS malware detection
Feature extraction
Syntactics
Semantics
Malware
Neural networks
Natural language processing
Programming
Malicious JavaScript
CNN},
   ISBN = {2161-4407},
   DOI = {10.1109/IJCNN.2019.8851760},
   year = {2019},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Liang, L. and Lin, L. and Jin, L. and Xie, D. and Li, M.},
   title = {SCUT-FBP5500: A Diverse Benchmark Dataset for Multi-Paradigm Facial Beauty Prediction},
   booktitle = {2018 24th International Conference on Pattern Recognition (ICPR)},
   pages = {1598-1603},
   abstract = {Facial beauty prediction (FBP) is a significant visual recognition problem to make assessment of facial attractiveness that is consistent to human perception. To tackle this problem, various data-driven models, especially state-of-the-art deep learning techniques, were introduced, and benchmark dataset become one of the essential elements to achieve FBP. Previous works have formulated the recognition of facial beauty as a specific supervised learning problem of classification, regression or ranking, which indicates that FBP is intrinsically a computation problem with multiple paradigms. However, most of FBP benchmark datasets were built under specific computation constrains, which limits the performance and flexibility of the computational model trained on the dataset. In this paper, we argue that FBP is a multi-paradigm computation problem, and propose a new diverse benchmark dataset, called SCUT-FBP5500, to achieve multi-paradigm facial beauty prediction. The SCUT-FBP5500 dataset has totally 5500 frontal faces with diverse properties (male/female, Asian/Caucasian, ages) and diverse labels (face landmarks, beauty scores within [1], [5], beauty score distribution), which allows different computational models with different FBP paradigms, such as appearance-based/shape-based facial beauty classification/regression model for male/female of Asian/Caucasian. We evaluated the SCUT-FBP5500 dataset for FBP using different combinations of feature and predictor, and various deep learning methods. The results indicates the improvement of FBP and the potential applications based on the SCUT-FBP5500.},
   keywords = {face recognition
image classification
learning (artificial intelligence)
regression analysis
multiparadigm facial beauty prediction
facial attractiveness
data-driven models
SCUT-FBP5500 dataset
beauty score distribution
appearance-based/shape-based facial beauty classification/regression model
deep learning techniques
supervised learning problem
visual recognition problem
Benchmark testing
Databases
Computational modeling
Predictive models
Correlation
Standards},
   ISBN = {1051-4651},
   DOI = {10.1109/ICPR.2018.8546038},
   year = {2018},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Lima, K. and Marques, E. R. B. and Pinto, J. and Sousa, J. B.},
   title = {Programming Networked Vehicle Systems Using Dolphin - Field Tests at REP'17},
   booktitle = {2018 OCEANS - MTS/IEEE Kobe Techno-Oceans (OTO)},
   pages = {1-5},
   abstract = {The increasing availability and use of autonomous vehicles for real operational scenarios has led to the need for tools that allow human operators to interact with multiple systems effectively, taking into account their capabilities, limitations and environmental constraints. Multiple vehicles, deployed together in order to accomplish a common goal, impose a high burden on a human operator for specifying and executing coordinated behavior, particularly in mixed-initiative systems where humans are part of the control loop. In this paper, we describe experimental field tests for Dolphin, a domain-specific language that allows a single program to define the joint behaviour of multiple vehicles over a network. Using the language, it is possible to accomplish an orchestrated execution of single-vehicle tasks according to several patterns such as sequential, concurrent, or event-based program flow. With this aim, Dolphin has been integrated modularly with a software toolchain for autonomous vehicles developed by Laboratório de Sistemas e Tecnologia Subaquática (LSTS). The tests we describe made use of LSTS unmanned underwater vehicles (UUVs) at open sea during the 2017 edition of Rapid Environment Picture (REP), an annual exercise jointly organised by LSTS and the Portuguese Navy.},
   keywords = {autonomous underwater vehicles
control engineering computing
mobile robots
multi-robot systems
specification languages
Dolphin
REP
autonomous vehicles
mixed-initiative systems
domain-specific language
single-vehicle tasks
event-based program flow
LSTS unmanned underwater vehicles
coordinated behavior
networked vehicle systems programming
concurrent-based program flow
sequential-based program flow
UUVs
Rapid Environment Picture},
   DOI = {10.1109/OCEANSKOBE.2018.8559474},
   year = {2018},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Liu, H. H. T.},
   title = {Multiparadigm design, validation and verification by simulation in flight control system development},
   booktitle = {2004 IEEE International Conference on Robotics and Automation (IEEE Cat. No.04CH37508)},
   pages = {71-76},
   abstract = {Flight control system development typically involves phases that are often chronological, yet are extensively interrelated and interconnected, where design, validation and verification (DV&V) play a central role. This paper proposes an integrated (DV&V) process aiming at reducing development cycles. A two-way integration approach suggests improvement than the traditional one-way integration approach, in integrating multiparadigm models, heterogeneous simulations, and in including mutual design and validation interactions. The necessity of such an integrated approach is illustrated by a flight control example},
   keywords = {aerospace control
aerospace simulation
control system synthesis
flight control system development
integrated design process
integrated validation process
integrated verification process
multiparadigm models
heterogeneous simulations
two way integration method
Computational modeling
Process design
Control systems
Aircraft propulsion
Aircraft manufacture
Aerospace engineering
Systems engineering and theory
Technological innovation},
   DOI = {10.1109/CACSD.2004.1393853},
   year = {2004},
   type = {Conference Proceedings}
}

@article{
   author = {Liu, X. and Xu, M. and Teng, T. and Huang, G. and Mei, H.},
   title = {MUIT: A Domain-Specific Language and its Middleware for Adaptive Mobile Web-Based User Interfaces in WS-BPEL},
   journal = {IEEE Transactions on Services Computing},
   journalAlt = {IEEE Transactions on Services Computing},
   volume = {12},
   number = {6},
   pages = {955-969},
   abstract = {In enterprise organizations, the Bring-Your-Own-Device (BYOD) requirement has become prevalent as employees use their own mobile devices to process the workflow-oriented tasks. Consequently, it calls for approaches that can quickly develop and integrate mobile user interactions into existing business processes, and adapt to various contexts. However, designing, developing, and deploying adaptive and mobile-oriented user interfaces for existing process engines are non-trivial, and require significant systematic efforts. To address this issue, we present a novel middleware-based approach, called MUIT, to developing and deploying the Mobility, User Interactions and Tasks into WS-BPEL engines. MUIT provides a Domain-Specific Language (DSL) that provides some intuitive facilities to support the declarative development of adaptive, mobile-oriented, and Web-based user interfaces in WS-BPEL. The DSL can significantly reduce developers' manual efforts of developing user interactions by preventing arbitrarily mixed code, and its runtime supports satisfactory user experiences. Additionally, MUIT can be seamlessly integrated into WS-BPEL without intrusions of existing process instances. We implement a proof-of-concept prototype by integrating MUIT into the commodity WS-BPEL-based Apusic Platform, and evaluate the performance and usability of MUIT platform.},
   keywords = {business data processing
Internet
middleware
mobile computing
specification languages
user interfaces
Web services
bring-your-own-device requirement
MUIT approach
MUIT platform
commodity WS-BPEL-based Apusic Platform
user experience
WS-BPEL engines
middleware-based approach
mobile-oriented user interfaces
business processes
mobile user interactions
workflow-oriented tasks
enterprise organizations
adaptive mobile web-based user interfaces
domain-specific language
Smart phones
Mobile communication
Business
Engines
DSL
WS-BPEL
mobile
human tasks
web programming},
   ISSN = {1939-1374},
   DOI = {10.1109/TSC.2016.2633535},
   year = {2019},
   type = {Journal Article}
}

@inproceedings{
   author = {Lohmann, D. and Huf, A. and Lettnin, D. and Siqueira, F. and Güntzel, J. L.},
   title = {A Domain-specific Language for Automated Fault Injection in SystemC Models},
   booktitle = {2018 25th IEEE International Conference on Electronics, Circuits and Systems (ICECS)},
   pages = {425-428},
   abstract = {With the evolution of technology, electronic systems have become significantly more complex. As a consequence, design and verification of these systems evolved notably. Fault injection is a dependability evaluation technique that is strongly recommend during the verification step. Although there are a number of tools capable of injecting faults, many of them do not have a simple fault model description language and require considerable manual effort. In this paper, we propose a SystemC template metaprogrammed Domain-Specific Language (DSL) integrated with Universal Verification Methodology (UVM) to describe formal fault models that requires neither specific compilers nor code preprocessing tools. Unlike current approaches for fault injection, there is no need to create fault injection environment manually or to describe the system in an XML format. We evaluate our approach in terms of readability and effort required from a designer to describe a fault injection test. Our case study illustrates how the DSL helps designers to create fault models in SystemC, decreasing programming effort and taking advantage of SystemC/C++ expressiveness.},
   keywords = {C++ language
fault diagnosis
program compilers
program testing
program verification
software fault tolerance
software libraries
specification languages
XML
automated fault injection
SystemC models
electronic systems
SystemC template
Universal Verification Methodology
formal fault models
fault injection test
SystemC/C++ expressiveness
domain-specific language
fault model description language
XML format
DSL
C++ languages
Reactive power
Engines
Tools
Fault location
Fault injection
SystemC},
   DOI = {10.1109/ICECS.2018.8617838},
   year = {2018},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Lopes, F. A. and Santos, M. and Fidalgo, R. and Fernandes, S.},
   title = {Model-driven networking: A novel approach for SDN applications development},
   booktitle = {2015 IFIP/IEEE International Symposium on Integrated Network Management (IM)},
   pages = {770-773},
   abstract = {Software-Defined Networking (SDN) has been receiving a great deal of attention from both academic and industry communities. One reason to this interest is that SDN enables the network programmability, through an external controller, which supports applications and policies built from SDN programming languages, thus breaking the traditional bind between control and data plane. Nevertheless, the application development in this context is still complex for such recent technology. Moreover, there is a strong need for methodologies and tools that explore the abstraction levels potentials supported by SDN. This paper presents a new approach based on the Model-Driven Engineering (MDE) paradigm, called Model-Driven Networking (MDN). MDN relies on a Domain-Specific Modelling Language (DSML) to create SDN applications. We argue that MDN raises the level of abstraction on development, thus reducing the complexity to implement SDN applications and avoiding inconsistent policies. In order to show the relevance and the technological viability of our proposal, we have specified a DSML and have built a tool for creating SDN applications using the MDN approach.},
   keywords = {software defined networking
specification languages
model-driven networking
SDN applications development
software-defined networking
network programmability
external controller
SDN programming languages
model-driven engineering paradigm
MDE paradigm
MDN
domain-specific modelling language
DSML
Syntactics
Proposals
Computational modeling
DSL
Semantics
Biological system modeling
Complexity theory
Domain-Specific Modeling Language
Model-Driven Engineering},
   ISBN = {1573-0077},
   DOI = {10.1109/INM.2015.7140372},
   year = {2015},
   type = {Conference Proceedings}
}

@article{
   author = {Macieira, R. M. and Barros, E.},
   title = {Towards a greater reliability of driver/device communication around the system life cycle through a contract-based protocol specification},
   journal = {IET Cyber-Physical Systems: Theory & Applications},
   journalAlt = {IET Cyber-Physical Systems: Theory & Applications},
   volume = {3},
   number = {1},
   pages = {11-23},
   abstract = {Vehicle computers, Internet of Things and cyber-physical systems are all examples of electronic devices in which embedded systems require greater flexibility to process different types of applications and communication protocols. High flexibility requires the use of general purpose processors as a solution for configuring and controlling several peripherals. However, this also increases the need for hardware-dependent software. Since this is a highly critical and error-prone component due to the nature of its coding and the surrounding environment, it is essential to support the development and runtime phases through methodologies that can detect violations and errors when accessing devices by monitoring the communication protocol. This approach proposes a technique for monitoring temporal properties in high-level communication protocols between devices and drivers using a contract-based specification mechanism for describing the interface and protocol. From this specification, a monitoring module is synthesised, which can detect violation during the simulation of virtual platforms or execution of hardware platforms. The proposed specification language is a domain-specific language that supports platform-based design and enables the iteractive refinement of communication protocol and temporal property specifications along with platform stepwise implementation. Some experiments have demonstrated the effectiveness of the proposed approach for detecting errors in device drivers and device access violation.},
   keywords = {device drivers
protocols
greater reliability
driver-device communication
system life cycle
protocol specification
vehicle computers
Internet of Things
cyber-physical systems
electronic devices
communication protocols
general purpose processors
hardware-dependent software
error-prone component
monitoring temporal properties
contract based specification mechanism
detect violation
virtual platforms
hardware platforms
specification language
domain-specific language
iteractive refinement
communication protocol
temporal property specifications},
   ISSN = {2398-3396},
   DOI = {10.1049/iet-cps.2017.0001},
   year = {2018},
   type = {Journal Article}
}

@inproceedings{
   author = {Mahmoudi, C. and Mourlin, F.},
   title = {A Language for Controller-Less Internet of Things Orchestration Based on Label Forwarding},
   booktitle = {2019 IEEE/ACS 16th International Conference on Computer Systems and Applications (AICCSA)},
   pages = {1-7},
   abstract = {The Internet of Things domain is generating large dataset, which display a part of our life. With new measure, we can manage these dataflow in much better ways. By making information available anytime, anywhere, IoT constantly changes and shapes the way we live and work. Named Data Networking (NDN) is a new networking paradigm that changes the way data is accessed and retrieved in networks and distributed systems. In this paper, we present a new approach that extends the in-network capabilities of this new paradigm and enables on-the-fly composition of IoT resources. Presently, the composition of IoT resources requires a central controller for orchestrating the composition and a catalog for organizing and classifying the resources and their availability. The proposed approach bypasses these requirements by providing a built-in resource classification using NDN naming and a distributed composition pattern. A Composition Domain Specific Language (C-DSL) is proposed as a solution to express the composition using the power of NDN naming. NamedIoT, an implementation of this approach, is also presented. A use case of Emergency Response is discussed as an illustration of how the proposed framework would help overcome the challenges raised during a tragic event, where resources should be rapidly, efficiently and accurately coordinated and directed to bring the event under control. The presented results illustrate the efficiency, compared to legacy solutions, of the resources composition and communication approach.},
   keywords = {Wireless sensor networks
Named-data networking
Information-centric networking
Internet of things},
   ISBN = {2161-5330},
   DOI = {10.1109/AICCSA47632.2019.9035346},
   year = {2019},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Mallet, F.},
   title = {UMES2: Time modelling with MARTE},
   booktitle = {2010 Forum on Specification & Design Languages (FDL 2010)},
   pages = {1-1},
   abstract = {The UML profile for MARTE has been adopted recently by the OMG. Its time model proposes several extensions to the UML Simple Time Model and comes with a companion language, called CCSL (Clock Constraint Specification Language), dedicated to the specification of causal and chronological constraints. CCSL elaborates on the work around synchronous and polychronous languages and advocates for the use of multiform logical time to a broad family of constraints common in reactive, real-time and embedded systems. This tutorial introduces the MARTE Time Model and CCSL and shows how CCSL can be used to build libraries of constraints dedicated to specific analysis domains. CCSL models are then used as an explicit timed causality model for executing purely syntactic UML or domain-specific models. As an example, we build CCSL libraries for East-ADL, AADL, and SDF.},
   DOI = {10.1049/ic.2010.0171},
   year = {2010},
   type = {Conference Proceedings}
}

@book{
   author = {Marco, Brambilla and Jordi, Cabot and Manuel, Wimmer},
   title = {Model-Driven Software Engineering in Practice},
   publisher = {Morgan & Claypool},
   series = {Model-Driven Software Engineering in Practice},
   abstract = {This book discusses how model-based approaches can improve the daily practice of software professionals. This is known as Model-Driven Software Engineering (MDSE) or, simply, Model-Driven Engineering (MDE). MDSE practices have proved to increase efficiency and effectiveness in software development, as demonstrated by various quantitative and qualitative studies. MDSE adoption in the software industry is foreseen to grow exponentially in the near future, e.g., due to the convergence of software development and business analysis. The aim of this book is to provide you with an agile and flexible tool to introduce you to the MDSE world, thus allowing you to quickly understand its basic principles and techniques and to choose the right set of MDSE instruments for your needs so that you can start to benefit from MDSE right away. The book is organized into two main parts. The first part discusses the foundations of MDSE in terms of basic concepts (i.e., models and transformations), driving principles, application scenarios and current standards, like the well-known MDA initiative proposed by OMG (Object Management Group) as well as the practices on how to integrate MDSE in existing development processes. The second part deals with the technical aspects of MDSE, spanning from the basics on when and how to build a domain-specific modeling language, to the description of Model-to-Text and Model-to-Model transformations, and the tools that support the management of MDSE projects. The book is targeted to a diverse set of readers, spanning: professionals, CTOs, CIOs, and team managers that need to have a bird's eye vision on the matter, so as to take the appropriate decisions when it comes to choosing the best development techniques for their company or team; software analysts, developers, or designers that expect to use MDSE for improving everyday work productivity, either by applying the basic modeling techniques and notations or by defining new domain-specific modeling languages and applying end-to-end MDSE practices in the software factory; and academic teachers and students to address undergrad and postgrad courses on MDSE. In addition to the contents of the book, more resources are provided on the book's website, including the examples presented in the book. Table of Contents: Introduction / MDSE Principles / MDSE Use Cases / Model-Driven Architecture (MDA) / Integration of MDSE in your Development Process / Modeling Languages at a Glance / Developing your Own Modeling Language / Model-to-Model Transformations / Model-to-Text Transformations / Managing Models / Summary},
   pages = {1},
   ISBN = {9781608458837}, http://ieeexplore.ieee.org/document/6813569   url = {http://ieeexplore.ieee.org/document/6813569},
   year = {2012},
   type = {Book}
}

@article{
   author = {Martinho, R. and Varajão, J. and Domingos, D.},
   title = {Using the semantic web to define a language for modelling controlled flexibility in software processes},
   journal = {IET Software},
   journalAlt = {IET Software},
   volume = {4},
   number = {6},
   pages = {396-406},
   abstract = {Software processes and corresponding models are dynamic entities that must evolve to cope with changes occurred in the enacting process, the software development organisation, the market and the methodologies used to produce software. However, in the everyday practice, software team members do not want total flexibility. They rather prefer to learn about and follow previously defined controlled flexibility, that is, advices on which, where, how and by whom process models and related instances can change/adapt. Process engineers can express these advices within a process model with a domain-specific language (DSL), which complements the core process modelling language with additional controlled flexibility information. Then, software team members can browse and learn on this information in process models and instances, and be guided when performing changes. In this study, the authors propose the use of the semantic web and associated ontology-based technologies to develop and evolve their controlled flexibility DSL for software processes. They use an ontology-based format to define the controlled flexibility-related concepts, descriptions and axioms that specify the formal semantics of their DSL. In addition, the authors provide concrete mappings between these ontology concepts and a unified modelling language class-based DSL metamodel and describe how it supports changes made in the ontology.},
   keywords = {ontologies (artificial intelligence)
semantic Web
simulation languages
software engineering
software processes
software development organisation
controlled flexibility modelling
process model
domain-specific language
core process modelling language
software team members
associated ontology-based technologies
formal semantics
unified modelling language class-based DSL metamodel},
   ISSN = {1751-8814},
   DOI = {10.1049/iet-sen.2010.0045},
   year = {2010},
   type = {Journal Article}
}

@inproceedings{
   author = {Mayrhofer, D. and Huemer, C.},
   title = {REA-DSL: Business Model Driven Data-Engineering},
   booktitle = {2012 IEEE 14th International Conference on Commerce and Enterprise Computing},
   pages = {9-16},
   abstract = {An accounting information system (AIS) manages data about a company's financial and economic status. The contribution of this paper is closing the gap between the languages used by business domain experts and IT-experts in analyzing the relevant data. A well accepted approach for an accountability infrastructure is the Resource-Event-Agent (REA) ontology. Although REA has been based on well-established concepts of the accounting theory, its representation has not been intuitive to domain experts. In previous work, we developed the REA-DSL, a dedicated and easy-to-understand graphical domain specific modeling language for the REA ontology. Evidently, a model-driven approach requires to transform the REA-DSL artifacts to code. In this paper we present the transformation of the REA-DSL to a relational database for AIS. This approach offers the advantage that a domain expert verifies the relevant data in an "accounting language", whereas the IT expert is able to work with traditional data base structures.},
   keywords = {accounts data processing
ontologies (artificial intelligence)
relational databases
simulation languages
software engineering
REA-DSL language
business model driven data-engineering
accounting information system
AIS
resource-event-agent ontology
REA ontology
accounting theory
graphical domain specific modeling language
relational database
domain expert
accounting language
Economics
Marine animals
Business
Ontologies
Unified modeling language
Marketing and sales
Analytical models
REA
domain-specific language
business models
relational schema},
   ISBN = {2378-1971},
   DOI = {10.1109/CEC.2012.12},
   year = {2012},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {McDuffie, J. H.},
   title = {Using the architecture description language MetaH for designing and prototyping an embedded reconfigurable sliding mode flight controller},
   booktitle = {Proceedings. The 21st Digital Avionics Systems Conference},
   volume = {2},
   pages = {8B1-8B1},
   abstract = {This work utilizes an integrated tool set consisting of the domain specific language Simulink, the BEACON code generator, and the architecture description language MetaH to prototype a new method for reconfiguring control systems. The model system selected is a simplified model of a derivative F-16 aircraft flying at 10,000 ft. at mach 0.7. Sliding mode controller design consists of two steps. First, a suitable hypersurface is selected such that linear tracking error behavior with desired eigenvalues placement is achieved on the surface. Then the control is found in order to guarantee the hypersurface is reached in finite time and is maintained thereafter. This guarantees the desired decoupled tracking response in sliding mode and insensitivity to external disturbances and parametric uncertainties. Smoothing of the control input is achieved via the saturation function and reconfiguration of the controller is accomplished by dynamically varying the boundary layer thickness. A model of the controller and aircraft are created using Simulink. The BEACON code generator is then used to generate code packages describing the aircraft and controller systems. MetaH is used to create a software architecture for integration of the controller and aircraft subsystems, to simplify software module integration, to create an executable for the embedded target, and to switch flight controller modes to enable the reconfigured controller.},
   keywords = {aircraft control
reconfigurable architectures
control system CAD
variable structure systems
aerospace computing
aerospace simulation
program compilers
eigenvalues and eigenfunctions
stability
ADL
embedded reconfigurable sliding mode flight controller design/prototyping
MetaH architecture description language
Simulink domain specific language
BEACON code generator
control system reconfiguration
F-16 aircraft modeling
hypersurface selection
linear tracking error behavior
eigenvalues placement
sliding mode decoupled tracking response
external disturbance sensitivity
parametric uncertainties
control input smoothing
saturation function
boundary layer thickness dynamic variation
aircraft/controller systems code package generation
software architecture
software module integration
flight controller mode switching
10000 ft
Architecture description languages
Prototypes
Sliding mode control
Aircraft
Aerospace control
Control systems
Thickness control
Switches
Domain specific languages},
   DOI = {10.1109/DASC.2002.1052937},
   year = {2002},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Meier, P. and Kounev, S. and Koziolek, H.},
   title = {Automated Transformation of Component-Based Software Architecture Models to Queueing Petri Nets},
   booktitle = {2011 IEEE 19th Annual International Symposium on Modelling, Analysis, and Simulation of Computer and Telecommunication Systems},
   pages = {339-348},
   abstract = {Performance predictions early in the software development process can help to detect problems before resources have been spent on implementation. The Palladio Component Model (PCM) is an example of a mature domain-specific modeling language for component-based systems enabling performance predictions at design time. PCM provides several alternative model solution methods based on analytical and simulation techniques. However, existing solution methods suffer from scalability issues and provide limited flexibility in trading-off between results accuracy and analysis overhead. Queueing Petri Nets (QPNs) are a general-purpose modeling formalism, at a lower level of abstraction, for which efficient and mature simulation-based solution techniques are available. This paper contributes a formal mapping from PCM to QPN models, implemented by means of an automated model-to-model transformation as part of a new PCM solution method based on simulation of QPNs. The limitations of the mapping and the accuracy and overhead of the new solution method compared to existing methods are evaluated in detail in the context of five case studies of different size and complexity. The new solution method proved to provide good accuracy with solution overhead up to 20 times lower compared to PCM's reference solver.},
   keywords = {object-oriented programming
Petri nets
queueing theory
software architecture
software performance evaluation
specification languages
component-based software architecture model
queueing Petri nets
performance prediction
software development process
Palladio component model
domain-specific modeling language
scalability issue
general-purpose modeling formalism
formal mapping
automated model-to-model transformation
Phase change materials
Analytical models
Unified modeling language
Color
Stochastic processes
Predictive models
non-functional system properties
software architecture models
model-to-model transformation},
   ISBN = {2375-0227},
   DOI = {10.1109/MASCOTS.2011.23},
   year = {2011},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Membarth, R. and Hannig, F. and Teich, J. and Körner, M. and Eckert, W.},
   title = {Generating Device-specific GPU Code for Local Operators in Medical Imaging},
   booktitle = {2012 IEEE 26th International Parallel and Distributed Processing Symposium},
   pages = {569-581},
   abstract = {To cope with the complexity of programming GPU accelerators for medical imaging computations, we developed a framework to describe image processing kernels in a domain-specific language, which is embedded into C++. The description uses decoupled access/execute metadata, which allow the programmer to specify both execution constraints and memory access patterns of kernels. A source-to-source compiler translates this high-level description into low-level CUDA and Open CL code with automatic support for boundary handling and filter masks. Taking the annotated metadata and the characteristics of the parallel GPU execution model into account, two-layered parallel implementations - utilizing SPMD and MPMD parallelism - are generated. An abstract hardware model of graphics card architectures allows to model GPUs of multiple vendors like AMD and NVIDIA, and to generate device-specific code for multiple targets. It is shown that the generated code is faster than manual implementations and those relying on hardware support for boundary handling. Implementations from Rapid Mind, a commercial framework for GPU programming, are outperformed and similar results achieved compared to the GPU backend of the widely used image processing library Open CV.},
   keywords = {C++ language
graphics processing units
medical image processing
parallel architectures
device-specific GPU code
local operator
medical imaging
GPU accelerator
image processing kernel
domain-specific language
C++
decoupled access-execute metadata
execution constraint
memory access pattern
source-to-source compiler
low-level CUDA
Open CL code
boundary handling
filter mask
parallel GPU execution model
SPMD parallelism
MPMD parallelism
abstract hardware model
graphics card architecture
AMD
NVIDIA
Rapid Mind
GPU programming
Graphics processing unit
Kernel
Image processing
Biomedical imaging
Programming
Hardware
GPU
CUDA
OpenCL
code generation
local operators},
   ISBN = {1530-2075},
   DOI = {10.1109/IPDPS.2012.59},
   year = {2012},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Meredith, J. S. and Alam, S. R. and Vetter, J. S.},
   title = {Analysis of a Computational Biology Simulation Technique on Emerging Processing Architectures},
   booktitle = {2007 IEEE International Parallel and Distributed Processing Symposium},
   pages = {1-8},
   abstract = {Multi-paradigm, multi-threaded and multi-core computing devices available today provide several orders of magnitude performance improvement over mainstream microprocessors. These devices include the STI Cell Broadband Engine, graphical processing units (GPU) and the Cray massively-multithreaded processors - available in desktop computing systems as well as proposed for supercomputing platforms. The main challenge in utilizing these powerful devices is their unique programming paradigms. GPUs and the Cell systems require code developers to manage code and data explicitly, while the Cray multithreaded architecture requires them to generate a very large number of threads or independent tasks concurrently. In this paper, we explain strategies for optimizing a molecular dynamics (MD) calculation that is used in biomolecular simulations on three devices: Cell, GPU and MTA-2. We show that the Cray MTA-2 system requires minimal code modification and does not outperform the microprocessor runs; but it demonstrates an improved workload scaling behavior over the microprocessor implementation. On the other hand, substantial porting and optimization efforts on the Cell and the GPU systems result in a 5times to 6times improvement, respectively, over a 2.2 GHz Opteron system.},
   keywords = {biology computing
computer architecture
computer graphic equipment
Cray computers
digital simulation
microprocessor chips
molecular biophysics
molecular dynamics method
multi-threading
computational biology simulation technique
microprocessors
STI Cell Broadband Engine
graphical processing units
Cray massively-multithreaded processors
desktop computing systems
supercomputing platforms
programming
multithreaded architecture
molecular dynamics
biomolecular simulations
Cray MTA-2 system
GPU systems
Computational biology
Biological system modeling
Computational modeling
Analytical models
Engines
Power system management
Yarn},
   ISBN = {1530-2075},
   DOI = {10.1109/IPDPS.2007.370444},
   year = {2007},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Mesz´ros, T. and Levendovszky, T.},
   title = {Verified Operational Patterns with Graph Transformation},
   booktitle = {2012 IEEE Fifth International Conference on Software Testing, Verification and Validation},
   pages = {954-961},
   abstract = {Using object-oriented patterns such as design patterns, architectural patterns, and refactoring operations has considerably simplified the design process of software systems. With the proliferation of Domain-Specific Languages, the generalization of OO patterns is a natural demand. A straightforward idea is to adapt OO patterns with automated tool support to the practice of Domain-Specific Modeling as well. A possible solution for that is using graph transformations to formalize and realize such patterns. One may expect, however, that the patterns are realized in a way that they are correct and do exactly what we expect them to. In this paper, we present how one can precisely define the requirements for a domain-specific model pattern, and how to verify the requirements on the implemented patterns. The presented concept is motivated and illustrated with a case study from the state chart domain.},
   keywords = {graph grammars
object-oriented methods
pattern classification
software architecture
software maintenance
software tools
graph transformation
verified operational patterns
object-oriented patterns
architectural patterns
refactoring operations
software system design process
domain-specific language proliferation
OO patterns
automated tool support
domain-specific model pattern
state chart domain
Containers
Unified modeling language
Adaptation models
Object oriented modeling
Semantics
Software systems
Joining processes
Active Model Patterns
Transformation Verification},
   ISBN = {2159-4848},
   DOI = {10.1109/ICST.2012.201},
   year = {2012},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Metayer, N. and Paz, A. and Boussaidi, G. El},
   title = {Modelling DO-178C Assurance Needs: A Design Assurance Level-Sensitive DSL},
   booktitle = {2019 IEEE International Symposium on Software Reliability Engineering Workshops (ISSREW)},
   pages = {338-345},
   abstract = {Avionics systems are relying more on software to control their behaviour. However, engineering such software is a complex task. Even more so due to their safety-critical nature. Aviation authorities require suppliers to provide appropriate safety assurance through the certification of compliance with DO-178C to a determined software design assurance level. Such a concern is leading the avionics software industry to consider and incorporate effective engineering methods that can support them in their certification endeavours. This paper presents a domain specific modelling language (DSML) providing a documentation infrastructure that enforces certification information mandated by DO-178C and its supplements according with the software's design assurance level. Focus is given to the conceptual model of DO-178C and its supplements, which lies behind the proposed DSML to support the features it delivers. The DSML was built and implemented as a UML profile. Three different use cases for the DSML are illustrated in an avionics case study.},
   keywords = {aerospace computing
avionics
certification
embedded systems
safety
safety-critical software
simulation languages
software engineering
Unified Modeling Language
DSML
avionics case study
DO-178C
design assurance level-sensitive DSL
avionics systems
complex task
safety-critical nature
aviation authorities
appropriate safety assurance
determined software design assurance level
avionics software industry
incorporate effective engineering methods
certification endeavours
domain specific modelling language
certification information
conceptual model
Airborne software, DO-178C, certification, model driven engineering, domain specific modelling language},
   DOI = {10.1109/ISSREW.2019.00094},
   year = {2019},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Mezhuyev, V. and Malakhov, E.},
   title = {Ontology-Driven Development of the Metamodels for Modelling Distributed Parallel Software Systems},
   booktitle = {2015 3rd International Conference on Artificial Intelligence, Modelling and Simulation (AIMS)},
   pages = {389-393},
   abstract = {The paper discusses a new technique for development of metamodels for the modelling distributed parallel software systems. The approach is an important stage of Domain-Specific Mathematical Modelling (DSMM), developed to enhance the methodology of Domain-Specific Modelling. The advantage of DSMM is a possibility of constructing metamodels for modelling domains, having different mathematical properties and structures. The paper analyses applicability of OWL-DL ontologies for expressing properties of software systems. Identification of the metatypes as OWL classes and use of OWL restrictions as rules of metamodels' grammars give us an effective way for the design and verification of software systems. The proposed approach have advantages of the model-driven software development and allows verification of software systems at earlier design stage.},
   keywords = {formal verification
knowledge representation languages
mathematical analysis
ontologies (artificial intelligence)
parallel processing
ontology-driven development
metamodels
distributed parallel software systems
domain-specific mathematical modelling
DSMM
different mathematical properties
OWL-DL ontologies
Synchronization
Mathematical model
Computational modeling
OWL
Software systems
Ontologies
ontology
metamodel
domain specific mathematical modelling
parallel software system
logical analysis},
   DOI = {10.1109/AIMS.2015.67},
   year = {2015},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Mierlo, S. Van and Deantoni, J. and Burgueño, L. and Verbrugge, C. and Vangheluwe, H.},
   title = {Towards Sketching Interfaces for Multi-paradigm Modeling},
   booktitle = {2019 ACM/IEEE 22nd International Conference on Model Driven Engineering Languages and Systems Companion (MODELS-C)},
   pages = {437-442},
   abstract = {Existing design processes typically begin with informal ideation by sketching out a basic approach that can be further developed into a more complete design. Although intuitively simple, and seemingly informal, the sketching process is actually a structured activity that strongly influences the design of the system; hence, it has an important role in the design success. In this work, we develop a well defined specification of the sketching activity. We consider sketching as a process of achieving agreement, based on stakeholders communicating ideas about a design and its properties, with the side-effect of incrementally developing a (set of) common language(s) specific to the idea domain. Our perspective on sketching further differs from more common notions of ideation by noting the roles of requirements and system properties, and offering a general perspective on sketching as a modular activity within design.We validate our approach by analyzing the sketches of a research group at the CAMPaM 2019 workshop. By recognizing sketching as a fundamental activity in design, we enhance the formalization of the design process, and suggest improvements to the tool support for sketching beyond the basic drawing features.},
   keywords = {design engineering
formal specification
software tools
design process
multiparadigm modeling
informal ideation
interface sketching
sketching activity specification
tool support
sketching, multi-paradigm, ideation, interface},
   DOI = {10.1109/MODELS-C.2019.00070},
   year = {2019},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Mierlo, S. Van and Syriani, E. and Blouin, D. and Amrani, M. and Deantoni, J. and Wimmer, M.},
   title = {Preface to the 1st Multi-Paradigm Modeling for Cyber-Physical Systems (MPM4CPS 2019)},
   booktitle = {2019 ACM/IEEE 22nd International Conference on Model Driven Engineering Languages and Systems Companion (MODELS-C)},
   pages = {417-418},
   abstract = {n/a},
   keywords = {Multi Paradigm
Cyber Physical Systems
Modeling},
   DOI = {10.1109/MODELS-C.2019.00066},
   year = {2019},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Miserendino, S. and Maynard, C. and Davis, J.},
   title = {ThreatVectors: contextual workflows and visualizations for rapid cyber event triage},
   booktitle = {2017 International Conference On Cyber Incident Response, Coordination, Containment & Control (Cyber Incident)},
   pages = {1-8},
   abstract = {Cyber security operations face a daily flood of security events generated by automated security tools and analytics. These events must be rapidly and accurately triaged to remove false positives and focus investigations on those presenting the greatest risks to the enterprise and requiring immediate remediation. We introduce ThreatVectors as a contextual triage workflow and event visualization tool to aid operators in event triage. ThreatVectors use a streaming event processing framework for event correlation, aggregation and prioritization based on user definable event collections and a cyber-triage domain specific language. Triage work progress is shown using a novel progress bar matrix. Event collection visualization includes abstract event thumbnails for event overview and a dynamic filtering mechanism based on metafield hierarchies. Bulk adjudication of filtered event views and event clusters is supported. User testing on large enterprise networks indicates the approach has significant potential for aiding in identifying multievent campaigns, supporting collaborative triage and reducing total time spent triaging events.},
   keywords = {data visualisation
security of data
specification languages
progress bar matrix
dynamic filtering mechanism
metafield hierarchies
event visualization tool
contextual triage workflow
cyber security operations
rapid cyber event triage
contextual workflows
ThreatVectors
collaborative triage
abstract event thumbnails
event collection visualization
cyber-triage domain specific language
user definable event collections
streaming event processing framework
Correlation
Computer security
Tools
Visualization
DSL
Domain specific languages
Triage
workflow
cyber event correlation
domain specific language
thumbnails},
   DOI = {10.1109/CYBERINCIDENT.2017.8054637},
   year = {2017},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Mohapi, L. J. and Winberg, S. and Inggs, M.},
   title = {Using a domain specific language for SDR to facilitate radar signal processing in heterogeneous computing architectures},
   booktitle = {2015 IEEE Radar Conference},
   pages = {306-311},
   abstract = {This paper presents the use of a Domain-Specific Language (DSL) for Software Defined Radio (SDR) in a Radar digital signal processing (DSP) using heterogeneous computing architectures (HCAs). These HCAs are a combinations of mul-ticore CPU, GPUs, and FPGAs. This DSL, which we named OptiSDR, uses a dataflow-like model of computations named parallel stream processing and a compiler guided optimization technique to provide optimized parallel executable patterns for a hybrid MCPU-GPU architecture. In this paper, we demonstrate the capabilities of OptiSDR in a Radar DSP case study, and show how OptiSDR achieves up to 50 times (50X) speed-up as compared to the hand-crafted Matlab and Octave scripts for the NetRAD pulse compression algorithm. We also show that, while hand-crafted CUDA-Qt implementation of the same pulse compression algorithm presents up to 2X speed-up against Op-tiSDR, this was minimized using platform-specific optimizations by efficiently utilizing available computing resources such as number of GPUs, memory, and number of cores of a MCPU.},
   keywords = {field programmable gate arrays
graphics processing units
multiprocessing systems
parallel architectures
radar signal processing
software radio
telecommunication computing
domain specific language
SDR
heterogeneous computing architecture
software defined radio
radar DSP
radar digital signal processing
HCA
multicore CPU
multicore GPU
multicore FPGA
dataflow-like model
parallel stream processing
compiler guided optimization technique
optimized parallel executable patterns
hybrid MCPU-GPU architecture
OptiSDR
NetRAD pulse compression algorithm
hand-crafted CUDA-Qt implementation
pulse compression algorithm
platform-specific optimization
graphics processing unit
Optimization
Radar
DSL
Digital signal processing
Computer architecture},
   DOI = {10.1109/RadarConf.2015.7411899},
   year = {2015},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Montecchi, L. and Lollini, P. and Bondavalli, A.},
   title = {A DSL-Supported Workflow for the Automated Assembly of Large Stochastic Models},
   booktitle = {2014 Tenth European Dependable Computing Conference},
   pages = {82-93},
   abstract = {Dependability and performance analysis of modern systems is facing great challenges: their scale is growing, they are becoming massively distributed, interconnected, and evolving. Such complexity makes model-based assessment a difficult and time-consuming task. For the evaluation of large systems, reusable sub models are typically adopted as an effective way to address the complexity and improve the maintanability of models. Approaches based on Stochastic Petri Nets often compose sub models by state-sharing, following predefined "patterns", depending on the scenario of interest. However, such composition patterns are typically not formalized. Clearly defining libraries of reusable sub models, together with valid patterns for their composition, would allow complex models to be automatically assembled, based on a high-level description of the scenario to be evaluated. The contribution of this paper to this problem is twofold: on one hand we describe our workflow for the automated generation of large per formability models, on the other hand we introduce the TMDL language, a DSL to concretely support the workflow. After introducing the approach and the language, we detail their implementation within the Eclipse modeling platform, and briefly show its usage through an example.},
   keywords = {Petri nets
specification languages
stochastic processes
workflow management software
DSL-supported workflow
automated assembly
large stochastic models
model-based assessment
stochastic Petri nets
predefined patterns
composition patterns
high-level description
TMDL language
Eclipse modeling platform
domain-specific language
large performability models
Libraries
Analytical models
Object oriented modeling
Workstations
Numerical models
Assembly
modularity
model-based evaluation
state-based
performability
template models
composition
model-driven engineering},
   DOI = {10.1109/EDCC.2014.33},
   year = {2014},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Montrieux, L. and Yu, Y. and Wermelinger, M.},
   title = {Developing a domain-specific plug-in for a modelling platform: The good, the bad, the ugly},
   booktitle = {2013 3rd International Workshop on Developing Tools as Plug-Ins (TOPI)},
   pages = {1-6},
   abstract = {Domain-Specific Modelling Languages (DSML) allow software engineers to use the techniques and tools of Model-Driven Engineering (MDE) to express, represent and analyse a particular domain. By defining DSMLs as UML profiles, i.e. domain-specific extensions of the UML metamodel, development time for DSMLs can be greatly reduced by extending existing UML tools. In this paper, we reflect on our own experience in building rbacUML, a DSML for Role-Based Access Control modelling and analysis, as a plugin for a UML modelling platform. We describe what motivated our choice, and discuss the advantages and drawbacks of using an existing platform to develop a DSML on top of UML and additional analysis tooling.},
   keywords = {authorisation
simulation languages
software engineering
Unified Modeling Language
domain-specific plug-in development
domain-specific modelling languages
model-driven engineering
MDE
UML profiles
UML metamodel
DSML development time
rbacUML
role-based access control modelling
role-based access control analysis
Engines
Biological system modeling
Generators
Standards
Software
Access control
RBAC
OCL
Eclipse
Modelling
Plugin},
   ISBN = {2327-0772},
   DOI = {10.1109/TOPI.2013.6597186},
   year = {2013},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Morris, K. A. and Clarke, P. J. and He, X. and Costa, F. M. and Allison, M.},
   title = {A Method for Validating Intent Model Behavior in DSVMs},
   booktitle = {2015 IEEE 16th International Symposium on High Assurance Systems Engineering},
   pages = {247-254},
   abstract = {The direct runtime interpretation and execution of domain-specific models through the use of a Domain Specific Virtual Machine (DSVM) is an area of emerging relevance in the model-driven engineering community. This is due in part to the increased efficiency and decreased complexity achieved through specialization of the architecture in disparate domains. An approach to the design of a DSVM is to include a middleware that is responsible for the delivery and management of domain-specific services. It is the job of this middleware to help realize user intent through the execution of received commands while ensuring adherence to system policies based on changing environmental context. To provide assurance of functionality, the DSVM middleware must be policy and context-aware and facilitate variability in its operations. It achieves this variability by dynamically generating behavioral models for execution in response to commands. The dynamic generation of models poses the challenge of ensuring their correctness at runtime. To guarantee the correctness of generated models, we adopted model validation techniques to ensure policy compliance and employed the Alloy Analyzer in our prototype to demonstrate the efficacy of this approach. This granted us use of the Alloy specification language, which, by utilizing first-order logic, enhanced our model validation process by allowing more expressive policies. We demonstrate the increased capabilities and assurance realized by this approach through a case study with a DSVM middleware instance for the communication domain.},
   keywords = {formal logic
middleware
specification languages
virtual machines
intent model behavior
DSVM
direct runtime interpretation
domain-specific models
domain specific virtual machine
model-driven engineering
domain-specific services
alloy analyzer
alloy specification language
first-order logic
Metals
Object oriented modeling
Analytical models
Runtime
Abstracts
model validation
models at runtime},
   ISBN = {1530-2059},
   DOI = {10.1109/HASE.2015.43},
   year = {2015},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Morris, K. A. and Wei, J. and Clarke, P. J. and Costa, F. M.},
   title = {Towards Adaptable Middleware to Support Service Delivery Validation in i-DSML Execution Engines},
   booktitle = {2012 IEEE 14th International Symposium on High-Assurance Systems Engineering},
   pages = {82-89},
   abstract = {A developing paradigm in the area of Software Engineering is that of Model Driven Development where models are used to express operations that are thereafter interpreted and executed through the use of an execution engine. The high level of abstraction within these models present inherent challenges in guaranteeing operation that respect policies and other constraints during execution. Additionally, the domain specificity necessarily present within these execution engines make them rigid and not suited for repurposing across different domains. We propose to address these issues through the use of a middleware architecture that is responsible for the service delivery aspect of the execution engine. Our architecture will provide a separation of domain specific and domain independent concerns, resulting in a set of domain specific artifacts which possess domain knowledge, and a generalized execution platform that inherits its operations from the domain artifacts. Our design facilitates the realization of user intent through the generation, validation and execution of adaptation models at runtime constrained by policies. We show the viability of this approach in the User-Centric Communication Middleware, a layer of the Communication Virtual Machine, which is responsible for enforcing communication requirements.},
   keywords = {middleware
program verification
software architecture
specification languages
virtual machines
adaptable middleware architecture
service delivery validation
i-DSML execution engines
software engineering
model driven development
domain specific concerns
domain independent concerns
domain specific artifacts
generalized execution platform
user-centric communication middleware
communication virtual machine layer
interpreted domain-specific modeling language
Adaptation models
Engines
Runtime
Cryptography
Virtual machining
Computer architecture
Models at Runtime
Adaptable Middleware
Functional Assurance
Domain Independence},
   ISBN = {1530-2059},
   DOI = {10.1109/HASE.2012.25},
   year = {2012},
   type = {Conference Proceedings}
}

@article{
   author = {Moser, O. and Rosenberg, F. and Dustdar, S.},
   title = {Domain-Specific Service Selection for Composite Services},
   journal = {IEEE Transactions on Software Engineering},
   journalAlt = {IEEE Transactions on Software Engineering},
   volume = {38},
   number = {4},
   pages = {828-843},
   abstract = {We propose a domain-specific service selection mechanism and system implementation to address the issue of runtime adaptation of composite services that implement mission-critical business processes. To this end, we leverage quality of service (QoS) as a means to specify rigid dependability requirements. QoS does not include only common attributes such as availability or response time but also attributes specific to certain business domains and processes. Therefore, we combine both domain-agnostic and domain-specific QoS attributes in an adaptive QoS model. For specifying the service selection strategy, we propose a domain-specific language called VieDASSL to specify so-called selectors. This language can be used to specify selector implementations based on the available QoS attributes. Both the QoS model implementation and the selectors can be adapted at runtime to deal with changing business and QoS requirements. Our approach is implemented on top of an existing WS-BPEL engine. We demonstrate its feasibility by implementing a case study from the telecommunication domain.},
   keywords = {business data processing
quality of service
reliability
specification languages
Web services
domain-specific service selection mechanism
composite services
runtime adaptation
mission-critical business processes
domain-agnostic QoS attributes
domain-specific QoS attributes
adaptive QoS model
domain-specific language
VieDASSL
selectors
business requirements
QoS requirements
WS-BPEL engine
telecommunication
Runtime
Business
Adaptation models
Time factors
Availability
Engines
Service composition
monitoring
service selection
domain specific languages},
   ISSN = {1939-3520},
   DOI = {10.1109/TSE.2011.43},
   year = {2012},
   type = {Journal Article}
}

@article{
   author = {Mosterman, P. J. and Sztipanovits, J. and Engell, S.},
   title = {Computer-automated multiparadigm modeling in control systems technology},
   journal = {IEEE Transactions on Control Systems Technology},
   journalAlt = {IEEE Transactions on Control Systems Technology},
   volume = {12},
   number = {2},
   pages = {223-234},
   abstract = {The use of model-based technologies has made it imperative for the development of a feedback control system to deal with many different tasks such as: plant modeling in all its variety; model reduction to achieve a complexity or level of abstraction suitable for the design task at hand; synthesis of control laws that vary from discrete event reactive control to continuous model predictive control, their analyses, and testing; design of the implementation; modeling of the computational platform and its operating system; analysis of the implementation effects; software synthesis for different platforms to facilitate rapid prototyping, hardware-in-the-loop simulation, etc. Throughout these tasks, different formalisms are used that are very domain specific (e.g., tailored to electrical circuits, multibody systems, reactive control algorithms, communication protocols) and that often need to be coupled, integrated, and transformed (e.g., a block diagram control law in the continuous domain has to be discretized and then implemented in software). Significant improvements in many aspects (performance, cost, development time) of the development process can therefore be achieved by: 1) relating and integrating these different formalisms; 2) automatic derivation of different levels of modeling abstractions; and 3) rigorous and tailored design of the different formalisms by capturing the domain (or meta) knowledge. The emerging field of computer automated multiparadigm modeling (CAMPaM), presented in this paper in the context of control system design, aims to develop a domain-independent formal framework that leverages and unifies different activities in each of these three dimensions.},
   keywords = {control system CAD
discrete event simulation
computational complexity
feedback
reduced order systems
large-scale systems
software prototyping
computer-automated multiparadigm modeling
control systems technology
model-based technologies
feedback control system
control system design
domain-independent formal framework
design automation
embedded software design
metamodeling
model integrated computing
controller design
functional hierarchy
implementation hierarchy
realization hierarchy
complex systems
plant modeling
model reduction
discrete event reactive control
continuous model predictive control
software synthesis
rapid prototyping
hardware-in-the-loop simulation
Control system synthesis
Predictive models
Computational modeling
Communication system control
Control systems
Automatic control
Feedback control
Predictive control
Control system analysis},
   ISSN = {1558-0865},
   DOI = {10.1109/TCST.2004.824280},
   year = {2004},
   type = {Journal Article}
}

@inproceedings{
   author = {Mousavi, B. A. and Azzouz, R. and Heavey, C. and Ehm, H.},
   title = {Simulation-Based Analysis of the Nervousness within Semiconductors Supply Chain Planning: Insight from a Case Study},
   booktitle = {2019 Winter Simulation Conference (WSC)},
   pages = {2396-2407},
   abstract = {In the growing globalization of production systems, the complexity of supply chains as socio-technical systems is escalating which, consequently, increases the importance of strong planning systems. Plans are developed to structure production in end-to-end supply chains that can experience nervousness due to uncertainties that results in unsatisfied customers. Although the external causes of nervousness and instabilities in supply chain planning systems were previously considered in the literature, internal nervousness of planning these complex networks can result from how the sub-components of the planning system interact. To study internal nervousness, a supply chain system of a semiconductor manufacturer is investigated as a case study. We examine internal nervousness of demand fulfillment by proposing a multi-paradigm simulation approach that combines discrete event and agent-based simulation. The results provide insight into the importance of visibility on the internal interactions of supply chain networks to reduce instability.},
   keywords = {discrete event simulation
globalisation
production planning
semiconductor device manufacture
semiconductor industry
supply chain management
supply chains
globalization
socio-technical systems
end-to-end supply chains
semiconductor manufacturer
multiparadigm simulation approach
agent-based simulation
simulation-based analysis
semiconductors supply chain planning
Planning
Materials requirements planning
Manufacturing
Complexity theory},
   ISBN = {1558-4305},
   DOI = {10.1109/WSC40007.2019.9004936},
   year = {2019},
   type = {Conference Proceedings}
}

@article{
   author = {Muller-Glaser, K. D. and Frick, G. and Sax, E. and Kuhl, M.},
   title = {Multiparadigm modeling in embedded systems design},
   journal = {IEEE Transactions on Control Systems Technology},
   journalAlt = {IEEE Transactions on Control Systems Technology},
   volume = {12},
   number = {2},
   pages = {279-292},
   abstract = {Embedded electronic systems for monitoring and control of technical processes (electronic control unit-ECU) are systems comprised of heterogeneous components (hardware, software, sensors, actuators, power electronics), thus making high demands on their development. Describing different aspects and views of the whole system, subsystem, or component requires according modeling paradigms for requirements specification, design, hardware implementation, software code generation, verification, integration, and testing. The first part of the paper surveys characteristic ECU features and describes a design strategy and the related technology, bringing out the necessity of multiparadigm modeling. Examples from automotive ECU applications are used throughout the paper. With respect to the problem that currently available tools provide insufficient support, integration strategies for multiparadigm modeling based on multiple tools are surveyed in the second part, concluding with examples from our own research activities.},
   keywords = {embedded systems
control system CAD
computer aided software engineering
specification languages
software prototyping
program compilers
simulation languages
embedded systems design
multiparadigm modeling
embedded electronic systems
electronic control unit
heterogeneous components
requirements specification
hardware implementation
software code generation
design strategy
automatic programming
code integration
executable specifications
software specification
tool integration
UML-based model representation
XFL-based model translation
Embedded system
Power system modeling
Process control
Control systems
Hardware
Monitoring
Embedded software
Sensor phenomena and characterization
Sensor systems
Actuators},
   ISSN = {1558-0865},
   DOI = {10.1109/TCST.2004.824340},
   year = {2004},
   type = {Journal Article}
}

@inproceedings{
   author = {Mustapha, K. and Tranvouez, E. and Espinasse, B. and Ferrarini, A.},
   title = {An organization-oriented methodological framework for agent-based supply chain simulation},
   booktitle = {2010 Fourth International Conference on Research Challenges in Information Science (RCIS)},
   pages = {353-364},
   abstract = {The SC organizational structure, and related management policies, is a crucial factor that can be adjusted to improve the SC performance, which consequently has to be taken into account in the SC modeling and simulation. This paper addresses a new methodological framework in the context of an agent-based SC simulation, which permits modeling and simulation of such SC organizational aspects, allowing observables of different levels of details. This methodological framework is structured according to two main abstraction levels, a conceptual level and an operational level. For each of these levels, different models are proposed and presented in detail. This methodological framework is associated with a multi model and multi-paradigm software architecture adapted to the SC simulation.},
   keywords = {multi-agent systems
production engineering computing
software architecture
supply chain management
organization-oriented methodological framework
agent-based supply chain simulation
SC organizational structure
SC modeling
multiparadigm software architecture
Supply chains
Context modeling
Large scale integration
Multiagent systems
Decision support systems
Environmental economics
Humans
Environmental management
component
Agent Based Simulation
Organization},
   ISBN = {2151-1357},
   DOI = {10.1109/RCIS.2010.5507395},
   year = {2010},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Nadjim-Tehrani, S.},
   title = {Formal methods for analysis of heterogeneous models of embedded systems},
   booktitle = {CACSD. Conference Proceedings. IEEE International Symposium on Computer-Aided Control System Design (Cat. No.00TH8537)},
   pages = {141-146},
   abstract = {Technological developments in micro-electronics have made digital control an indispensable component in all engineering systems. The rapid pace of development and the demands on modern systems in terms of novel functions and shorter development cycles has led to many challenges in system design and verification. The down side of improved functionality is the unmanaged complexity: never have we had systems built with so many different disciplines simultaneously at work-each with their own collection of conceptual and concrete tools. To manage complexity in this setting it is essential to recognise and accommodate the diversities as early as they arise. For most application domains this results in a multi-paradigm development process, and is most visible in the design modelling stage. We discuss how mathematical modelling and analysis of system properties is affected by having several disciplines at work. We show that soundness in design models can be obtained both through static analysis based on properties defined for a meta-model, and through formal verification of an instance of a model-the latter being defined in terms of conformance to a requirements specification.},
   keywords = {digital control
embedded systems
control system CAD
discrete event systems
continuous time systems
formal verification
data flow computing
closed loop systems
formal methods
heterogeneous models
development cycles
unmanaged complexity
multi-paradigm development process
design modelling stage
static analysis
meta-model
requirements specification
Embedded system
Mathematical model
Digital systems
Hardware
Systems engineering and theory
Electronic equipment testing
Information analysis
Embedded computing
Information science},
   DOI = {10.1109/CACSD.2000.900201},
   year = {2000},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Nägele, T. and Hooman, J.},
   title = {Scalability Analysis of Cloud-Based Distributed Simulations of IoT Systems Using HLA},
   booktitle = {2018 IEEE 24th International Conference on Parallel and Distributed Systems (ICPADS)},
   pages = {1075-1080},
   abstract = {Gaining insight in the properties of an Internet of Things (IoT) system during the design phase is difficult. The cosimulation of such a system would be very useful, but creating it is usually time consuming. By means of domain specific languages (DSLs) we support the fast construction of large co-simulations of IoT systems. This approach includes the use of CoHLA, a DSL that generates co-simulation code based on the HLA and FMI standards. Due to the large number of connected sensors and actuators in an IoT system, the time needed for simulation can be a blocking factor. Hence we facilitate distributed co-simulation in the cloud. To do that efficiently, we have conducted a set of experiments to analyse scalability and the performance impact of distribution methods. From these experiments, lessons were learned on how to distribute the co-simulation of IoT systems.},
   keywords = {cloud computing
computer simulation
distributed processing
Internet of Things
specification languages
cloud-based distributed simulations
co-simulation code
IoT systems
Internet of Things system
HLA
scalability analysis
domain specific languages
high level architecture
FMI standards
Object oriented modeling
Lighting
Standards
Sensors
Buildings
DSL
Domain Specific Language
Cyber-physical systems
Co-simulation
Distribution
FMI},
   ISBN = {1521-9097},
   DOI = {10.1109/PADSW.2018.8644925},
   year = {2018},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Nagy, I. and Cleophas, L. and Brand, M. v. d. and Engelen, L. and Raulea, L. and Mithun, E. X. L.},
   title = {VPDSL: A DSL for Software in the Loop Simulations Covering Material Flow},
   booktitle = {2012 IEEE 17th International Conference on Engineering of Complex Computer Systems},
   pages = {318-327},
   abstract = {We present an approach to model hardware configurations of complex manufacturing systems such as ASML's lithography machines. These hardware configurations consist of actuator and sensor elements which are controlled by system software that consists of over 35 million lines of code. To minimize the cost of testing and system integration, software simulators of hardware configurations are used-acting as virtual hardware platforms on which the real control software can be executed and tested. An important aspect in such simulation and testing is material flow (specifically wafer flow) in the machine. To support the effective and efficient realization of simulators covering material flow, we defined a domain specific language (DSL) for modelling the hardware configurations to be simulated, and used a model-driven engineering approach to generate the software components implementing the simulators. The DSL can be used to specify not only nominal (i.e. good weather) behaviour but also simulation based fault injection scenarios. The overall approach reduces the cost of early hardware-software integration and enables simulating scenarios that cannot be executed on real machines because they are difficult or hazardous to carry out.},
   keywords = {actuators
control engineering computing
digital simulation
lithography
manufacturing systems
object-oriented programming
production engineering computing
program testing
semiconductor industry
sensors
simulation languages
VPDSL
hardware configuration modelling
complex manufacturing systems
ASML lithography machines
actuator element control
sensor element control
testing cost minimization
system integration cost minimization
software simulators
virtual hardware platforms
control software execution
control software testing
material flow
wafer flow
domain specific language
model-driven engineering approach
software component generation
simulation-based fault injection scenarios
hardware-software integration
software-in-the-loop simulations
SIL
Hardware
Semiconductor device modeling
Software
Unified modeling language
Robot sensing systems
DSL},
   DOI = {10.1109/ICECCS20050.2012.6299227},
   year = {2012},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Nakamura, H. and Nagano, R. and Hisazumi, K. and Kamei, Y. and Ubayashi, N. and Fukuda, A.},
   title = {QORAL: An External Domain-Specific Language for Mining Software Repositories},
   booktitle = {2012 Fourth International Workshop on Empirical Software Engineering in Practice},
   pages = {23-29},
   abstract = {The mining software repositories (MSR) field integrates and analyzes data stored in repositories such as source control and bug repositories to provide support to practitioners. In order to provide useful information to practitioners, MSR researchers need to perform tasks iteratively, these tasks include extracting data from repositories, transforming them into specific data formats, and loading them into the statistical analysis tool. These tasks require a significant amount of man hours to implement and execute according to the requirements of the researchers. This paper proposes an external domain-specific language (DSL) called QORAL to facilitate the performance of multiple iterations and environment development. The results from a questionnaire used to evaluate QORAL indicate that it is easy to understand and modify source code.},
   keywords = {configuration management
data analysis
data mining
program debugging
software engineering
QORAL
external domain-specific language
software repository mining
MSR
data integration
source control
bug repository
data extraction
data format
statistical analysis tool
DSL
multiple iteration
environment development
source code modification
version control system
bug tracking system
Measurement
Grammar
Software
Libraries
Loading},
   DOI = {10.1109/IWESEP.2012.20},
   year = {2012},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Narayanan, A. and Misra, A. and Sim, K. C. and Pundak, G. and Tripathi, A. and Elfeky, M. and Haghani, P. and Strohman, T. and Bacchiani, M.},
   title = {Toward Domain-Invariant Speech Recognition via Large Scale Training},
   booktitle = {2018 IEEE Spoken Language Technology Workshop (SLT)},
   pages = {441-447},
   abstract = {Current state-of-the-art automatic speech recognition systems are trained to work in specific `domains', defined based on factors like application, sampling rate and codec. When such recognizers are used in conditions that do not match the training domain, performance significantly drops. This work explores the idea of building a single domain-invariant model for varied use-cases by combining large scale training data from multiple application domains. Our final system is trained using 162,000 hours of speech. Additionally, each utterance is artificially distorted during training to simulate effects like background noise, codec distortion, and sampling rates. Our results show that, even at such a scale, a model thus trained works almost as well as those fine-tuned to specific subsets: A single model can be robust to multiple application domains, and variations like codecs and noise. More importantly, such models generalize better to unseen conditions and allow for rapid adaptation - we show that by using as little as 10 hours of data from a new domain, an adapted domain-invariant model can match performance of a domain-specific model trained from scratch using 70 times as much data. We also highlight some of the limitations of such models and areas that need addressing in future work.},
   keywords = {speech codecs
speech recognition
single domain-invariant model
scale training data
multiple application domains
codec distortion
domain-specific model
training domain
automatic speech recognition systems
domain-invariant speech recognition
large scale training
background noise
domain-invariant model
Training
Codecs
Adaptation models
Data models
Noise measurement
Feature extraction
Acoustics
multidomain model
domain robustness
noise robustness},
   DOI = {10.1109/SLT.2018.8639610},
   year = {2018},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Neubauer, P. and Bill, R. and Mayerhofer, T. and Wimmer, M.},
   title = {Automated generation of consistency-achieving model editors},
   booktitle = {2017 IEEE 24th International Conference on Software Analysis, Evolution and Reengineering (SANER)},
   pages = {127-137},
   abstract = {The advances of domain-specific modeling languages (DSMLs) and their editors created with modern language work-benches, have convinced domain experts of applying them as important and powerful means in their daily endeavors. Despite the fact that such editors are proficient in retaining syntactical model correctness, they present major shortages in mastering the preservation of consistency in models with elaborated language-specific constraints which require language engineers to manually implement sophisticated editing capabilities. Consequently, there is a demand for automating procedures to support editor users in both comprehending as well as resolving consistency violations. In this paper, we present an approach to automate the generation of advanced editing support for DSMLs offering automated validation, content-assist, and quick fix capabilities beyond those created by state-of-the-art language workbenches that help domain experts in retaining and achieving the consistency of models. For validation, we show potential error causes for violated constraints, instead of only the context in which constraints are violated. The state-space explosion problem is mitigated by our approach resolving constraint violations by increasing the neighborhood scope in a three-stage process, seeking constraint repair solutions presented as quick fixes to the editor user. We illustrate and provide an initial evaluation of our approach based on an Xtext-based DSML for modeling service clusters.},
   keywords = {pattern clustering
program verification
simulation languages
automated consistency-achieving model editor generation
domain-specific modeling languages
modern language work-benches
domain experts
syntactical model correctness
language-specific constraints
language engineers
sophisticated editing capabilities
editor users
content-assist
automated validation
violated constraints
state-space explosion problem
constraint repair solutions
Xtext-based DSML
service clusters
Maintenance engineering
Manuals
Servers
Unified modeling language
Grammar
Optimization
Adaptation models
Domain Specific Modeling Languages
Model Driven Engineering
Search-based Software Engineering
Advanced Editor Support},
   DOI = {10.1109/SANER.2017.7884615},
   year = {2017},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Noughi, N. and Cleve, A.},
   title = {Conceptual interpretation of SQL execution traces for program comprehension},
   booktitle = {2015 IEEE 6th International Workshop on Program Comprehension through Dynamic Analysis (PCODA)},
   pages = {19-24},
   abstract = {Modern data-intensive software systems manipulate an increasing amount of heterogeneous data usually stored in a database. Maintaining such systems became a crucial and complex task, which is especially true due to the lack of sufficient documentation. In this context, program comprehension became a primary and an important step in this task. Unfortunately, the highly dynamic nature of interactions between a system and its database makes it hard to analyze these interactions with static analysis techniques. To this end, we propose a novel approach that combines dynamic analysis techniques and visualization to ease understanding data-intensive systems, by focusing on their database manipulation behavior. The approach consists of defining the conceptual interpretation of SQL execution traces in terms of a domain-specific, platform-independent model.},
   keywords = {data visualisation
distributed databases
program diagnostics
SQL
conceptual interpretation
SQL execution traces
program comprehension
data-intensive software systems
heterogeneous data
static analysis techniques
dynamic analysis techniques
data visualization
database manipulation behavior
domain-specific model
platform-independent model
Visualization
Databases
Cities and towns
Natural languages
Context
Software systems
Abstracts},
   DOI = {10.1109/PCODA.2015.7067179},
   year = {2015},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Oakes, B. J. and Franceschini, R. and Mierlo, S. Van and Vangheluwe, H.},
   title = {The Computational Notebook Paradigm for Multi-paradigm Modeling},
   booktitle = {2019 ACM/IEEE 22nd International Conference on Model Driven Engineering Languages and Systems Companion (MODELS-C)},
   pages = {449-454},
   abstract = {Computational notebooks are gaining widespread acceptance as a paradigm for storage, dissemination, and re-production of experimental results. In this paper, we define the computational notebook paradigm (CNP) consisting of entities and processes and discuss how the reproducibility of the experimental process and results is enhanced by each element. This paper also details the interactions of CNP and multi-paradigm modeling (MPM), with an aim of understanding how to support MPM within the CNP, and improve the reproducibility aspects of both the CNP and MPM.},
   keywords = {storage management
system documentation
CNP
computational notebook paradigm
computational notebooks
experimental process
multiparadigm modeling
Multi-paradigm modeling
Paradigms
Reproducibility},
   DOI = {10.1109/MODELS-C.2019.00072},
   year = {2019},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Oehler, M. and Phatak, D. S.},
   title = {A Conjunction for Private Stream Searching},
   booktitle = {2013 International Conference on Social Computing},
   pages = {441-447},
   abstract = {Our contribution defines a conjunction operator for private stream searching. Private stream searching is a system of cryptographic methods that preserves the confidentiality of the search criteria and the result. The system uses an encrypted filter to conceal the search terms, processes a search without decrypting these terms, and saves the result to an encrypted buffer. Fundamentally, the system provides a private search capability based on a logical disjunction of search terms. Our conjunction operator broadens the search capability, and achieves this without significantly increasing the complexity of the private search system. The conjunction is processed as a bit wise summation of hashed keyword values to reference an encrypted entry in the filter. The method is best suited for a conjunction of fields from a record, does not impute a calculation of bilinear map, as required in prior research, and offers a practical utility that integrates into private stream searching. We demonstrate the practicality by including the conjunction operator into our domain specific language for private packet filtering.},
   keywords = {cryptography
data privacy
information retrieval
specification languages
conjunction filter
private stream searching
conjunction operator
cryptographic methods
search criteria confidentiality
encrypted buffer
encrypted filter
logical disjunction
search capability
bit wise summation
hashed keyword values
bilinear map
private packet filtering
domain specific language
Dictionaries
Buffer storage
IP networks
Indexes
Encryption
Public key
Oblivious Transfer
Packet Filtering
Private Search
Security Language},
   DOI = {10.1109/SocialCom.2013.69},
   year = {2013},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Oliveira, R. and Pereira, D. and Maia, C. and Santos, P.},
   title = {A Domain Specific Language for Automotive Systems Integration},
   booktitle = {IECON 2019 - 45th Annual Conference of the IEEE Industrial Electronics Society},
   volume = {1},
   pages = {4483-4488},
   abstract = {Developing complex safe and secure Cyber-Physical Systems (CPS) applications for the automotive domain is typically a complex task, due to the criticality inherent to this domain. Considering such known complexity of the development process, we propose a novel solution that aims to provide a quasi-automatic' integration process between the different components of such CPS systems via the support of a Domain Specific Language (DSL) that provides several views of the system, abstracting away the more technical implementation details, while imposing system properties and restrictions that have the potential to be formally verified (either statically or at run-time) during design, and facilitates the process of customization and quasi-automatic build and deployment processes. In this paper, we briefly analyze the tools that are available and that cover partially the characteristics of our envisioned DSL, describe its building blocks, and show how it can be applied in a small, yet sufficiently complex CPS application whose architecture is very close to what we may expect for the modern and future generation of CPS application in the automotive domain.},
   keywords = {automobile industry
cyber-physical systems
high level languages
mechanical engineering computing
security of data
automotive domain
CPS systems
domain specific language
secure cyber-physical systems
complex cyber-physical systems
safe cyber-physical systems
automotive systems integration
quasiautomatic integration process
DSL
Tools
Unified modeling language
Automotive engineering
Computer architecture
Security
Software
system verification
CPS application development
system integration
domain specific languages},
   ISBN = {2577-1647},
   DOI = {10.1109/IECON.2019.8927516},
   year = {2019},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Olukotun, K.},
   title = {Scaling data analytics with moore's law},
   booktitle = {2016 International Conference on Parallel Architecture and Compilation Techniques (PACT)},
   pages = {313-313},
   abstract = {Analyzing the volume, variety and velocity of big data requires the use of modern heterogeneous computing platforms composed of multicores with SIMD execution units, GPUs, clusters, FPGAs and in the future new reconfigurable architectures. However, programming in this environment is extremely challenging due to the need to use multiple low-level programming models and then combine them together in ad-hoc ways. Furthermore, many data analytics algorithms do not take full advantage of modern hardware capabilities. To optimize big data applications both for modern hardware and for modern programmers needs algorithms specialized for modern hardware and a high-level programming model that executes efficiently on heterogeneous parallel hardware. In this talk, I will describe the Delite DSL framework, which uses nested parallel patterns encapsulated in domain specific languages (DSLs). I will describe how a nested parallel pattern based programming model can be used to develop new data analytics algorithms that are optimized for architectures as diverse as multicore/NUMA, clusters, GPUs, FPGAs and a new reconfigurable architecture called Plasticine.},
   keywords = {Big Data
data analysis
parallel programming
specification languages
data analytics
Moore law
Delite DSL framework
nested parallel pattern based programming model
domain specific language
Multicore processing
Parallel processing
Hardware
DSL
Reconfigurable architectures
Data models
Heterogeneous architectures
Domain Specific Programming Languages},
   DOI = {10.1145/2967938.2970375},
   year = {2016},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Ouchani, S. and Khaled, A.},
   title = {A Meta Language for Cyber-Physical Systems and Threats: Application on Autonomous Vehicle},
   booktitle = {2019 IEEE/ACS 16th International Conference on Computer Systems and Applications (AICCSA)},
   pages = {1-8},
   abstract = {One of the main challenges in the development process of secure systems is how to detect as early as possible the system's vulnerabilities and weaknesses, and also how to quantify the severity of attacks through them. In this paper, we rely on the concept of attack surfaces to implement a secure cyber physical system in Java. Attack surfaces can be sometimes detected automatically, regarding the used language, by matching them against known attacks still is a step apart. Further, systems and attacks are not usually modeled with compatible formalism. This paper develops a modeling framework that automates the whole process by generating attacks for cyber physical systems. First, we formalize a system using UML class and activity diagrams. Further, we use UML to develop a meta language for cyber physical systems, cyber attacks, and cyber counter measures. The framework instantiates the dependent-application diagrams for the domain/application in test, searches for the existing attack surfaces; then it generates the possible attacks that might exploit the found vulnerabilities/weaknesses. Further the proposed framework generates the proper java code for the composition counter measures, attacks, and CPS models.},
   keywords = {Cyber Security
Domain Specific Language
CPS
Threat behavior
Attack Graphs
UML
JAVA},
   ISBN = {2161-5330},
   DOI = {10.1109/AICCSA47632.2019.9035273},
   year = {2019},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Ouraiba, E. A. and Choquet, C. and Cottier, P.},
   title = {Domain-Specific Modeling Approach to Support Instructional Design Rationale},
   booktitle = {2011 IEEE 11th International Conference on Advanced Learning Technologies},
   pages = {205-206},
   abstract = {We investigate in this paper the instructional design rationale of open pedagogical scenarios. We use the Domain-Specific Modeling (DSM) approach for proposing Domain-Specific Educational Modeling Languages (DSEML) and dedicated editors to teachers/designers in order to allow them to work at a high-level of abstraction. Thanks to EMF tools we have realized a first implementation of our proposal about learning sessions of Hop3x. The Hop3x's DSEML is described by a metamodel and accordingly a first version of specific editor has been generated.},
   keywords = {computer aided instruction
simulation languages
instructional design rationale
open pedagogical scenarios
domain-specific modeling
educational modeling languages
abstraction
EMF tools
learning sessions
DSEML
Context
Object oriented modeling
Semantics
Biological system modeling
Proposals
Adaptation models
Context modeling
design rationale
instructional design
open pedagogical scenario},
   ISBN = {2161-377X},
   DOI = {10.1109/ICALT.2011.66},
   year = {2011},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Ouraiba, E. A. and Choquet, C. and Cottier, P. and Després, C. and Jacoboni, P.},
   title = {Engineering of Open Learning Scenarios - The Case of Hop3x Learning Scenarios},
   booktitle = {2010 10th IEEE International Conference on Advanced Learning Technologies},
   pages = {264-268},
   abstract = {Within an educational context, adaptation could improve the learning's quality. Many researches are done in the learning-situations adaptation field. The Educational Modeling Languages (EML) and tools provided currently to the teacher for a learning design, as preexistent means in our sense, remain useless by practitioners. In our work we aim to support the practitioner teacher to design and adapt his/her learning scenarios which are by nature open, influenced by the context in which they are executed. The approach adopted is the combination between Model-Driven Engineering (MDE) and Domain-Specific Modeling (DSM). In this paper we present a model of open learning scenario. So we take the learning scenarios of Hop3x as a case study.},
   keywords = {computer aided instruction
digital simulation
software engineering
open learning scenarios
Hop3x learning scenario
educational context
educational modeling languages
practitioner teacher support
model-driven engineering
domain-specific modeling
Adaptation model
Context
Education
Computational modeling
Computer science
Conferences
Proposals
learning design
adaptation
open learning scenario
learning context
Model Driven Engineering
Domain Specific Modeling},
   ISBN = {2161-377X},
   DOI = {10.1109/ICALT.2010.78},
   year = {2010},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Paczona, M. and Mayr, H. C.},
   title = {Model-Driven Mechatronic System Development},
   booktitle = {2019 IEEE 15th International Conference on Automation Science and Engineering (CASE)},
   pages = {1730-1736},
   abstract = {This paper presents an approach for model-driven mechatronic system development. The approach starts with the definition of a suitable domain-specific modeling language and its semantic foundation in a domain ontology. Models created in this language are used to generate application-specific artefacts. We illustrate our approach with the example of the development of Electric Vehicle Testbeds (EVTs), i.e. systems for testing high-voltage electric vehicle components. Companies in the electric vehicle industry (automobile, aircraft and rail vehicle manufacturers) mainly use such systems. Like many other mechatronic systems, EVTs are typically tailor-made solutions. Our approach automates manual development steps and can thus contribute to quality improvement, development time reduction and finally cost reduction.},
   keywords = {control engineering computing
mechanical engineering computing
mechatronics
ontologies (artificial intelligence)
specification languages
model-driven mechatronic system development
application-specific artefacts
high-voltage electric vehicle components
mechatronic systems
development time reduction
electric vehicle testbeds
domain-specific modeling language
domain ontology
cost reduction
quality improvement
Ontologies
Integrated circuit modeling
Unified modeling language
Software
Tools
Electric vehicles},
   ISBN = {2161-8089},
   DOI = {10.1109/COASE.2019.8843314},
   year = {2019},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Palensky, P. and Widl, E. and Stifter, M. and Elsheikh, A.},
   title = {Modeling intelligent energy systems: Co-Simulation platform for validating flexible-demand EV charging management},
   booktitle = {2014 IEEE PES General Meeting | Conference & Exposition},
   pages = {1-1},
   abstract = {Summary form only given. Energy systems experience a rise in complexity: new technologies, topologies and components, tighter links to other systems like markets and the increased usage of information technology. This leads to challenging questions that can not be answered via traditional methods. The goal of including renewable energy and clean technologies in the grid, however, requires solutions for the resulting complex problems. This paper investigates dynamic demand response for intelligent electric vehicle charging as a use-case for detailed hybrid models that cannot be properly handled by traditional tools alone. Universal modeling languages and specialized domain-specific modeling solutions are brought together via standardized cosimulation interfaces to achieve maximal flexibility and minimal implementation efforts. This combination of previously numerically incompatible modeling paradigms enables a detailed look into the dynamics of hybrid component models while keeping the comfort and the strength of established tools. This coupling of a Modelica-based physical simulation engine, a commercial power system simulation tool and an agent-based discrete event simulator for energy grids results in a novel co-simulation platform. This visionary concept provides the high level of detail, scope, flexibility, scalability and accuracy in simulations needed to analyze and optimize energy systems of the future.},
   keywords = {battery management systems
battery powered vehicles
discrete event simulation
power grids
intelligent energy systems
co-simulation platform
flexible-demand EV charging management
dynamic demand response
intelligent electric vehicle charging
universal modeling languages
domain-specific modeling solutions
hybrid component models
Modelica-based physical simulation engine
power system simulation tool
agent-based discrete event simulator
energy grids
Numerical models
Power system dynamics
Vehicle dynamics
Artificial intelligence
Complexity theory
Topology
Information technology},
   ISBN = {1932-5517},
   DOI = {10.1109/PESGM.2014.6939434},
   year = {2014},
   type = {Conference Proceedings}
}

@article{
   author = {Pathak, S. D. and Dilts, D. M. and Biswas, G.},
   title = {On the Evolutionary Dynamics of Supply Network Topologies},
   journal = {IEEE Transactions on Engineering Management},
   journalAlt = {IEEE Transactions on Engineering Management},
   volume = {54},
   number = {4},
   pages = {662-672},
   abstract = {Supply chains, or supply networks (SNs), exist in a multitude of different topologies, yet little is known concerning how such topologies grow, evolve, and adapt over time. To study this complex phenomenon, we begin by identifying some primary topological structures that SNs may form. Then, to investigate the evolution of such structures, a theory-based framework is developed that combines aspects of complex adaptive systems theory, industrial growth theory, network theory, market structure, and game theory. This framework specifies categories of rules that may evoke different behaviors in the two fundamental components of any adaptive SN, i.e., the environment and the Arms in that environment. The framework is implemented as a multiparadigm simulation utilizing software agents and it joins discrete-time with discrete-event simulation formalisms. This methodology allows the spontaneous generation of network structures so that it is possible to examine the potential factors behind the evolution of different SN topologies. Using data and parameters extracted from 80 years of the U.S. automobile industry, we have been able to "grow" a wide range of SN topologies and preliminary results show that certain environmental and firm-level factors may impact the eventual evolution of such structures.},
   keywords = {corporate modelling
game theory
organisational aspects
software agents
supply chains
discrete-time simulation formalisms
discrete-event simulation formalisms
market structure
network theory
industrial growth theory
adaptive systems theory
theory-based framework
primary topological structures
supply network topology
evolutionary dynamics
Adaptive systems
Network topology
Complex adaptive systems
emergence
simulation
supply chain topologies
supply network (SN) topologies},
   ISSN = {1558-0040},
   DOI = {10.1109/TEM.2007.906856},
   year = {2007},
   type = {Journal Article}
}

@inproceedings{
   author = {Paunov, S. and Hill, J. and Schmidt, D. and Baker, S. D. and Slaby, J. M.},
   title = {Domain-specific modeling languages for configuring and evaluating enterprise DRE system quality of service},
   booktitle = {13th Annual IEEE International Symposium and Workshop on Engineering of Computer-Based Systems (ECBS'06)},
   pages = {10 pp.-208},
   abstract = {The quality of service (QoS) of enterprise distributed real-time and embedded (DRE) systems can degrade under certain operating conditions and system architectures. This paper provides two contributions to research on model-driven development (MDD) tools and methods that help identify and rectify these QoS problems in component-based enterprise DRE systems. First, we show how MDD tools can be used to simplify and automate the evaluation of component-based DRE systems to identify QoS problems. Second, we show how MDD tools can be used to specify alternative QoS polices for component-based DRE systems and synthesize metadata automatically to simplify system (re)configurations that rectify QoS problems. We illustrate our MDD tools on a case study of multi-layer resource management services for shipboard computing systems that automate many aspects of power, navigation, command and control, and tactical operations},
   keywords = {distributed processing
embedded systems
enterprise resource planning
formal specification
object-oriented programming
quality of service
simulation languages
domain specific modeling language
component-based enterprise DRE system
distributed real-time embedded system
system architecture
model driven development tool
system configuration
multilayer resource management service
shipboard computing system
Application software
Real time systems
Resource management
Computer networks
Distributed computing
Embedded computing
Delay
Computer architecture
Companies},
   DOI = {10.1109/ECBS.2006.39},
   year = {2006},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Peng, Y. and Zhao, C. and Yao, S. and Li, S. and Chen, Y.},
   title = {Scheduling Multi-paradigm and Multi-grain Parallel Components on Heterogeneous Platforms},
   booktitle = {2011 Sixth Annual Chinagrid Conference},
   pages = {15-21},
   abstract = {In this paper, we present a multi-paradigm and multi-grain parallel component model. It is an extension to the Common Component Architecture (CCA). Components have two kinds of paradigms, running paradigms and programming paradigms. Running paradigms can be serial execution, message passing parallel, or memory sharing parallel. Programming paradigms can be the programming languages the components use. The grain of a component can be coarse, middle, or fine. We built a resource management system to manage our heterogeneous platforms. We gave a components schedule policy. It is based on the paradigms and grains descriptions of components. It also uses resources information. This policy improves the performance of CCA parallel components applications. And it raises the utilization of heterogeneous platforms.},
   keywords = {parallel processing
scheduling
scheduling multi-paradigm
multigrain parallel components
heterogeneous platforms
common component architecture
message passing
memory sharing parallel
programming languages
resource management system
Servers
Resource management
Software
Engines
Component architectures
Programming
Image processing
parallel component
multi-paradigm
multi-grain
performance prediction
CCA},
   ISBN = {1949-1328},
   DOI = {10.1109/ChinaGrid.2011.12},
   year = {2011},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Periola, A. A. and Alonge, A. A. and Ogudo, K. A.},
   title = {Multi-Paradigm Computing Architecture for Power Efficient Intent Based Networks},
   booktitle = {2019 IEEE 2nd Wireless Africa Conference (WAC)},
   pages = {1-7},
   abstract = {Machine learning plays an important role in next generation Intent based networks. The realization of the potential of machine learning requires big data processing. This can be achieved in cloud computing platforms that utilize Von-Neumann hardware. Von-Neumann hardware big data processing for machine learning is power intensive. Therefore, a mechanism for realizing low power big data processing and machine learning algorithm development is required. The use of neuromorphic computing hardware with low power consumption can achieve this goal. This paper proposes a multi-paradigm computing architecture that incorporates neuromorphic and Von Neumann hardware. This is done to protect existing investment in Von Neumann hardware infrastructure. The proposed architecture is intended for use in machine learning driven Intent based networks. The paper also proposes the use of a pause feature to ensure that unused processors are inactive state. Performance evaluation shows that the proposed mechanism enhances the existing approach of using only Von-Neumann hardware. The proposed mechanism reduces cloud power consumption, enhances data transmit power, number of data transmit epochs and the power usage effectiveness by up to 51.3%, 28.4%, 94% and 68.2% on average respectively.},
   keywords = {Big Data
cloud computing
computer centres
learning (artificial intelligence)
power aware computing
power consumption
multiparadigm computing architecture
power efficient Intent based networks
generation Intent based networks
Von-Neumann hardware big data processing
low power big data processing
machine learning algorithm development
neuromorphic computing hardware
Von Neumann hardware infrastructure
cloud power consumption
data transmit power
power usage effectiveness
Computer architecture
Hardware
Neuromorphic engineering
Deep learning
Intent Based Networks
Cloud Platforms
Neuromorphic systems
Von-Neumann systems},
   DOI = {10.1109/AFRICA.2019.8843400},
   year = {2019},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Pfeiffer, M. and Pichler, J.},
   title = {A DSM approach for end-user programming in the automation domain},
   booktitle = {2009 7th IEEE International Conference on Industrial Informatics},
   pages = {142-148},
   abstract = {In this paper we present an approach and a software prototype that enables domain experts to program control software in the automation domain. The approach follows the principles of domain-specific modeling providing a graphical domain-specific language to model the control cycle of an injection molding machine, a user interface to manipulate and monitor the control cycle as well as code generators to generate control code that can be executed by the machine. As result, domain experts like machine operators can manipulate and monitor the control cycle directly on the touch-screen of a machine without detailed software development expertise.},
   keywords = {control engineering computing
injection moulding
object-oriented languages
production engineering computing
production equipment
program compilers
user interfaces
end-user programming
DSM
domain-specific modeling
graphical domain-specific language
injection molding machine
user interface
control cycle
touch-screen
control software program
code generators
automation
Automatic programming
DSL
Automatic control
Application software
Domain specific languages
Automatic generation control
IEC standards
Software prototyping
Injection molding},
   ISBN = {2378-363X},
   DOI = {10.1109/INDIN.2009.5195793},
   year = {2009},
   type = {Conference Proceedings}
}

@article{
   author = {Pham, H.},
   title = {Special Issue on Critical Reliability Challenges and Practices [Guest Editorial]},
   journal = {IEEE Transactions on Systems, Man, and Cybernetics - Part A: Systems and Humans},
   journalAlt = {IEEE Transactions on Systems, Man, and Cybernetics - Part A: Systems and Humans},
   volume = {37},
   number = {2},
   pages = {141-142},
   abstract = {The six papers in this special issue address various research challenges in the reliability-related areas including optimization, software reliability and measurements, network reliability, software quality, semisupervised learning, Bayesian approach, statistical anomaly detection, flooding attacks, genetic algorithms, multistate systems, system redundancy, service reliability, multiparadigm modeling, heuristic algorithms, and grid and distributed computing. The selected papers are briefly summarized.},
   keywords = {Software reliability
Area measurement
Software measurement
Software quality
Semisupervised learning
Bayesian methods
Genetic algorithms
Redundancy
Heuristic algorithms
Software algorithms},
   ISSN = {1558-2426},
   DOI = {10.1109/TSMCA.2007.891923},
   year = {2007},
   type = {Journal Article}
}

@inproceedings{
   author = {Phull, D. K. and Kumar, G. B.},
   title = {Analyzing various topic modeling approaches for Domain-Specific language model},
   booktitle = {2017 International Conference on Networks & Advances in Computational Technologies (NetACT)},
   pages = {69-73},
   abstract = {In recent times, topic modeling approaches for adaptive language modeling have been extensively explored for Natural Language Processing applications such as machine translation, speech recognition etc. Language model is extremely fragile in adapting towards the required domain, so it needs to be channeled towards an area or a topic for producing optimal results. This paves the need to investigate various topic modeling approaches which are used to infer knowledge from a large corpora. In this paper, we mileage various topic modeling techniques which include Latent Semantic Indexing, Latent Dirichlet Allocation and Hierarchical Dirichlet Process. In this process, the baseline language model is dynamically adapted to different topics and the results are analyzed for these three topic modeling approaches.},
   keywords = {indexing
inference mechanisms
natural language processing
specification languages
statistical analysis
text analysis
topic modeling approaches
domain-specific language model
adaptive language modeling
baseline language model
knowledge inference
latent semantic indexing
latent Dirichlet allocation
hierarchical Dirichlet process
Adaptation models
Computational modeling
Mathematical model
Semantics
Analytical models
Large scale integration
Domain Modeling
Topic Modeling
Language Modeling
Dynamically adapted},
   DOI = {10.1109/NETACT.2017.8076743},
   year = {2017},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Plusch, M. and Fry, C. and Haase, K. and Farrell, T.},
   title = {Modeling Executable Specifications with X-Spec and Water},
   booktitle = {2007 International Conference on Integration of Knowledge Intensive Multi-Agent Systems},
   pages = {69-72},
   abstract = {X-Spectrade is a business modeling tool and executable specification language that enables business people to describing requirements in their domain language. The specification, or model, can be shown in multiple editable views that use English and pictures. The specification is directly executed to deliver a fully-functional user interface for rich Internet applications. The model is available at run-time, since no code is generated. The model enforces the clean separation of user interface, controller logic, and services. X-Spec is built on the Water language. Watertrade is an open dynamic, object-based language that uses ConciseXMLtrade syntax. It is a multi-paradigm language that can represent many different modeling styles and forms of knowledge representation. Water can treat code as data, and is a meta-language for creating domain specific models. Water integrates many features of RDF and OWL. The Water language may be expressed in graphical views as well as ConciseXML.},
   keywords = {public domain software
specification languages
XML
executable specification modeling
X-Spec
business modeling tool
executable specification language
domain language
user interface
rich Internet applications
controller logic
Water language
open dynamic language
object-based language
ConciseXML syntax
knowledge representation
meta-language
Object oriented modeling
User interfaces
Natural languages
Management training
Graphics
Internet
Runtime
Logic
Resource description framework},
   DOI = {10.1109/KIMAS.2007.369787},
   year = {2007},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Quirós, G. and Cao, D. and Cañedo, A.},
   title = {Dispersed automation for industrial Internet of Things — An enabler for advanced manufacturing},
   booktitle = {2017 13th IEEE Conference on Automation Science and Engineering (CASE)},
   pages = {269-274},
   abstract = {This position paper introduces the vision of Dispersed Automation, a novel approach for reprogramming the omnipresent Industrial Internet of Things (IIoT) devices in critical infrastructure for the co-execution of general-purpose computation workloads in an optimal and reliable manner. The key observation is that IIoT devices are available in large quantities in critical infrastructure (e.g., micro-grids, water management and treatment, energy generation and transmission, manufacturing, buildings, and traffic) but are often underutilized due to the conservative allocation of resources, static task assignment, and lack of exploitation of parallelism that is intrinsic in redundant hardware. Dispersed Automation can give new life to IIoT devices, some of them as powerful as general-purpose computers, and can make them accessible for the co-execution of various computational workloads while dynamically adapting to different applications and operational environments. Two key technical innovations will make this possible: the use of a domain-specific language, and on-channel computation. This paper shows how Dispersed Automation can be an enabling technology for the implementation of smart manufacturing systems.},
   keywords = {Internet of Things
manufacturing systems
production engineering computing
resource allocation
Dispersed automation
critical infrastructure
general-purpose computation workloads
IIoT devices
traffic
general-purpose computers
computational workloads
omnipresent Industrial Internet of Things devices
domain-specific language
on-channel computation
smart manufacturing systems
Automation
Programming
Real-time systems
Performance evaluation
Runtime},
   ISBN = {2161-8089},
   DOI = {10.1109/COASE.2017.8256113},
   year = {2017},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Reimer, U. and Laurenzi, E.},
   title = {Creating and maintaining a collaboration platform via domain-specific reference modelling},
   booktitle = {eChallenges e-2014 Conference Proceedings},
   pages = {1-9},
   abstract = {We present a model-driven approach to create and maintain a collaboration platform for supporting the collaboration between acute hospitals and rehabilitation clinics to optimize transferal management. The model-driven approach makes the platform highly configurable to accommodate new clinical pathways and be easily extendable to include additional functions to meet future needs. All domain-specific aspects are described declaratively in an application model. The elements in the application model are mapped to corresponding elements in an application framework to obtain the executable collaboration platform. Attaching the mappings to the constructs of an underlying domain-specific language ensures that executable code can be derived from all application models. Furthermore, our framework includes reference models which serve as blueprints and will make it easier to create and adapt application models.},
   keywords = {groupware
hospitals
software engineering
collaboration platform creation
domain-specific reference modelling
model-driven approach
collaboration platform maintenance
acute hospitals
rehabilitation clinics
transferal management optimization
clinical pathways
application framework
domain-specific language
executable code
Unified modeling language
Adaptation models
DSL
Collaboration
Logic gates
Surgery},
   ISBN = {2166-1677},    year = {2014},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Reinfelds, J.},
   title = {Programming as an engineering discipline},
   booktitle = {32nd Annual Frontiers in Education},
   volume = {2},
   pages = {F2G-F2G},
   abstract = {For too long computer programming has been treated as an art or a craft rather than as a science or an engineering discipline. The Kernel Language approach provides a precise and concise basis for programming in all paradigms (imperative, logical, functional and object-oriented) as well as for parallel, concurrent and distributed multi-thread programming. The Kernel Language is implemented as a subset of Oz, a powerful, multi-paradigm programming language that is similar to Java. This allows us to apply the theory to enhance the art of practical problem solving. KL allows us to introduce multi-thread programming and the major programming paradigms in first courses of programming. With the rapidly expanding acceptance of multi-language programming capabilities of dotNET, a revision of traditional introductory programming courses becomes more and more important.},
   keywords = {computer science education
object-oriented programming
multi-threading
parallel programming
educational courses
multi-paradigm programming
net-centric programming
teaching
distributed multi-thread programming
Oz multi-paradigm programming language
computer programming
Kernel Language approach
concurrent programming
multi-language programming capabilities
dotNET
introductory programming courses
object oriented programming
Art
Kernel
Functional programming
Logic programming
Power engineering and energy
Computer languages
Java
Problem-solving},
   ISBN = {0190-5848},
   DOI = {10.1109/FIE.2002.1158173},
   year = {2002},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Roberge, D. and MacLeod, B. and Hartsock, B. and Asangansi, I.},
   title = {Integrating Mobile Collection Software with Health Applications},
   booktitle = {2011 IEEE Global Humanitarian Technology Conference},
   pages = {122-126},
   abstract = {This paper describes and analyzes three approaches for integrating mobile data collection software and health applications. The first approach uses a domain-specific language module that is installed in a health application that communicates directly with the mobile data collection software. The second approach uses Mirth Connect to integrate the mobile collection software with a health application. The third approach is writing custom code required to integrate mobile data collection software with a health application. In the final section of this paper, we provide an analysis of the three approaches, and make recommendations on which approach should be used based on the resources available to a health facility.},
   keywords = {health care
hospitals
medical information systems
mobile computing
specification languages
mobile collection software
health applications
mobile data collection software
domain-specific language module
Mirth connect
custom code
health facility
DSL
Mobile communication
Databases
Web services
Mobile handsets
Manuals
OpenHDS
Mobile Devices
Health Software
System Integration},
   DOI = {10.1109/GHTC.2011.91},
   year = {2011},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Rock, C. T. and Soule, N. and Toll, B. and Do, E. and Milligan, J. R. and Paulini, M. S.},
   title = {Efficiently Composing Validated Systems Integration Gateways for Dynamic, Diverse Data},
   booktitle = {MILCOM 2019 - 2019 IEEE Military Communications Conference (MILCOM)},
   pages = {46-53},
   abstract = {Software systems typically evolve independently from one another. Integration opportunities and benefits only become apparent when new users or organizations adopt the system into the composition of a new system of systems solution, typically when new use cases are identified, or tangential needs arise. This leads to systems designed to use different data formats, network protocols, interaction patterns, and other disparities unable to natively communicate with each other. When integration does occur, it is often with custom one-off solutions that bridge the networks and systems in question. While integration may be plausible and even successful, these solutions tend to be costly, slow to produce, and tightly coupled to the specific systems or, even worse, specific versions of systems that they are connecting. In this paper we examine ROGER, a composable and dynamic gateway building framework that helps to address these integration costs and complexities. The ROGER framework abstracts away the common infrastructure needed in any system-bridging middleware, fosters reuse and capability sharing through a composition-driven plug-in framework, and allows for rapid gateway construction through a policy-centric composition structure. ROGER seeks to shorten integration gateway development time, reduce the amount of code creation required to build and deploy new gateways, as well as enable in-mission adaptation and extension of gateway capabilities as mission parameters and system awareness dictates. At the heart of this dynamism and adaptability in ROGER is the Information Flow Policy (IFP), a domain specific language that describes processing pipelines over incoming data streams. This paper presents the design of the compositional model and of the IFP that describes and enables the composition. We use a set of ROGER gateways as a dataset, along with a representative case study, in initial evaluations that show promising results regarding ROGER's ability to reduce development time and cost as well as minimize required skill sets.},
   keywords = {Logic gates
Bridges
Protocols
Pipelines
Software systems
Buildings
Middleware
gateway
integration framework
framework-specific modeling language
validation
plug-ins
code reuse
dataflow
message-oriented middleware},
   ISBN = {2155-7586},
   DOI = {10.1109/MILCOM47813.2019.9020714},
   year = {2019},
   type = {Conference Proceedings}
}

@article{
   author = {Rosique, F. and Jimenez, M. and Iborra, A.},
   title = {A Graphical Modeling Language for Home Automation},
   journal = {IEEE Latin America Transactions},
   journalAlt = {IEEE Latin America Transactions},
   volume = {10},
   number = {6},
   pages = {2249-2255},
   abstract = {Home automation systems have emerged as one of the most attractive fields in engineering, thanks to the burgeoning demand from society for information systems. Today, the development of these systems is confined to the immediate context of the solution and is platform-dependent. This has intensified the need for suitable tools to tackle their development while enhancing quality and productivity. On one hand, domain specific languages allow the description of the system by means of graphic models easily and intuitively, using domain concepts. On the other hand, the model driven development approach stands out as a good option for solving the problems of the existing methods, as well as contributing tools that pioneer the development of domain specific languages. The present article proposes an alternative methodology and tools for the development of home automation applications following the model driven approach together with the use of a domain specific language.},
   keywords = {formal specification
home automation
information systems
software tools
specification languages
graphical modeling language
home automation systems
domain specific languages
graphic models
domain concepts
model driven development approach
home automation applications
model driven approach
DSL
Software
Visualization
Computational modeling
Computer integrated manufacturing
model driven engineering},
   ISSN = {1548-0992},
   DOI = {10.1109/TLA.2012.6418129},
   year = {2012},
   type = {Journal Article}
}

@inproceedings{
   author = {Ross, W. and Ulieru, M. and Gorod, A.},
   title = {A multi-paradigm modelling & simulation approach for system of systems engineering: A case study},
   booktitle = {2014 9th International Conference on System of Systems Engineering (SOSE)},
   pages = {183-188},
   abstract = {The process of modelling and simulation (M&S) plays a critical role in system of systems (SoS) engineering, given its ability to capture and visualize the dynamic nature embedded within SoS complexity. While there are multiple M&S paradigms, currently there is limited guidance for selecting the most appropriate one(s) based on the intention of the SoS modeller, which can manifest itself through different “views” of the SoS. This paper examines three such viewssocial physical, and socio-physical-and suggests an approach for matching each view with the most-suitable paradigm(s) in order to better represent the modeller's intention. A real-life case study of an emergency-response situation is presented to demonstrate the applicability of the introduced approach.},
   keywords = {modelling
simulation
systems engineering
multiparadigm modelling
system of systems engineering
SoS engineering
SoS complexity
SoS modeller
modeller intention
emergency response situation
Hospitals
Educational institutions
Mathematical model
Modeling
Cities and towns
Complexity theory
Modelling and simulation
system of systems
socio-physical view
agent-based simulation
discrete-event simulation
system dynamics
multi-paradigm approach},
   DOI = {10.1109/SYSOSE.2014.6892485},
   year = {2014},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Roy, N. and Gokhale, A. and Dowdy, L.},
   title = {Impediments to Analytical Modeling of Multi-Tiered Web Applications},
   booktitle = {2010 IEEE International Symposium on Modeling, Analysis and Simulation of Computer and Telecommunication Systems},
   pages = {441-443},
   abstract = {Service providers hosting multi-tiered applications require accurate analytical models of the applications they will host for different system management activities, such as capacity planning, configuration management, cost analysis and feedback control. Due to the complexity of real world scenarios, developing accurate analytical models is hard. This paper presents the commonly faced challenges in developing these analytical models that stem from real-world issues, such as excessive system activity, presence of multiple cores or processors, and concurrency management. Presence of multi-tiered applications further compounds the challenges faced. We sketch preliminary ideas based on application-specific and/or domain-specific modeling techniques to overcome these limitations.},
   keywords = {data analysis
Web services
analytical modeling
multitiered Web application
service provider
system management
application-specific modeling
domain-specific modeling
Analytical models
Load modeling
Databases
Optimization
Computational modeling
Capacity planning
Program processors
Multi-tier applications
performance estimation
service deployment},
   ISBN = {2375-0227},
   DOI = {10.1109/MASCOTS.2010.60},
   year = {2010},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Rubin, S. H.},
   title = {On the fusion and transference of knowledge. I},
   booktitle = {Proceedings Fifth IEEE Workshop on Mobile Computing Systems and Applications},
   pages = {144-149},
   abstract = {Contemporary neural architectures having one or more hidden layers suffer from the same deficiencies that genetic algorithms and methodologies for non-trivial automatic programming do; namely, they cannot exploit inherent domain symmetries for the transference of knowledge from an application of lesser to greater rank, or across similar applications. As a direct consequence, no ensemble of contemporary neural architectures allows for the effective codification and transference of knowledge within a society of individuals (i.e., swarm knowledge). These deficiencies stem from the fact that contemporary neural architectures cannot reason symbolically using heuristic ontologies. They cannot directly provide symbolic explanations of what was learned for purposes of inspection and verification. Moreover, they do not allow the knowledge engineer to precondition the internal feature space through the application of domain-specific modeling languages. A symbolic representation can support the heuristic evolution of an ensemble of neural architectures. Each neural network in the ensemble imbues a hidden layer and for this reason is NP-hard in its learning performance. It may be argued that the internal use of a neat representation subsumes the heuristic evolution of a scruffy one. It follows that there is a duality of representation under transformation. The goal of AI then is to find symbolic representations, transformations, and associated heuristic ontologies. This paper provides an introduction to this quest. Consider the game of chess for example. If a neural network or symbolic heuristic is used to evaluate board positions, then the best found iterate (i.e., of weights or symbols) serves as a starting point for iterative refinement. This paper addresses the ordering and similarity of the training instances in refining subsequent iterates. If we fix the learning technology, then we need to focus on reducing the problem, composing intermediate results, and transferring the results to a similar domain. For example, moving just a bishop against one opposing piece is a reduction, moving a bishop and say a rook against one opposing piece a composition, and moving a queen against one or more opposing pieces a transference. The training sets must be mutually orthogonal, or random to maximize the learned content. Learning what to present and when involves self-reference and this necessarily implies a heuristic approach.},
   keywords = {learning (artificial intelligence)
neural nets
heuristic programming
information fusion
heuristics
neural network
information transference
genetic algorithm
nontrivial automatic programming
contemporary neural architectures
information codification
swarm knowledge
domain-specific modeling language
symbolic representation
heuristic evolution
neural architecture ensemble
learning
artificial intelligence
heuristic approach
training sets
Neural networks
Ontologies
Genetic algorithms
Automatic programming
Inspection
Knowledge engineering
Machine learning
Sensor phenomena and characterization
USA Councils
Domain specific languages},
   DOI = {10.1109/IRI.2003.1251407},
   year = {2003},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Salleh, F. H. M. and Bin, I. A. and Sayuti, A. B. and Omar, R. B.},
   title = {WOAL: A Tool to Orchestrate Workflow Using An Abstraction Layer},
   booktitle = {2019 IEEE Conference on e-Learning, e-Management & e- Services (IC3e)},
   pages = {46-51},
   abstract = {The development of systems with complex business processes needs developers who can orchestrate the system workflow accurately. Orchestrating workflow normally requires someone who has the knowledge in programming. This is because they are the ones who are able to directly link the workflow to the programming framework. Contrary to the normal practise, the business people is actually the best person to design the workflow as they are experts in their domain and therefore, can design complex workflow more accurately. However, business people have difficulty in orchestrating workflows using programming languages without having to go through a long learning process. Hence, the objective of Workflow Orchestration Abstraction Layer (WOAL) is to allow business people to design workflow on their own using an easy-to-understand language. They will be able to produce workflow diagrams for verification and workflow's automator for system development. This paper presents the architecture of WOAL, including the design of domain-specific language (DSL), lexer and parser.},
   keywords = {business data processing
formal specification
specification languages
workflow management software
programming languages
learning process
Workflow Orchestration Abstraction Layer
WOAL
business people
workflow diagrams
system development
complex business processes
system workflow
programming framework
complex workflow
domain-specific language
lexer
parser
workflow
abstraction layer},
   DOI = {10.1109/IC3e47558.2019.8971783},
   year = {2019},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Sannier, N. and Baudry, B.},
   title = {Toward multilevel textual requirements traceability using model-driven engineering and information retrieval},
   booktitle = {2012 Second IEEE International Workshop on Model-Driven Requirements Engineering (MoDRE)},
   pages = {29-38},
   abstract = {In complex industrial projects, textual information remains the main vector of information at the project level. Consequently, requirements are scattered throughout multiple documents expressing different levels of requirements and different kinds of requirements. Formalizing this information and tracing different relationships among documents and organizing this environment present a challenging question. Domain-specific modeling and traceability modeling are Model-Driven Engineering (MDE) techniques that could address various aspects of requirements formalization. Text-based high level requirements can be formalized as document concepts can be gathered and represented. Still, relationships cannot always be determined using sole MDE approaches and, as a consequence, relationships and traceability issue remains. Information retrieval (IR) approaches have already proved to work in an efficient way on large text corpora for requirements traceability analysis but do only consider similarity aspects of flatten documents, losing their organization and hierarchy. This paper aims to introduce how a combined use of both MDE and IR can lead to improved requirements organization and traceability while handling textual ambiguous requirements documents.},
   keywords = {formal specification
information retrieval
software engineering
text analysis
multilevel textual requirements traceability
model driven engineering
complex industrial projects
textual information
multiple documents
domain-specific modeling
traceability modeling
MDE techniques
Text-based high level requirements
IR approach
large text corpora
flatten documents
Indexes
Standards organizations
Organizations
Software
Analytical models
textual requirements
modeling
traceability},
   DOI = {10.1109/MoDRE.2012.6360072},
   year = {2012},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Santos, A. L. and Koskimies, K. and Lopes, A.},
   title = {Automated Domain-Specific Modeling Languages for Generating Framework-Based Applications},
   booktitle = {2008 12th International Software Product Line Conference},
   pages = {149-158},
   abstract = {The adoption of Domain-Specific Modeling Languages (DSMLs) for generating framework-based applications has proved to be an effective way of enforcing the correct use of frameworks and improve the productivity of application developers. However, the development of the code generator of a DSML is typically a laborious task with difficulties in what concerns complexity, understandability, and maintainability. In this paper, we address this problem with a new approach for developing DSMLs for frameworks that allows to eliminate the need of implementing code generators. The approach relies on the extension of frameworks with an additional layer based on aspect-oriented programming that encodes a DSML. By means of a generic language workbench, framework-based applications can be generated from application models described in that DSML. The proposed language workbench was implemented in a prototype tool and a case study on the Eclipse Rich Client Platform was performed.},
   keywords = {object-oriented programming
program compilers
simulation languages
automated domain-specific modeling languages
code generator
aspect-oriented programming
generic language workbench
Generators
Object oriented modeling
Buildings
Evolution (biology)
Java
Encoding
DSL
object-oriented frameworks
domain-specific modeling languages
language workbenches},
   DOI = {10.1109/SPLC.2008.17},
   year = {2008},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Schafer, W.},
   title = {Model driven development with mechatronic UML},
   booktitle = {2008 IEEE Symposium on Visual Languages and Human-Centric Computing},
   pages = {9-10},
   abstract = {We address these challenges by the model-driven mechatronic UML development approach which combines domain specific modeling and refinement techniques with verification based on compositional model checking. The approach suggests modeling the software by using a refined UML 2.0 component model including the detailed definition of ports, connectors, and patterns. We further refine the component model to define a proper integration between discrete and continuous control such that the reconfiguration of hierarchical component systems can be described in a modular way. Compositional model checking is based on a domain specific decomposition of the system specification into individually checkable components based on a common pre-defined architectural model. As a basis for formal verification, a formal semantic definition of the concepts taken from UML 2.0 is given. For the scope of this presentation, this is particularly done for our notion of so-called real-time statecharts. Besides supporting compositional verification, the approach supports checking consistency between different parts of a systems specification by a syntax check. This check is based on giving a formal definition of consistency.},
   keywords = {formal specification
mechanical engineering computing
mechatronics
object-oriented programming
program verification
software architecture
Unified Modeling Language
model-driven mechatronic UML development approach
domain specific modeling
refinement technique
compositional formal verification
compositional model checking
software architectural modeling
refined UML 2.0 component model
hierarchical component system reconfiguration
system specification
domain specific decomposition
formal semantic definition
real-time statechart
consistency checking
syntax check},
   ISBN = {1943-6106},
   DOI = {10.1109/VLHCC.2008.4639050},
   year = {2008},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Schmitt, C. and Kuckuk, S. and Köstler, H. and Hannig, F. and Teich, J.},
   title = {An Evaluation of Domain-Specific Language Technologies for Code Generation},
   booktitle = {2014 14th International Conference on Computational Science and Its Applications},
   pages = {18-26},
   abstract = {Software systems are becoming increasingly complex, requiring a deep knowledge to work and program with them. This is especially true for simulation frameworks used by scientists and engineers, but also applies to completely different domains such as mobile or web applications. To ease working with these systems, domain-specific languages (DSLs) are a convenient way to enable domain experts describe settings and problems they want to solve using terms familiar to them. Building upon this specification in the DSL, a compiler transform this to the target software framework, e.,g., runnable program code. To write such a compiler, a solid implementation framework is needed. In this paper, we propose criteria for the evaluation of textual programming language implementation frameworks to which we accordingly evaluate four technologies, namely Spoofax/IMP, Rascal MPL, a custom approach using C++ and a custom approach using Scala.},
   keywords = {C++ language
program compilers
specification languages
domain-specific language technology
code generation
software system
DSL
runnable program code
textual programming language
Spoofax/IMP
Rascal MPL
C++
Scala
Syntactics
Grammar
Abstracts
Pattern matching
Java},
   DOI = {10.1109/ICCSA.2014.16},
   year = {2014},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Sendall, S.},
   title = {Domain-driven software development - a world of transformations},
   booktitle = {Proceedings. 15th IEEE International Workshop on Rapid System Prototyping, 2004.},
   pages = {110-112},
   abstract = {Software development teams are faced with bridging the gap between the problem, as envisaged by the stakeholders and constrained by the environment, and a software solution, which is built upon the abstractions offered by current software technologies. Unfortunately, too often the abstractions offered are limited and disparate with respect to the problem space. Reducing this gap would facilitate more sophisticated problems to be tackled in software development projects, and it would comparatively reduce development costs and time-to-market, and remove errors caused by the disparity. In this talk, I will explore a number of techniques for improving current software development practice, which relate to the theme of domain-driven software development. Domain-driven software development is concerned with making use of languages that better capture the problem by using abstractions that are more familiar to experts in the domain. These domain-specific languages are made executable either directly (compilation or interpretation) or through tool-supported refinement/elaboration to computational models that can be executed, e.g., to a mainstream programming language where one can make use of existing frameworks, components, services, etc. In the later case, real value is added to software development only if we can automate as much as possible the transformation step(s). Automating these steps requires languages that can express such transformations in a concise and maintainable manner. The principles of abstraction, separation of concerns, and problem decomposition are essential in providing intuitive and manageable domain-specific languages. The practice of software modeling has become a significant way of applying these principles to software development. Over the last few years, the software development industry has gone through the process of standardizing visual modeling notations. The Unified Modeling Language (UML) is the product of this effort, and it unifies scores of notations that were proposed in the '80s and '90s. The language has gained significant industry support and became an object management group (OMG) standard in 1997. Nowadays, the majority of software modeling techniques and approaches use UML.},
   keywords = {software engineering
Unified Modeling Language
software tools
domain-driven software development
abstraction
tool support
programming language
domain-specific language
software modeling
object management group
OMG standard
Programming
Space technology
Domain specific languages
Software systems
Documentation
System testing
Costs
Time to market
Computational modeling},
   ISBN = {1074-6005},
   DOI = {10.1109/IWRSP.2004.1311104},
   year = {2004},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Shani, U. and Sela, A.},
   title = {Integrating Domain-Specific Programming into Software Design},
   booktitle = {2010 IEEE International Conference on Software Science, Technology & Engineering},
   pages = {1-6},
   abstract = {Domain-specific languages (DSLs) have recently become a focus of attention in the software engineering community. We look at domain-specific modeling (DSM) methods that drive modeling languages for specific domains with a strong emphasis on visual tools and suggest a method for integrating them into common software design methodologies. We demonstrate a practical approach, whereby components of software are designed to be externalized as specific domain-oriented tasks. The logic in such tasks is intended to be developed by skilled personnel, different from those required to implement the main application. Furthermore, the application will become adaptable to a large class of solutions that do not require new version releases when business logic changes. Unlike application customization via configuration parameters, the logic implemented in DSL languages requires a meaningful imperative expressive power. Our method starts with the common software design methodologies based on UML and uses the Eclipse Modeling Framework (EMF) tools to externalize a selected subset of the design.},
   keywords = {simulation languages
software tools
specification languages
domain specific programming
software design
domain specific languages
software engineering
domain specific modeling
visual tools
UML
Eclipse modeling framework
Logic
Unified modeling language
DSL
Application software
Design engineering
Personnel
Programming profession
Imperative Languages
EMF
Language Modeling
Software Engineering Methodologies},
   DOI = {10.1109/SwSTE.2010.9},
   year = {2010},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Singh, P. and Shukla, S. and Chandra, S. and Dixit, V.},
   title = {Performance evaluation of programming languages},
   booktitle = {2017 International Conference on Innovations in Information, Embedded and Communication Systems (ICIIECS)},
   pages = {1-4},
   abstract = {In the world of computer, languages used for the purpose of communication are known as programming languages. These languages are used to do the interaction between various other parts of computer and other machines. There is the long list of such languages which are widely used in this field, some of them are existing from long time while some are developed and were used for certain period of time and right now some of them are out of use. Here in this paper we basically did the comparison between array programming language and compiled programming languages besides this we also discussed about the concurrent, imperative and declarative languages. We further classified the imperative and declarative languages. We saw the dependency of languages on memory as we took the program of factorial in various languages as a result some of the programming languages used here terminated and provided the wrong output on giving the large value as input. As in case of factorial, if we have to perform the computation of nth number then we have to do the computation of (n-1)th term first which takes large memory size in static memory allocation while it can be easily done through dynamic allocation of memory as it does the use of runtime memory allocation concept. So, as we increase the input values most of the languages fails and result to lead wrong output.},
   keywords = {program compilers
programming languages
software performance evaluation
storage allocation
storage management
performance evaluation
concurrent languages
compiled programming languages
array programming language
declarative languages
imperative languages
Logic programming
Java
Resource management
Functional programming
Arrays
PLP
Functional
Recursive
Factorial
Multi-paradigm},
   DOI = {10.1109/ICIIECS.2017.8276102},
   year = {2017},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Sivonen, S.},
   title = {DSML for Developing Repository-Based Eclipse Plug-Ins},
   booktitle = {2008 12th International Software Product Line Conference},
   pages = {356-356},
   abstract = {Summary form only given. This paper presents a successful case of utilising DSM in software product line development: DSML and code generator for creating repository-based Eclipse plug-ins.},
   keywords = {program compilers
public domain software
simulation languages
software engineering
open source platform
DSML
repository-based Eclipse plug-ins
domain-specific modelling languages
code generation
software product line development:
code generator
embedded Java database
MySQL database
Databases
Unified modeling language
Generators
Computational modeling
Software
Java
Image databases},
   DOI = {10.1109/SPLC.2008.47},
   year = {2008},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Slominski, A. and Muthusamy, V. and Khalaf, R.},
   title = {Building a Multi-tenant Cloud Service from Legacy Code with Docker Containers},
   booktitle = {2015 IEEE International Conference on Cloud Engineering},
   pages = {394-396},
   abstract = {In this paper we address the problem of migrating a legacy Web application to a cloud service. We develop a reusable architectural pattern to do so and validate it with a case study of the Beta release of the IBM Bluemix Workflow Service [1] (herein referred to as the Beta Workflow service). It uses Docker [2] containers and a Cloudant [3] persistence layer to deliver a multi-tenant cloud service by re-using a legacy codebase. We are not aware of any literature that addresses this problem by using containers.The Beta Workflow service provides a scalable, stateful, highly available engine to compose services with REST APIs. The composition is modeled as a graph but authored in a Javascript-based domain specific language that specifies a set of activities and control flow links among these activities. The primitive activities in the language can be used to respond to HTTP REST requests, invoke services with REST APIs, and execute Javascript code to, among other uses, extract and construct the data inputs and outputs to external services, and make calls to these services.Examples of workflows that have been built using the service include distributing surveys and coupons to customers of a retail store [1], the management of sales requests between a salesperson and their regional managers, managing the staged deployment of different versions of an application, and the coordinated transfer of jobs among case workers.},
   keywords = {application program interfaces
cloud computing
Java
specification languages
Javascript code
HTTP REST requests
Javascript-based domain specific language
REST API
Cloudant persistence layer
Beta Workflow service
IBM Bluemix Workflow Service
reusable architectural pattern
legacy Web application
docker containers
legacy codebase
multitenant cloud service
Containers
Engines
Security
Organizations
Browsers
Memory management},
   DOI = {10.1109/IC2E.2015.66},
   year = {2015},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Sobernig, S. and Hoisl, B. and Strembeck, M.},
   title = {Requirements-Driven Testing of Domain-Specific Core Language Models Using Scenarios},
   booktitle = {2013 13th International Conference on Quality Software},
   pages = {163-172},
   abstract = {In this paper, we present an approach for the scenario-based testing of the core language models of domain-specific modeling languages (DSML). The core language model is a crucial artifact in DSML development, because it captures all relevant domain abstractions and specifies the relations between these abstractions. In software engineering, scenarios are used to explore and to define (actual or intended) system behavior as well as to specify user requirements. The different steps in a requirements-level scenario can then be refined through detailed scenarios. In our approach, we use scenarios as a primary design artifact. Non-executable, human-understandable scenario descriptions can be refined into executable test scenarios. To demonstrate the applicability of our approach, we implemented a scenario-based testing framework based on the Eclipse Modeling Framework (EMF) and the Epsilon model-management toolkit.},
   keywords = {formal specification
program testing
specification languages
requirement-driven testing
domain-specific core language models
scenario-based testing
domain-specific modeling languages
DSML development
software engineering
user requirements
Eclipse modeling framework
Epsilon model-management toolkit
EMF
system behavior
Biological system modeling
Testing
Unified modeling language
Software
Prototypes
Metamodeling
domain-specific modeling
language engineering
metamodel testing},
   ISBN = {2332-662X},
   DOI = {10.1109/QSIC.2013.56},
   year = {2013},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Song, Z. and Tilevich, E.},
   title = {Equivalence-Enhanced Microservice Workflow Orchestration to Efficiently Increase Reliability},
   booktitle = {2019 IEEE International Conference on Web Services (ICWS)},
   pages = {426-433},
   abstract = {The applicability of the microservice architecture has extended beyond traditional web services, making steady inroads into the domains of IoT and edge computing. Due to dissimilar contexts in different execution environments and inherent mobility, edge and IoT applications suffer from low execution reliability. Replication, traditionally used to increase service reliability and scalability, is inapplicable in these resource-scarce environments. Alternately, programmers can orchestrate the parallel or sequential execution of equivalent microservices-microservices that provide the same functionality by different means. Unfortunately, the resulting orchestrations rely on parallelization, synchronization, and failure handing, all tedious and error-prone to implement. Although automated orchestration shifts the burden of generating workflows from the programmer to the compiler, existing programming models lack both syntactic and semantic support for equivalence. In this paper, we enhance compiler-generated execution orchestration with equivalence to efficiently increase reliability. We introduce a dataflow-based domain-specific language, whose dataflow specifications include the implicit declarations of equivalent microservices and their execution patterns. To automatically generate reliable workflows and execute them efficiently, we introduce new equivalence workflow constructs. Our evaluation results indicate that our solution can effectively and efficiently increase the reliability of microservice-based applications.},
   keywords = {data flow analysis
formal specification
program compilers
software architecture
software reliability
specification languages
Web services
equivalence-enhanced microservice workflow orchestration
microservice architecture
edge computing
low execution reliability
service reliability
resource-scarce environments
parallel execution
sequential execution
automated orchestration
compiler-generated execution orchestration
dataflow-based domain-specific language
execution patterns
microservice-based applications
equivalence workflow
dataflow specifications
Workflow orchestration
microservice
functional equivalence
quality of service},
   DOI = {10.1109/ICWS.2019.00076},
   year = {2019},
   type = {Conference Proceedings}
}

@article{
   author = {Sorber, L. and Barel, M. Van and Lathauwer, L. De},
   title = {Structured Data Fusion},
   journal = {IEEE Journal of Selected Topics in Signal Processing},
   journalAlt = {IEEE Journal of Selected Topics in Signal Processing},
   volume = {9},
   number = {4},
   pages = {586-600},
   abstract = {We present structured data fusion (SDF) as a framework for the rapid prototyping of knowledge discovery in one or more possibly incomplete data sets. In SDF, each data set-stored as a dense, sparse, or incomplete tensor-is factorized with a matrix or tensor decomposition. Factorizations can be coupled, or fused, with each other by indicating which factors should be shared between data sets. At the same time, factors may be imposed to have any type of structure that can be constructed as an explicit function of some underlying variables. With the right choice of decomposition type and factor structure, even well-known matrix factorizations such as the eigenvalue decomposition, singular value decomposition and QR factorization can be computed with SDF. A domain specific language (DSL) for SDF is implemented as part of the software package Tensorlab, with which we offer a library of tensor decompositions and factor structures to choose from. The versatility of the SDF framework is demonstrated by means of four diverse applications, which are all solved entirely within Tensorlab's DSL.},
   keywords = {data mining
eigenvalues and eigenfunctions
matrix decomposition
sensor fusion
specification languages
tensors
structured data fusion
rapid prototyping
knowledge discovery
tensor decomposition
matrix factorization
eigenvalue decomposition
singular value decomposition
QR factorization
domain specific language
DSL
software package
Tensorlab
SDF framework
Tensile stress
Data integration
Vectors
Approximation methods
Signal processing
Covariance matrices
Big data
tensor
data fusion
structured matrices
canonical polyadic decomposition
block term decomposition
structured factors},
   ISSN = {1941-0484},
   DOI = {10.1109/JSTSP.2015.2400415},
   year = {2015},
   type = {Journal Article}
}

@inproceedings{
   author = {Stefanov, V. and List, B.},
   title = {Business Metadata for the DataWarehouse},
   booktitle = {2006 10th IEEE International Enterprise Distributed Object Computing Conference Workshops (EDOCW'06)},
   pages = {20-20},
   abstract = {Enterprise organizations use Data Warehouses (DWHs) analyze their performance. Performance is judged regarding the achievement of goals. DWH data models are well established. There exist numerous domain-specific modeling approaches. Enterprises also often model their goals in terms of formal or semiformal goal models. The problem is that these two aspects - the Data Warehouse and the Enterprise Goals - are described separately and not related to each other. We identify a need for combining these two aspects. If their relationship is made explicit, it can be used to enhance the way users access and interpret data in the DWH. To address this limitation, in this paper we introduce a weaving model between enterprise goals and DWH data. Thus we present a domain-specific application of model weaving to an aspect of enterprise computing. We describe metamodels for both aspects as well as the weaving links between them, which allows to show the aspects separately but also in combination. We furthermore illustrate how to use the weaving links to create business metadata. Business metadata can be used in the DWH to describe the business context and implications of the data to the users, but is usually not available in today's DWHs. We apply our approach to a sample situation, which is used as a running example in the paper.},
   keywords = {Weaving
Context modeling
Data warehouses
Data models
Information analysis
Investments
Data structures
Multidimensional systems
Performance analysis
Information resources},
   DOI = {10.1109/EDOCW.2006.27},
   year = {2006},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Strasser, T. and Peters, T. and Jägle, H. and Zrenner, E. and Wilke, R.},
   title = {An integrated domain specific language for post-processing and visualizing electrophysiological signals in Java},
   booktitle = {2010 Annual International Conference of the IEEE Engineering in Medicine and Biology},
   pages = {4687-4690},
   abstract = {Electrophysiology of vision - especially the electroretinogram (ERG) - is used as a non-invasive way for functional testing of the visual system. The ERG is a combined electrical response generated by neural and non-neuronal cells in the retina in response to light stimulation. This response can be recorded and used for diagnosis of numerous disorders. For both clinical practice and clinical trials it is important to process those signals in an accurate and fast way and to provide the results as structured, consistent reports. Therefore, we developed a freely available and open-source framework in Java (http://www.eye.uni-tuebingen.de/project/idsI4sigproc). The framework is focused on an easy integration with existing applications. By leveraging well-established software patterns like pipes-and-filters and fluent interfaces as well as by designing the application programming interfaces (API) as an integrated domain specific language (DSL) the overall framework provides a smooth learning curve. Additionally, it already contains several processing methods and visualization features and can be extended easily by implementing the provided interfaces. In this way, not only can new processing methods be added but the framework can also be adopted for other areas of signal processing. This article describes in detail the structure and implementation of the framework and demonstrate its application through the software package used in clinical practice and clinical trials at the University Eye Hospital Tuebingen one of the largest departments in the field of visual electrophysiology in Europe.},
   keywords = {application program interfaces
data visualisation
electroretinography
Java
medical signal processing
neurophysiology
vision
integrated domain specific language
post-processing
electrophysiological signals
electroretinogram
ERG
neural cells
light stimulation
pipes-and-filters
fluent interfaces
application programming interfaces
smooth learning curve
visualization features
University Eye Hospital Tuebingen
visual electrophysiology
Lead
Artificial neural networks
Hospitals
HTML
Visualization
Algorithms
Computer Graphics
Diagnosis, Computer-Assisted
Humans
Programming Languages
Retinal Diseases
Software
User-Computer Interface},
   ISBN = {1558-4615},
   DOI = {10.1109/IEMBS.2010.5626417},
   year = {2010},
   type = {Conference Proceedings}
}

@article{
   author = {Sung, C. and Kim, T. G.},
   title = {Collaborative Modeling Process for Development of Domain-Specific Discrete Event Simulation Systems},
   journal = {IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)},
   journalAlt = {IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)},
   volume = {42},
   number = {4},
   pages = {532-546},
   abstract = {The discrete event systems specification (DEVS) formalism supports the object-oriented (OO) specification of discrete event models in a hierarchical, modular manner. If a system that is to be modeled is domain-specific, the development of models with the use of the DEVS formalism would require domain knowledge about the system as well as to understand DEVS semantics. This paper proposes a collaborative modeling process to compensate for the lack of professional engineers. To compensate, this modeling process utilizes three types of engineers: domain engineer, modeling and simulation (M&S) engineer, and platform engineer. The process consists of four steps: conceptual modeling, model partition, model implementation, and model integration/simulation. The system requirements are used to specify domain models in the conceptual modeling step, and the models are partitioned into two types: discrete event-level model (DEM) and behavioral-level model (BM). The DEM is specified as the DEVS formalism, and the BM is defined as algorithms and equations. Each model is implemented separately, and the implemented models are integrated and simulated flexibly by using a dynamic linking library. The modeling process is then applied to develop a war game simulator. The advantage of this modeling process is that the collaborative work is related to the whole series of steps. This collaboration maximally utilizes the capabilities of the professional engineers by seamlessly separating yet correlating their works.},
   keywords = {computer games
discrete event simulation
formal specification
groupware
military computing
object-oriented methods
collaborative modeling process
domain-specific discrete event simulation system development
object-oriented specification
DEVS formalism
domain knowledge
DEVS semantics
domain engineer
modeling and simulation engineer
platform engineer
conceptual modeling
model partition
model implementation
model integration-simulation
discrete event-level model
DEM
behavioral-level model
BM
dynamic linking library
war game simulator
Unified modeling language
Object oriented modeling
Mathematical model
Collaboration
Discrete event systems
Software
discrete event systems specification (DEVS)
domain-specific
modeling process
simulation systems
unified modeling language (UML)},
   ISSN = {1558-2442},
   DOI = {10.1109/TSMCC.2011.2135850},
   year = {2012},
   type = {Journal Article}
}

@inproceedings{
   author = {Sutherland, C. J. and MacDonald, B.},
   title = {RoboLang: A Simple Domain Specific Language to Script Robot Interactions},
   booktitle = {2019 16th International Conference on Ubiquitous Robots (UR)},
   pages = {265-270},
   abstract = {Building interactions for social robots is hard and be time consuming. One common solution is to build visual programming tools, but these tools are not integrated with tools and practises used by software developers. Rather than building a new tool, we have implemented a text-based Domain Specific Language that could be used with existing programming tools. RoboLang is designed to be a simple language specifically for programming social interactions on a robot. The scripts can be run on different robot platforms with minimal changes and can be easily modified in response to user feedback.},
   keywords = {control engineering computing
high level languages
human-robot interaction
robot programming
RoboLang
social robots
social interactions
robot interactions
text-based domain specific language
Robots
Visualization
Tools
Programming profession
Computer languages
Buildings},
   ISBN = {2325-033X},
   DOI = {10.1109/URAI.2019.8768625},
   year = {2019},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Szabo, C. and Chen, Y.},
   title = {A Model-Driven Approach for Ensuring Change Traceability and Multi-model Consistency},
   booktitle = {2013 22nd Australian Software Engineering Conference},
   pages = {127-136},
   abstract = {In model driven engineering, high-level models of an application are constructed to enable reasoning about functional and non-functional requirements independently of implementation issues and concerns. This allows for reduced maintenance, shortens development time, and permits automated model updates, system model executions, and impact assessment. Part of model driven engineering, multi-modeling integrates models that abstract various aspects of the system, such as I/O, behavioral, and functional among others, at different levels of granularity and using various domain specific modeling languages. An important challenge is to understand the relationship between these models towards preserving multi-model consistency as changes in one model affect other models in the multi-model. This paper presents a multi-modeling architecture that captures model relationships at syntactic and semantic levels. We define a taxonomy of change effects that relies on a relationship correspondence meta-model to highlight and trace the impact of changes across various modeling environments. Following the correspondence meta-model and associated change effects, our prototype implementation ensures that multi-model consistency is met and notifies stakeholders of significant changes. Our case study of a submarine tracking system checks multi model consistency and highlights the impact of changes across system modeling tools that capture its functional and behavioral aspects among others. Our experiments show the feasibility of our approach while highlighting important challenges.},
   keywords = {model-based reasoning
simulation languages
software maintenance
change traceability
multimodel consistency
model driven engineering
reasoning
nonfunctional requirements
maintenance
impact assessment
domain specific modeling languages
taxonomy
submarine tracking system
Semantics
Analytical models
Data models
Mathematical model
Maintenance engineering
multi-modeling
model consistency},
   ISBN = {2377-5408},
   DOI = {10.1109/ASWEC.2013.24},
   year = {2013},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Sztipanovits, J.},
   title = {Model integrated computing: foundations and applications},
   booktitle = {12th IEEE International Conference and Workshops on the Engineering of Computer-Based Systems (ECBS'05)},
   pages = {xii},
   abstract = {Summary form only given. The goal of this article is to describe our approach to model-based design, which is based on an integrated framework called model-integrated computing (MIC). MIC includes theoretical foundations for specifying the syntax and semantics of domain-specific modeling languages (DSML), and provides a meta-programmable tool suite for modeling, model transformation, code generation and tool integration. The approaches and tools discussed are used in a wide range projects focusing on different categories of computer-based systems.},
   keywords = {specification languages
formal specification
programming language semantics
metacomputing
software tools
model-based design
model-integrated computing
MIC
domain-specific modeling language
DSML
meta-programmable tool
model transformation
code generation
computer-based systems
Software requirements and specifications},
   DOI = {10.1109/ECBS.2005.50},
   year = {2005},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Tao, Jiang and WenYun, Zheng},
   title = {Research on formalization of Domain-Specific Metamodeling Language based on first-order logic},
   booktitle = {2011 IEEE International Conference on Computer Science and Automation Engineering},
   volume = {4},
   pages = {170-174},
   abstract = {Domain-Specific Modeling has been widely and successfully used in software system modeling of specific domains. In spite of its general important, due to its informal definition, Domain-Specific Metamodeling Language (DSMML) cannot strictly represent its structural semantics, so its properties such as consistency cannot be systematically verified. In response, the paper proposes a formal representation of the structural semantics of DSMML named XMML based on first-order logic. Firstly, XMML is introduced, secondly, we illustrate our approach by formalization of attachment relationship which is one of association meta-types based on first-order logic, based on this, the approach of consistency verification of XMML itself and metamodels built based on XMML is presented, finally, the formalization automatic mapping engine for metamodels is introduced to show the application of formalization of XMML.},
   keywords = {formal verification
simulation languages
XML
domain-specific metamodeling language formalization
first-order logic
software system modeling
DSMML
formal representation
formalization automatic mapping engine
association meta-types
XMML consistency verification
Semantics
Unified modeling language
Metamodeling
Analytical models
Syntactics
Generators
Engines
Domain-Specific Metamodeling Language (DSMML)
XMML
structural semantics
attachment
consistency},
   DOI = {10.1109/CSAE.2011.5952827},
   year = {2011},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Teixeira, T. S. F. X. and Padua, D. and Gropp, W.},
   title = {A DSL for Performance Orchestration},
   booktitle = {2017 26th International Conference on Parallel Architectures and Compilation Techniques (PACT)},
   pages = {372-372},
   abstract = {The complexity and diversity of today's computer architectures are requiring more attention from the software developers in order to harness all the computing power available. Furthermore, each different modern architecture requires a potentially non-overlapping set of optimizations to attain a higher fraction of its nominal peak speed. This leads to challenges about performance portability and code maintainability, in particular, how to manage different optimized versions of the same code tailored to different architectures and how to keep them up to date as new algorithmic features are added. This increasing complexity of the architectures and the extension of the optimization space tends to make compilers deliver unsatisfactory performance, and the gap between the performance of hand-tuned and compiler-generated code has grown dramatically. Even the use of advanced optimization flags is not enough to narrow this gap. On the other hand, optimizing applications manually is very time-consuming, and the developer needs to understand and interact with many different hardware features for each architecture. Successful research has been developed to assist the programmer in this painful and error-prone process of implementing, optimizing and porting applications to different architectures. Nonetheless, the adoption of these works has been mostly restricted to specific domains, such as dense linear algebra, Fourier transforms, and signal processing. We have developed the framework ICE that decouples the performance expert role from the application expert role (separation of concerns). It allows the use of architecture-specific optimizations while keeping the code maintainable on the long term. It is responsible to orchestrate the use of multiple optimization tools to application's baseline version and perform an empirical search to find the best sequence of optimizations and their parameters. The baseline version is regarded as not having any architecture- or compiler-specific optimizations. The optimizations and the empirical search are directed by a domain-specific language (DSL) in an external file. Application's code are often dramatically altered by adding multiple optimization cases for each architecture used. This DSL allows the performance expert to apply optimizations without disarrange the original code. The DSL has constructs to expose the options of the optimizations and generates a search space that can be traversed by different search tools. For instance, it has conditional statements that can be used to specify which optimizations should be carried out for each compiler. The DSL is not only the input of the empirical search, but also the output. It can be used so save the best sequence of transformations found in previous searches. The application's code is annotated with unique identifiers that are referenced in the DSL. Currently, source-to-source loop optimizations, algorithm and pragmas selection are accepted. The framework interface is flexible to integrate new optimization and search tools. And in case of any failure it falls back to the baseline version. We have applied the framework to linear algebra problems, stencil computations and to a production code for the simulation of plasma-coupled combustion~xpacc achieving up to 3x speedup. Other works have tried to solve the problem of facilitating optimizing applications, but they lack of important features comprised by ICE. CHiLL, Orio, and X Language simplifies the generation of optimized code. CHiLL is the only one among these that the instructions to carry out the optimizations are given using an external file, but it references loops by their position on the source and modifications in the source require modifications in the external file, restricting its use in large production codes. Only Orio empirically evaluates variants of the annotated code. Summarizing, the contributions of the framework are: the separation of concerns, incremental adoption, a DSL to specify the optimization space, interface to plug-in and compare different optimization nd search tools, combination of empirical search with expert knowledge.},
   keywords = {optimisation
program compilers
software architecture
software portability
DSL
performance orchestration
computer architectures
software development
portability
code maintainability
compiler-generated code
error-prone process
domain-specific language
source-to-source loop optimizations
Orio
Optimization
Computer architecture
Ice
Tools
Complexity theory
Linear algebra
Autotuning
Compilers},
   DOI = {10.1109/PACT.2017.50},
   year = {2017},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Tolvanen, J.},
   title = {Domain-Specific Modeling and Code Generation for Product Lines},
   booktitle = {10th International Software Product Line Conference (SPLC'06)},
   pages = {229-229},
   abstract = {Current modeling languages provide surprisingly little, if any, support for product line development. They are either based on the code world using the semantically well-defined concepts of programming languages (e.g. UML, SA/SD) or based on an architectural view using a simple component-connector concept. In both cases, the languages themselves say nothing about a product family or its variants. This situation could be compared to that of a programmer being asked to write object-oriented programs where the language does not support any object-oriented concepts.},
   keywords = {Object oriented modeling
Product development
Production
Metamodeling
Computer languages
Unified modeling language
Programming profession
Productivity
Telecommunication services
Electronic commerce},
   DOI = {10.1109/SPLINE.2006.1691611},
   year = {2006},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Ueyama, J. and Hughes, D. and Man, K. L. and Guan, S. and Matthys, N. and Horré, W. and Michiels, S. and Huygens, C. and Joosen, W.},
   title = {Applying a Multi-paradigm Approach to Implementing Wireless Sensor Network Based River Monitoring},
   booktitle = {2010 First ACIS International Symposium on Cryptography, and Network Security, Data Mining and Knowledge Discovery, E-Commerce and Its Applications, and Embedded Systems},
   pages = {187-191},
   abstract = {This paper describes the application of the DisSeNT middleware to implement Wireless Sensor Network based river monitoring. DisSeNT provides LooCI, an efficient run-time reconfigurable component model, PMA, a lightweight policy-based management framework and QARI, a declarative quality-aware deployment framework. Using a river monitoring case-study, this paper analyses how these distinct software development paradigms can be used in a complimentary fashion to develop efficient wireless sensor network applications. The resulting system has been deployed and evaluated in a real-world river monitoring scenario in the city of São Carlos, Brazil.},
   keywords = {environmental monitoring (geophysics)
middleware
rivers
software engineering
wireless sensor networks
multiparadigm approach
wireless sensor network
DisSeNT middleware
LooCI
runtime reconfigurable component model
PMA
lightweight policy-based management
QARI
declarative quality aware deployment
software development
real-world river monitoring
Carlos
Brazil
Sensors
Monitoring
Software
Programming
Multi-Paradigm Programming},
   DOI = {10.1109/CDEE.2010.44},
   year = {2010},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Uhrmacher, A. M.},
   title = {Keynote Speaker: Credible Simulation Models — Provenance beyond Reproducibility},
   booktitle = {2018 IEEE/ACM 22nd International Symposium on Distributed Simulation and Real Time Applications (DS-RT)},
   pages = {1-1},
   abstract = {When expressing concerns about the credibility of simulation studies, simulation data have been traditionally in the focus. However, what about another and, some might argue, even more central product of simulation studies, i.e., the simulation model itself? How can the credibility of a simulation model be assessed? Therefore, information about the process of generating a simulation model is needed. This provenance relates entities (or artifacts) and activities involved in the generating process. Based on simulation studies we will illuminate how the provenance of a simulation model relates the refinement, extension, composition, calibration and validation of simulation models to the diverse sources used in these processes. To exploit this information, unambiguously means for specifying entities play a central role. For example, a formal domain-specific language for modeling facilitates assessing and reusing simulation models. Similarly, a declarative domain-specific language for specifying simulation experiments, helps utilizing simulation experiments done with earlier models for future models. Thus, provenance, information about the past, does not only allow to understand the present, but also to design the future, in opening up new avenues for generating and analyzing simulation models.},
   keywords = {computer simulation
specification languages
simulation studies
simulation data
simulation experiments
formal domain-specific language
simulation model provenance
simulation model analysis},
   ISBN = {1550-6525},
   DOI = {10.1109/DISTRA.2018.8600928},
   year = {2018},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Vanderbauwhede, W. and Margala, M. and Chalamalasetti, S. R. and Purohit, S.},
   title = {A C++-embedded Domain-Specific Language for programming the MORA soft processor array},
   booktitle = {ASAP 2010 - 21st IEEE International Conference on Application-specific Systems, Architectures and Processors},
   pages = {141-148},
   abstract = {MORA is a novel platform for high-level FPGA programming of streaming vector and matrix operations, aimed at multimedia applications. It consists of soft array of pipelined low-complexity SIMD processors-in-memory (PIM). We present a Domain-Specific Language (DSL) for high-level programming of the MORA soft processor array. The DSL is embedded in C++, providing designers with a familiar language framework and the ability to compile designs using a standard compiler for functional testing before generating the FPGA bitstream using the MORA toolchain. The paper discusses the MORA-C++ DSL and the compilation route into the assembly for the MORA machine and provides examples to illustrate the programming model and performance.},
   keywords = {C++ language
field programmable gate arrays
multimedia computing
parallel processing
pipeline processing
program compilers
specification languages
C++ embedded domain specific language
MORA soft processor array programming
high level FPGA programming
vector streaming
matrix operations
multimedia
pipelined low complexity SIMD processors-in-memory
DSL
MORA machine
compiler
Domain specific languages
Streaming media
Application specific integrated circuits
Parallel programming
Concurrent computing
Algorithm design and analysis
Programming profession
Reconfigurable Processor
Soft Processor Array
Multimedia Processing
Domain-Specific Language},
   ISBN = {1063-6862},
   DOI = {10.1109/ASAP.2010.5540750},
   year = {2010},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Vangheluwe, H.},
   title = {Multi-paradigm modelling for design of complex heterogeneous systems},
   booktitle = {2008 Joint 6th International IEEE Northeast Workshop on Circuits and Systems and TAISA Conference},
   pages = {285-288},
   abstract = {Model-based techniques allow design teams to reduce development time and increase quality of products. The ubiquitous use of models in design has created challenges beyond supporting one isolated design task. In particular, the need to combine, couple, and integrate models at different levels of abstraction and in different formalisms poses problems which (Computer Automated) multi-paradigm modelling (CAMPaM) addresses. At the heart of multi-paradigm modeling is the use of explicit models throughout the development process (including requirements, design, realization, and testing). This leads to a framework with models to represent the syntax of formalisms used for modelling, models of the transformations that represent the operational semantics, as well as model-to-model transformations for inter-formalism transformation, refinement, and synthesis. This paper introduces the main CAMPaM concepts.},
   keywords = {CAD
logic design
modelling
systems analysis
complex heterogeneous systems
model-based techniques
computer automated multiparadigm modelling
operational semantics
model-to-model transformations
interformalism transformation
Unified modeling language
Computational modeling
Visualization
Mathematical model
Conferences
Analytical models
Finite element methods},
   DOI = {10.1109/NEWCAS.2008.4606377},
   year = {2008},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Varró, D.},
   title = {Keynote 2: A Bridge Over Troubled Water - Synergies between Model Transformation and Software Maintenance Techniques},
   booktitle = {2012 16th European Conference on Software Maintenance and Reengineering},
   pages = {5-6},
   abstract = {Summary form only given. Model transformations aim to process one (or more) source model in order to derive one (or more) target model, thus acting in the role of compilers in a model driven engineering context. In actual application scenarios, model transformations play a key role in (1) providing systematic bridges between various domain-specific modeling languages (2) driving the automated derivation of the design artifacts of software intensive systems (source code, configuration files, documentation, etc.), or simply (3) detecting inconsistencies and design rule violations in an early phase of development. This talk aims to build a bridge between model transformation techniques and traditional software maintenance. More specifically, I will first overview recent advances in model transformations, which can be easily and efficiently applied for various software maintenance or reengineering problems. Conversely, I will also present recent results where software maintenance approaches significantly improved the state-of-the-art of model transformations. Finally, I will also identify some challenges and research gaps to facilitate future collaboration between the two communities.},
   keywords = {simulation languages
software maintenance
model transformation
software maintenance technique
model driven engineering context
domain-specific modeling language
software intensive system
software design artifact
software reengineering problem
inconsistency detection
design rule violations
Educational institutions
Biological system modeling
Context modeling},
   ISBN = {1534-5351},
   DOI = {10.1109/CSMR.2012.10},
   year = {2012},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Venkataramanan, V. and Wang, P. and Srivastava, A. and Hahn, A. and Govindarasu, M.},
   title = {Interfacing techniques in testbed for cyber-physical security analysis of the electric power grid},
   booktitle = {2017 Workshop on Modeling and Simulation of Cyber-Physical Energy Systems (MSCPES)},
   pages = {1-6},
   abstract = {The electric power grid is an heterogeneous cyber-physical system with various physical, cyber/communication, computation, and control components. Individually, each of these components have established models and well developed tools for modeling, simulation and analysis. However, to analyze the impact of cyber events on the power grid, it is essential to bring all these components together in a coherent simulation environment to study the interdependencies of the cyber and physical system. Additionally, increasing instances of cyber attacks on the electric power grid demands tightly coupled cyber-physical co-simulation for security analysis. Integrated simulation of all the components requires interfacing existing domain-specific modeling and simulation tools for cyber-physical security analysis. This is a challenging task given diversity of domain specific physical and cyber systems simulator/ emulators and interface with hardware in the loop. This paper develops and analyzes number of interfacing techniques for integrated simulation of cyber and power systems for cyber-physical security analysis.},
   keywords = {power engineering computing
power grids
power system security
cyber-physical security analysis
heterogeneous cyber-physical system
cyber events
cyber attacks
electric power grid demands
cyber-physical co-simulation
integrated simulation
simulation tools
power systems
physical-communication components
cyber-communication components
domain-specific modeling
interfacing techniques
COKE
Cyber-Physical Test Bed
Cyber Security
Microgrid Reconfiguration
Micro-grid ResUiency
Real Tune Digital Sbnulator
Smart Grid},
   DOI = {10.1109/MSCPES.2017.8064543},
   year = {2017},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Vidal, G.},
   title = {A partial evaluation tool for multi-paradigm declarative languages},
   booktitle = {IEEE International Conference on Systems, Man and Cybernetics},
   volume = {1},
   pages = {194-199},
   keywords = {Logic programming
Functional programming
Equations
Proposals
Concurrent computing
Computational modeling
Data structures
Programming environments
Boolean functions
Arithmetic},
   ISBN = {1062-922X},
   DOI = {10.1109/ICSMC.2002.1167972},
   year = {2002},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Vitelli, M. C. and Tipaldi, M. and Troiano, L.},
   title = {A domain specific language oriented to fault detection, isolation and recovery},
   booktitle = {2013 International Conference on Soft Computing and Pattern Recognition (SoCPaR)},
   pages = {343-348},
   abstract = {Reliability of complex systems requires to take into account possible failures and strategies to detect and recover from system faults. This leads designers to consider models and algorithms capable of simulating and verifying fault detection, isolation and recovery (FDIR) strategies in different scenarios, characterized by uncertainty and partial information. Different solutions have been proposed. In this paper we present Trouble, a domain specific language aimed at describing and simulating troubleshooting algorithm. Different examples highlight advantages of such an approach.},
   keywords = {fault diagnosis
program testing
specification languages
system recovery
domain specific language
system fault detection
system fault isolation
system fault recovery
FDIR
complex system reliability
Trouble
troubleshooting algorithm
Hidden Markov models
Circuit faults
Production
Monitoring
Bayes methods
Computational modeling
Biomedical monitoring
reliable systems
domain-specific languages
Bayesian troubleshooting},
   DOI = {10.1109/SOCPAR.2013.7054156},
   year = {2013},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Wang, J. and Hu, C. and Lai, J. and Zhao, Y. and Zhang, S.},
   title = {Notice of Violation of IEEE Publication Principles: Multi-paradigm and Multi-grain Parallel Execution Model Based on SMP-Cluster},
   booktitle = {IEEE John Vincent Atanasoff 2006 International Symposium on Modern Computing (JVA'06)},
   pages = {266-272},
   abstract = {In this paper, we propose a multi-paradigm and multi-grain parallel execution model based on SMP-Cluster, which integrates coarse grain, mid grain and fine grain parallelism. Multiple paradigms supported by our model include task parallel, data parallel, sequential execution, data pipeline and task-farming paradigm. It can be achieved by extending the OpenMP specification, and the extensions include directives for computing resource partition, data distribution and alignment, sequential execution and data pipeline, and functions for Master/Slave model in Macro-Task group. We also compare the performance of different implementations of three benchmark applications, using the same numerical algorithm but employing different programming approaches},
   DOI = {10.1109/JVA.2006.33},
   year = {2006},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Wang, Z. and Dong, Q. and Hongyue, He and Fengke, Fu},
   title = {Imprecise domain-specific modeling for C4ISR capability requirements analysis},
   booktitle = {International Conference on Information Science and Technology},
   pages = {33-38},
   abstract = {The paper proposes an approach to model the uncertain and vague requirements information of the C4ISR capability requirements. It suggests that C4ISR requirements elicitation be initiated with capability meta concept framework (CMCF) construction according to the Meta-Model of DoDAF. With the semantic confinement of CMCF, the approach extends the Fuzzy-UML and declares a C4ISR domain-specific modeling language (C4ISR DSL). Compared with classic UML and Fuzzy-UML, the C4ISR DSL is more specialized in C4ISR domain knowledge elicitation and reuse. The experiment shows the modeling language can better express both precise and vague concepts of the C4ISR capability model.},
   keywords = {fuzzy set theory
military computing
software architecture
systems analysis
Unified Modeling Language
C4ISR capability requirements analysis
capability meta concept framework
CMCF
meta model
DoDAF
fuzzy-UML
C4ISR domain-specific modeling language
C4ISR DSL
domain knowledge elicitation
Atmospheric modeling
Analytical models
DSL
Semantics
Coordinate measuring machines
Knowledge engineering},
   ISBN = {2164-4357},
   DOI = {10.1109/ICIST.2011.5765205},
   year = {2011},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Wang, Z. and Pu, G. and Li, J. and Gu, B.},
   title = {A Type System for SPARDL},
   booktitle = {2012 Sixth International Symposium on Theoretical Aspects of Software Engineering},
   pages = {209-216},
   abstract = {SPARDL is a domain-specific modeling language for periodic control systems, which are widely used in embedded systems. Periodic control systems are usually driven by the given period. A periodic control system can be decomposed into different modes or sub-modes, and each mode represents a system state observed from outside. We believe that introducing static checking will extend the power of SPARDL. In this paper, we develop a type system for SPARDL. To make the contributions of this paper convincible and easy to understand, we apply the traditional approaches to construct the type system for SPARDL. An operational semantics is proposed as the basic explanation of SPARDL. And then some type safety theorems are proved under such semantics. We apply the type system to an industrial case from China Academy of Space Technology(CAST) to evaluate the effectiveness of our approach in practice, and then eight type errors are revealed.},
   keywords = {embedded systems
periodic control
programming language semantics
safety
simulation languages
type system
SPARDL
domain-specific modeling language
periodic control systems
static checking
operational semantics
type safety theorems
industrial case
China Academy of Space Technology
CAST
type errors
Control systems
Software
Semantics
Abstracts
Context
Computational modeling
Periodic Control System},
   DOI = {10.1109/TASE.2012.47},
   year = {2012},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Weiss, N. and Preisler, T. and Renz, W.},
   title = {Towards a Unified Description Language for Simulations in Cloud Environments},
   booktitle = {2018 IEEE/ACM International Conference on Utility and Cloud Computing Companion (UCC Companion)},
   pages = {341-348},
   abstract = {In recent years, cloud infrastructures evolved into a flexible technology for computationally intense simulations. Container-based clouds provide scalability to scientists who develop large-scale distributed simulations, particularly when developed in microservice architecture. Automating configuration and deployment of such distributed simulations on container as a service (CaaS) platforms is a challenge that we approach in this paper. We will present a novel concept for a descriptive language, that allows for convenient execution and management of distributed simulations on cloud infrastructures using heterogeneous models run on CaaS platforms, supplemented by a software framework to implement functionality. This language will allow for reproducible simulation results and a reduction of necessary configuration for structural layers by providing an interface towards the simulation system. The configuration, deployment, conduction, roll-back and result collection of the simulation will be handled by the framework provided for this domain specific language (DSL).},
   keywords = {cloud computing
computer simulation
specification languages
unified description language
cloud environments
cloud infrastructures
container-based clouds
large-scale distributed simulations
microservice architecture
descriptive language
CaaS platforms
simulation system
domain specific language
container as a service
Containers
DSL
Computational modeling
Software
Tools
Computer architecture
SIMaaS
CaaS
Cloud
Simulation
cyber physical systems
distributed systems
microservice},
   DOI = {10.1109/UCC-Companion.2018.00078},
   year = {2018},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Werner, J. and Mathe, J. L. and Duncavage, S. and Malin, B. and Ledeczi, A. and Jirjis, J. N. and Sztipanovits, J.},
   title = {Platform-Based Design for Clinical Information Systems},
   booktitle = {2007 5th IEEE International Conference on Industrial Informatics},
   volume = {2},
   pages = {749-754},
   abstract = {Clinical information systems (CIS) have emerged as a new critical infrastructure that influence affordability and security of health care delivery. Complex and conflicting societal requirements, such as providing control for patients over their personal health information and requiring health organizations to assure the security and privacy of patient-specific information, create significant technical challenges for the design of CIS. This paper presents a novel approach that is based on the principles and tools of model integrated computing (MIC), platform-based design (PBD) and service-oriented architectures (SOA). We present a domain-specific, graphical design environment and show how formal system specifications can be mapped to different service-oriented architecture execution platforms through a set of standard languages, such as WSBPEL and XACML. The model-integrated clinical information systems (MICIS) design environment includes a suite of domain-specific modeling languages capturing essential aspects of CIS design, model transformation tools that map the domain models onto the standard specification languages of SOA platforms and static model analysis tools checking the consistency and wellformedeness of the multiple-view models. The MICIS design tool is tested in modeling the MyHealth@Vanderbilt patient portal of the Vanderbilt University Medical Center.},
   keywords = {data privacy
health care
medical information systems
software architecture
specification languages
platform-based design
clinical information system
model integrated computing
service-oriented architecture
graphical design environment
formal system specification
XACML
WSBPEL
specification language
Clinical diagnosis
Service oriented architecture
Computational Intelligence Society
Information security
Medical services
Privacy
Microwave integrated circuits
Information analysis
Medical tests},
   ISBN = {2378-363X},
   DOI = {10.1109/INDIN.2007.4384867},
   year = {2007},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {White, J. and Schmidt, D. and Gokhale, A.},
   title = {The J3 Process for Building Autonomic Enterprise Java Bean Systems},
   booktitle = {Second International Conference on Autonomic Computing (ICAC'05)},
   pages = {363-364},
   abstract = {Autonomic computer systems aim to reduce the configuration, operational, and maintenance costs of distributed enterprise applications. This paper provides two contributions to the development of autonomic computing systems using Enterprise Java Beans (EJBs). First, we describe a model-driven development (MDD) tool that formally captures the design of EJB systems, their quality of service (QoS) requirements, and the autonomic properties that will be applied to the EJBs to support the rapid development of autonomic EJB applications. Second, we describe how this MDD tool can generate code to plug EJBs into a Java component framework that provides an autonomic structure to monitor, configure, and execute EJBs and their adaptation strategies at run-time},
   keywords = {distributed object management
formal specification
Java
object-oriented programming
program compilers
quality of service
specification languages
J3 process
autonomic Enterprise Java bean systems
autonomic computer systems
system configuration
system maintenance
distributed enterprise applications
EJB systems
QoS requirements
EJB applications
code generation
Java component
autonomic structure
adaptation strategy
J2EEML
domain-specific modeling language
Monitoring
Distributed computing
Application software
Plugs
Humans
Costs
Runtime
Large scale integration},
   DOI = {10.1109/ICAC.2005.60},
   year = {2005},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Winberg, S. and Mohapi, L. and Inggs, M.},
   title = {OptiSDR — A domain specific language to improve developer productivity for software defined radio},
   booktitle = {2016 IEEE International Conference on Emerging Technologies and Innovative Business Practices for the Transformation of Societies (EmergiTech)},
   pages = {20-26},
   abstract = {Domain specific languages (DSLs) offer the potential for using a small, specialized and highly expressive programming language to concisely represent solutions for a particular domain of problems. The DSL approach is in stark contrast to that of a general programming language that attempts to provide a means to represent solutions for a broad range of problems. DSLs may incorporate constructs and syntactical features that not only relate to the problem context, but also to the execution platform. DSLs thus provide a potential for reducing development time and thereby cutting business costs. At present this approach is likely more appropriate to prototyping and rapid experimental work; but as technologies to implement DSLs improve they may become more beneficial and cost effective for developing marketable products. In this paper we present a DSL, called OptiSDR, aimed to improve developer productivity for development of software defined radio (SDR) applications deployed on heterogeneous computing architectures (HCAs). OptiSDR is designed for HCAs that adhere to certain combinations of processing devices, namely FPGAs, graphics processing units, and multi-core general purpose processors. Our aim to improve developer productivity in multiple ways was achieved, with development cycles for parallel DSP routines for SDR reduced to few hours as opposed to days for CUDA-C development cycles. OptiSDR uses automatic code generation for structured parallel SDR patterns, and performs automatic profiling to generate faster execution kernels with speed-ups of more than 50× compared to other sequential implementations while reducing manual effort in porting and tuning code. Therefore this paper reports on a study confirming the potential to speed up when using OptiSDR for prototyping SDR applications.},
   keywords = {parallel architectures
parallel programming
program compilers
program diagnostics
programming languages
software radio
source code (software)
telecommunication computing
OptiSDR
domain specific language
developer productivity
software defined radio
DSL
programming language
syntactical features
development time reduction
business cost cutting
SDR applications
heterogeneous computing architectures
HCA
FPGA
graphics processing units
multicore general purpose processors
parallel DSP routines
CUDA-C development cycles
automatic code generation
structured parallel SDR patterns
automatic profiling
porting code
tuning code
Field programmable gate arrays
Computer architecture
Computer languages
Programming},
   DOI = {10.1109/EmergiTech.2016.7737304},
   year = {2016},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Windisch, A. and Monjau, D.},
   title = {An operational framework for the multi-lingual system simulation based on /spl pi/-calculus},
   booktitle = {SCCC 2001. 21st International Conference of the Chilean Computer Science Society},
   pages = {282-291},
   abstract = {Complex heterogeneous systems are usually specified at system level by a set of interacting cores each of which can be implemented in a different, domain-specific language. The dynamic verification of such systems requires a coupling of a set of language-specific simulators to a multilanguage simulation system such that the simulation semantics of each individual language are respected. In order to aid a semantics-preserving coupling this paper introduces an operational framework based upon which the simulation semantics of different languages can be formally captured and their correct co-simulation semantics can be derived. This formalisation of the simulation semantics is founded on a fixed set of semantic primitives for capturing model structure, behaviour communication, timing, and scheduling. All parts of the presented framework are defined in the single unifying notation of the /spl pi/-calculus process algebra.},
   keywords = {pi calculus
hardware description languages
integrated circuit design
circuit simulation
operational framework
multi-lingual system simulation
/spl pi/-calculus
heterogeneous systems
domain-specific language
dynamic verification
language-specific simulators
multilanguage simulation system
simulation semantics
semantics-preserving coupling
co-simulation semantics
semantic primitives
model structure
behaviour
communication
timing
scheduling
process algebra
microelectronic circuits
heterogeneous components
complex heterogeneous systems-on-chip
Computational modeling
Space technology
Aerospace electronics
Design methodology
Computer simulation
Military aircraft
Chemical technology
Computer science
Domain specific languages
Aerodynamics},
   ISBN = {1522-4902},
   DOI = {10.1109/SCCC.2001.972658},
   year = {2001},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Wyk, E. V. and Krishnan, L. and Bodin, D. and Johnson, E. and Schwerdfeger, A. and Russell, P.},
   title = {Tool Demonstration: Silver Extensible Compiler Frameworks and Modular Language Extensions for Java and C},
   booktitle = {2006 Sixth IEEE International Workshop on Source Code Analysis and Manipulation},
   pages = {161-161},
   abstract = {In this tool demonstration of Silver extensible compiler frameworks for Java and C we illustrate how new languages that are adapted to specific problem domains can be easily created, by their users, by importing a set of desired domain-specific language extensions into an extensible host language compiler. Language extensions for computational geometry and database access will be shown. We also show extensions that provide general purpose language features such as algebraic types and pattern matching can be imported into an extensible language compiler. Each Silver extensible compiler framework supports the development of language extensions that have two important facets. First, language extensions should satisfy a completeness requirement. That is, they should be as welldeveloped as host language features and fit seamlessly into the host language. In particular, the language feature designer should be able to specify new language constructs together with their domain-specific semantic analyses and techniques for their optimization. One aspect of this requirement is that language extension should report a useful error message when they are used incorrectly. Second, the extensions should be modular so that a programmer can extend his or her language by choosing from a collection of previously defined features knowing only the functionality they provide and with no implementation-level knowledge or a detailed analysis of their interactions. Thus we draw a distinction between the programmer importing an extension and the feature designer who implements it. We will show extensible compilers for both C and Java. These compilers are defined by an attribute grammar written in the Silver attribute grammar language. A Silver compiler analyses attribute grammar specifications and generates an executable compiler for the defined (extended) language by translating the Silver specifications into an efficient Haskell representation. Language extensions are also specified as Silver attribute grammar fragments and the framework tools automatically compose specifications of the host language and chosen language extensions into a specification for the custom extended language.},
   keywords = {Silver
Java
Programming profession
Domain specific languages
Computational geometry
Pattern matching
Computer science
Spatial databases
Design optimization
Engineering profession},
   DOI = {10.1109/SCAM.2006.32},
   year = {2006},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Yafi, M. Z. and Fatima, A.},
   title = {Syntax Recovery for Uniface as a Domain Specific Language},
   booktitle = {2018 UKSim-AMSS 20th International Conference on Computer Modelling and Simulation (UKSim)},
   pages = {61-66},
   abstract = {This paper discusses the problems faced by the organisations who are running domain specific 4GL systems to deploy their core business logic. Given the fact that it is often not realistic to find new engineers for these not-widespread languages, the paper proposes a method to extract useful artefacts from 4GL systems which have the data stored in XML like format such as Uniface system. In this work, the authors show how to use Encapsulated Document Object Model to read Uniface XML and scan the content to extract the custom code. In addition, this paper introduces how to restore the code schema and visualise it.},
   keywords = {object-oriented programming
program compilers
software engineering
software metrics
XML
syntax recovery
domain specific 4GL systems
Uniface system
Uniface XML
business logic
encapsulated document object model
HTML
Syntactics
Business
Indexes
Domain specific languages
Uniface
XML parsing
EDOM},
   ISBN = {2158-1657},
   DOI = {10.1109/UKSim.2018.00023},
   year = {2018},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Yang, G. and Zhao, M. and Hongli and Wu, Z.},
   title = {SmartC: A Component-Based Hierarchical Modeling Language for Automotive Electronics},
   booktitle = {2006 9th International Conference on Control, Automation, Robotics and Vision},
   pages = {1-6},
   abstract = {This paper introduces SmartC, a language designed for programming automotive electronics embedded systems such as engine control systems. SmartC is a hierarchical modeling language and implements the SmartOSEK operating system model. The SmartC models are classified into four levels, namely module level, task level, subtask level and component level. In the SmartC models, control-flow oriented models and data-flow oriented models are integrated in the hybrid SmartC models. At the task level, the model is constructed based on the control flow, whereas the component level model is constructed based on the data flow. In SmartC programs, all inter-task communication, task triggering mechanisms, and access to guarded global variables, are automatically generated by the SmartC generator which generates the C code from the SmartC code. Having well-structured concurrency mechanisms, SmartC greatly reduces the risk of concurrency errors, such as deadlock and race conditions. The SmartC language is implemented on the automated manual transmission (AMT) control system and is compatible with the OSEK/VDX specifications. We use a continuous time (CT) model as an example to illustrate the effectiveness of the language},
   keywords = {automotive electronics
concurrency control
embedded systems
engines
object-oriented languages
program compilers
road vehicles
specification languages
SmartC modeling language
component-based hierarchical modeling language
automotive electronic programming
engine control system
SmartOSEK operating system
control-flow oriented model
data-flow oriented model
intertask communication
task triggering
C code generation
concurrency errors
deadlock
race condition
automated manual transmission control system
Embedded system
Automotive engineering
Embedded software
Operating systems
Control system synthesis
Communication system control
Application software
Software systems
Automatic control
OSEK/VDX
Modeling Language
Domain-specific Language},
   DOI = {10.1109/ICARCV.2006.345212},
   year = {2006},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Yang, J. and Hu, Z. and Zheng, Y.},
   title = {Macml: A Domain-Specific Language for Machinery Service Management},
   booktitle = {2010 International Conference on Service Sciences},
   pages = {293-297},
   abstract = {The paper presents Macml, a domain-specific language (DSL) that focuses on the effective specification, implementation, and verification of information systems in the domain of machinery services. As a meta-model of the application domain, the language precisely defining elements including entities, relationships, behaviors, constraints, and workflows, based on which the users, domain experts, and software engineers can effectively communicate with each other and work together to model a variety of machinery service management systems, which are all instances of the meta-model and which can be further transformed into executable systems mechanically. As a case study, a system model of Macml is presented to illustrate the implementation of our approach.},
   keywords = {formal specification
formal verification
information systems
programming languages
Macml
domain-specific language
machinery service management
information systems specification
information systems verification
meta-model
Domain specific languages
Machinery
DSL
Software systems
Application software
Object oriented modeling
Engineering management
Design engineering
Computer languages
domain-specific language (DSL)
service management
model transformation},
   ISBN = {2165-3836},
   DOI = {10.1109/ICSS.2010.12},
   year = {2010},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Zabasta, A. and Carreira, P. and Nikiforova, O. and Amaral, V. and Kunicina, N. and Goulão, M. and Sukovskis, U. and Ribickis, L.},
   title = {Developing a mutually-recognized cross-domain study program in cyber-physical systems},
   booktitle = {2017 IEEE Global Engineering Education Conference (EDUCON)},
   pages = {791-799},
   abstract = {The primary scientific targets of the European COST Action Multi-Paradigm Modelling for Cyber-Physical Systems (MPM4CPS) are: i) the conceptualization of techniques and tools for improving interoperability; ii) the development of new ontologies and formalisms (and the links between them) to deal with the heterogeneity; and, iii) to perform the integration of the problems resulting from several application domains, under a common MPM4CPS umbrella. The action also aims at crystallizing MPM4CPS contents into a suitable format for educational purposes. This entails to create the base for a European Master and PhD program in MPM4CPS involving several European leading Universities and setting up the respective discipline roadmap facing the challenge of development mutually recognized cross-domain expertise based study program in CPS. This paper offers a methodology for the creation of CPS expert profile for educational purposes, provides an analysis of results of an initial survey of experts in the field and sets up a discussion about the next steps of the research. The paper depicts the work in a progress.},
   keywords = {computer science education
cyber-physical systems
electrical engineering education
mechanical engineering
cross-domain study program
CPS expert profile
MPM4CPS
multiparadigm modelling for cyber-physical systems
electrical engineering
computer science engineering
Europe
Industries
Training
Computers
Multi-Paradigm Modelling
design and simulation
software engineering
computer engineering
student master program development},
   ISBN = {2165-9567},
   DOI = {10.1109/EDUCON.2017.7942937},
   year = {2017},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Zander, J. and Mosterman, P. J.},
   title = {Technical engine for democratization of modeling, simulations, and predictions},
   booktitle = {Proceedings of the 2012 Winter Simulation Conference (WSC)},
   pages = {1-14},
   abstract = {Computational science and engineering play a critical role in advancing both research and daily-life challenges across almost every discipline. As a society, we apply search engines, social media, and selected aspects of engineering to improve personal and professional growth. Recently, leveraging such aspects as behavioral model analysis, simulation, big data extraction, and human computation is gaining momentum. The nexus of the above facilitates mass-scale users in receiving awareness about the surrounding and themselves. In this paper, an online platform for modeling and simulation (M&S) on demand is proposed. It allows an average technologist to capitalize on any acquired information and its analysis based on scientifically-founded predictions and extrapolations. The overall objective is achieved by leveraging open innovation in the form of crowd-sourcing along with clearly defined technical methodologies and social-network-based processes. The platform aims at connecting users, developers, researchers, passionate citizens, and scientists in a professional network and opens the door to collaborative and multidisciplinary innovations. An example of a domain-specific model of a pick and place machine illustrates how to employ the platform for technical innovation and collaboration.},
   keywords = {cloud computing
digital simulation
extrapolation
innovation management
search engines
social aspects of automation
social networking (online)
technical engine
modeling democratization
simulation democratization
prediction democratization
computational science
computational engineering
social media
personal growth
professional growth
behavioral model analysis
data extraction
human computation
mass-scale users
online modeling and simulation platform
M&S
information analysis
scientifically-founded predictions
scientifically-founded extrapolations
crowd-sourcing
social-network-based processes
professional network
multidisciplinary innovations
collaborative innovations
domain-specific model
Engines
Computational modeling
Analytical models
Data models
Information management
Data handling
Data storage systems},
   ISBN = {1558-4305},
   DOI = {10.1109/WSC.2012.6465243},
   year = {2012},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Zeeshan, S. and Ahmed, Z.},
   title = {PAS-MUT with Somatic Mutations in Cancer and Classified Diseases for Clinical-Genomics Research: PAS-MUT & Somatic Mutations},
   booktitle = {2019 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)},
   pages = {1708-1715},
   abstract = {Over the recent years, enormous progress has been made in mapping complex traits in humans. These studies have demonstrated that there is a crucial need to generate appropriate gene-disease annotation repositories accessed through modern resources. Our focus here is to create a comprehensive database with mobile access to authentic somatic mutations in cancer and classified diseases worldwide, considered as the foundation for clinical and genomics research, epidemiology and precision medicine. In this manuscript, we present a non-commercial, academic and publically available iOS app i.e., PAS-MUT, which invites global users to freely download it on iPhone & iPad devices, quickly adopt its easy to use interface and search for somatic mutations, genes and related diseases. PAS-MUT is developed with Swift multi-paradigm programming language, XCODE integrated development environment for MacOS, and PHP scripting that uses MySQL database and web servers. PAS-MUT database includes over a million authentic somatic mutations released global, including available at the COSMIC, CNVD, SwissVar, and ClinVar etc. PAS-MUT is founded on the clinical and scientific premise to support and promote healthcare and genomics data sharing with technological advancements.},
   keywords = {authoring languages
cancer
genetics
genomics
health care
Internet
iOS (operating system)
medical information systems
mobile computing
SQL
diseases classification
clinical-genomics research
mapping complex traits
epidemiology
precision medicine
PAS-MUT database
PAS-MUT-and-somatic mutations
gene-disease annotation repositories
academic iOS app
authentic somatic mutations
genomics data
Web servers
MySQL database
PHP scripting
MacOS
XCODE integrated development environment
Swift
programming language
mobile access
Database
Disease
iOS-App
Mutations},
   DOI = {10.1109/BIBM47256.2019.8983236},
   year = {2019},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Zhang, C. and Bakshi, A. and Prasanna, V. K.},
   title = {ModelML: a Markup Language for Automatic Model Synthesis},
   booktitle = {2007 IEEE International Conference on Information Reuse and Integration},
   pages = {317-322},
   abstract = {Domain-specific modeling has become a popular way of designing and developing systems. It generally involves a systematic use of a set of object-oriented models to represent various facets of a domain. However, manually creating instances of these models is time-consuming and error-prone when a system in the domain is complex. Automatic model synthesis tools are thus usually developed to free users from the model creation process. In practice, most of these tools would hard code knowledge about the domain specific models in the program. A biggest problem with these tools is that their source code needs to be changed whenever the knowledge changes. In this paper, we define a model markup language (ModelML) to facilitate the development of automatic model synthesis tools. The language provides a complete self-describing representation of object-oriented models to be synthesized. Unlike other XML-based representations of models, ModelML reflects the structure of the models directly in the nesting of elements in the XML-based syntax. This feature allows the knowledge about the domain specific models to be decoupled from model synthesis tools. To demonstrate the usefulness of the markup language, we have developed a generic automatic model synthesis tool which is based on ModelML inputs.},
   keywords = {formal specification
object-oriented methods
XML
ModelML language
domain-specific modeling
object-oriented models
automatic model synthesis tools
model creation process
XML-based model markup language
Markup languages
Object oriented modeling
Reservoirs
Embedded system
Prototypes
Software engineering
Large-scale systems
Programming
Analytical models
Asset management},
   DOI = {10.1109/IRI.2007.4296640},
   year = {2007},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Zhang, L.},
   title = {Multi-view approach to model aerospace cyber-physical systems},
   booktitle = {2013 19th International Conference on Automation and Computing},
   pages = {1-6},
   abstract = {Aerospace cyber-physical system design focuses on the mutual impact of cyberspace and physical world. In this paper, we propose a multi-dimension, multidomain and multi-paradigm architecture approach for cyber physical systems. It integrates Modelica and AADL based on model-driven architecture to construct multidimension, multi-domain and multi-view approach for aerospace cyber physical systems. We divide aerospace cyber physical system into three dimensions: physical world dimension, communication dimension and computation dimension. We design the system from physical world view, functional view, static view, spatio-temporal view, Nonfunctional view, hardware view. The physical world analysis is considered to be one fundamental stage of our proposed method. The proposed method is illustrated by the modeling of the lunar rover system, which involves a broad range of mechanical, electronic, control, communications, computing, mechanics, and physics. In this paper, we specify and model the lunar rover system by extending Modelica and AADL.},
   keywords = {aerospace computing
space vehicles
multiview approach
aerospace cyber-physical systems
cyberspace
physical world
multidimension multidomain multiparadigm architecture approach
Modelica
AADL
model-driven architecture
physical world dimension
communication dimension
computation dimension
physical world view
functional view
static view
spatio-temporal view
nonfunctional view
hardware view
lunar rover system
architecture analysis and design language
Object oriented modeling
Unified modeling language
Computational modeling
Moon
Mathematical model
Computer architecture
Analytical models
CPS
Multi-View
Lunar Rover
Spatial-Temporal Features
Dynamic Continuous Featurest},    year = {2013},
   type = {Conference Proceedings}
}

@inproceedings{
   author = {Zhuang, Y.},
   title = {Query customization and trigger optimization on home care systems},
   booktitle = {2017 International Conference on Applied System Innovation (ICASI)},
   pages = {668-671},
   abstract = {Epilepsy is a common neural disorder disease, while difficult to cure. There is still a risk of suffering from seizures even though patients have used antiepileptic drugs or had an operation. In such cases, patients must be immediately taken care; on the other hand, how to avoid introducing danger to their family and people around is also a concern. To address this issue, we integrate and develop a health cloud system to detect, record, and further predict epileptic seizure, which includes a dedicated wearable device for detection, a medical-IoT box to avoid heavy computation on the wearable device and provide cross reference to cameras, a cloud computing platform for complex computation, and an application on tablets for health care professionals. We propose a reactive and highly programmable model for such a system to allow health care professionals to easily and quickly query data from different devices and customize the trigger conditions, while optimize computing resource to achieve power saving on devices. We base this research on reactive programming (RP), which recently attracts the interests of researchers and developers, to construct our model, and develop a domain-specific language (DSL) that is applied among the medical-IoT box, cloud computing, and user interface for health care professionals. Such a DSL must be easy-to-write since health care professionals are not necessarily experts in programming, but it must also be powerful enough to allow them to query the logging data, analyze the interaction between different devices, and further configure the setting of devices for individual patients to benefit from our platform. At the same time, it automatically optimizes the communication and computation based the trigger conditions to achieve power saving on devices.},
   keywords = {cloud computing
diseases
health care
query processing
query customization
trigger optimization
home care systems
epilepsy
common neural disorder disease
health cloud system
medical-IoT box
health care professionals
reactive programming
domain-specific language
user interface
Medical services
Programming profession
DSL
Mobile handsets
Cameras
epileptic seizure detection
health cloud platform},
   DOI = {10.1109/ICASI.2017.7988514},
   year = {2017},
   type = {Conference Proceedings}
}

